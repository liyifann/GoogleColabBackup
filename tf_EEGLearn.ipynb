{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf-EEGLearn.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMnAT2rS6yzi5zvRQoTzKc9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liyifann/GoogleColabBackup/blob/master/tf_EEGLearn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXiOvRNsgBg1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e7f10d9c-8ff6-4d5e-82af-e4ddf6f742cb"
      },
      "source": [
        "pip install tensorflow-gpu"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/93/c7bca39b23aae45cd2e85ad3871c81eccc63b9c5276e926511e2e5b0879d/tensorflow_gpu-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n",
            "\u001b[K     |████████████████████████████████| 421.8MB 37kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.0.8)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.8.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.11.2)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.17.5)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.9.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Collecting tensorboard<2.2.0,>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/23/53ffe290341cd0855d595b0a2e7485932f473798af173bbe3a584b99bb06/tensorboard-2.1.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 44.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.34.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.1.8)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.0)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.4.1)\n",
            "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 47.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.10.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu) (2.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (2.21.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.16.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.1.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (45.1.0)\n",
            "Collecting google-auth<2,>=1.6.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/6d/7aae38a9022f982cf8167775c7fc299f203417b698c27080ce09060bba07/google_auth-1.11.0-py2.py3-none-any.whl (76kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 9.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (2019.11.28)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (4.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (4.0.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.4.8)\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 2.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorflow-estimator==1.15.1, but you'll have tensorflow-estimator 2.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorboard 2.1.0 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.4.0, but you'll have google-auth 1.11.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: google-auth, tensorboard, tensorflow-estimator, tensorflow-gpu\n",
            "  Found existing installation: google-auth 1.4.2\n",
            "    Uninstalling google-auth-1.4.2:\n",
            "      Successfully uninstalled google-auth-1.4.2\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "Successfully installed google-auth-1.11.0 tensorboard-2.1.0 tensorflow-estimator-2.1.0 tensorflow-gpu-2.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkxBIY-UhDCL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "349f3772-9f80-4e70-b753-921a814a8fa0"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EG2_6E3Xi_KP",
        "colab_type": "text"
      },
      "source": [
        "model below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMTCXHl3jEGT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "604faab1-da9f-4bf0-a0d4-330c0f65ec9c"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def my_conv2d(inputs, filters, kernel_size, strides=(1, 1), padding='same', activation=None, name=None, reuse=None):\n",
        "    return tf.layers.conv2d(inputs=inputs, filters=filters, kernel_size=kernel_size, strides=strides, padding=padding, activation=activation,\n",
        "                kernel_initializer=tf.truncated_normal_initializer(stddev=0.1), bias_initializer=tf.constant_initializer(0.1), name=name, reuse=reuse)\n",
        "                \n",
        "def build_cnn(input_image=None, image_size=32, n_colors=3, activation_function=tf.nn.relu, reuse=None, name='VGG_NET_CNN'):\n",
        "    # VGG_NET 32       # [samples, W, H, colors]\n",
        "    with tf.variable_scope(name, reuse=reuse): \n",
        "        input_image = tf.reshape(input_image, shape=[-1, image_size, image_size, n_colors], name='Reshape_inputs')\n",
        "        # layer_1   # 4个3*3*32\n",
        "        \n",
        "        h_conv1_1 = my_conv2d(input_image, filters=32, kernel_size=(3,3), activation=activation_function, name='conv1_1')\n",
        "        h_conv1_2 = my_conv2d(h_conv1_1, filters=32, kernel_size=(3,3), activation=activation_function, name='conv1_2')\n",
        "        h_conv1_3 = my_conv2d(h_conv1_2, filters=32, kernel_size=(3,3), activation=activation_function, name='conv1_3')\n",
        "        h_conv1_4 = my_conv2d(h_conv1_3, filters=32, kernel_size=(3,3), activation=activation_function, name='conv1_4')\n",
        "        h_pool1 = tf.layers.max_pooling2d(h_conv1_4, pool_size=(2,2), strides=(2,2), padding='same', name='max_pooling_1')    # shape is (None, 16, 16, 32)\n",
        "\n",
        "        # layer_2\n",
        "        h_conv2_1 = my_conv2d(h_pool1, filters=64, kernel_size=(3,3), activation=activation_function, name='conv2_1')\n",
        "        h_conv2_2 = my_conv2d(h_conv2_1, filters=64, kernel_size=(3,3), activation=activation_function, name='conv2_2')\n",
        "        h_pool2 = tf.layers.max_pooling2d(h_conv2_2, pool_size=(2,2), strides=(2,2), padding='same', name='max_pooling_2')    # shape is (None, 8, 8, 64)\n",
        "\n",
        "        # layer_3\n",
        "        h_conv3_1 = my_conv2d(h_pool2, filters=128, kernel_size=(3,3), activation=activation_function, name='conv3_1')\n",
        "        h_pool3 = tf.layers.max_pooling2d(h_conv3_1, pool_size=(2,2), strides=(2,2), padding='same', name='max_pooling_3')    # shape is (None, 4, 4, 128)\n",
        "\n",
        "    return h_pool3\n",
        "\n",
        "\n",
        "def build_convpool_max(input_image, nb_classes, image_size=32, n_colors=3, \n",
        "        n_timewin=7, dropout_rate=0.5, name='CNN_Max', train=True, reuse=False):\n",
        "    \"\"\"\n",
        "    Builds the complete network with maxpooling layer in time.\n",
        "\n",
        "    :param input_image: list of EEG images (one image per time window)\n",
        "    :param nb_classes: number of classes\n",
        "    :param image_size: size of the input image (assumes a square input)\n",
        "    :param n_colors: number of color channels in the image\n",
        "    :param n_timewin: number of time windows in the snippet\n",
        "    :return: a pointer to the output of last layer\n",
        "    \"\"\"\n",
        "    with tf.name_scope(name):\n",
        "        with tf.name_scope('Parallel_CNNs'):\n",
        "            convnets = []\n",
        "            # Build 7 parallel CNNs with shared weights\n",
        "            for i in range(n_timewin):\n",
        "                if i==0:\n",
        "                    convnet = build_cnn(input_image[i],image_size=image_size,n_colors=n_colors, reuse=reuse)\n",
        "                else:\n",
        "                    convnet = build_cnn(input_image[i],image_size=image_size,n_colors=n_colors, reuse=True)\n",
        "                convnets.append(convnet)    # list contains [None, 4, 4, 128]\n",
        "            convnets = tf.stack(convnets)   # [n_timewin, nSamples, 4, 4, 128]\n",
        "            convnets = tf.transpose(convnets, [1,0,2,3,4]) # [nSamples, n_timewin, 4, 4, 128]\n",
        "        \n",
        "        with tf.variable_scope('Max_pooling_over_flames'):\n",
        "            # convpooling using Max pooling over frames\n",
        "            convnets = tf.reshape(convnets, shape=[ -1, n_timewin, 4*4*128, 1])\n",
        "            convpool = tf.nn.max_pool(convnets, # [nSamples, 1，4*4*128, 1]\n",
        "                ksize=[1, n_timewin, 1, 1], strides=[1, 1, 1, 1], padding='VALID', name='convpool_max')\n",
        "        \n",
        "\n",
        "        convpool_flat = tf.reshape(convpool, [-1, 4*4*128])\n",
        "        h_fc1_drop1 = tf.layers.dropout(convpool_flat, rate=dropout_rate, training=train, name='dropout_1')\n",
        "        # input shape [batch, 4*4*128] output shape [batch, 512]\n",
        "        h_fc1 = tf.layers.dense(h_fc1_drop1, 512, activation=tf.nn.relu, name='fc_relu_512')\n",
        "        # dropout \n",
        "        h_fc1_drop2 = tf.layers.dropout(h_fc1, rate=dropout_rate, training=train, name='dropout_2')\n",
        "        # inputshape [batch, 512] output shape [batch, nb_classes]    # the loss function contains the softmax activation\n",
        "        prediction = tf.layers.dense(h_fc1_drop2, nb_classes, name='fc_softmax')\n",
        "    \n",
        "    return prediction\n",
        "\n",
        "def build_convpool_conv1d(input_image, nb_classes, image_size=32, n_colors=3, \n",
        "        n_timewin=7, dropout_rate=0.5, name='CNN_Conv1d', train=True, reuse=False):\n",
        "    \"\"\"\n",
        "    Builds the complete network with 1D-conv layer to integrate time from sequences of EEG images.\n",
        "\n",
        "    :param input_image: list of EEG images (one image per time window)\n",
        "    :param nb_classes: number of classes\n",
        "    :param image_size: size of the input image (assumes a square input)S\n",
        "    :param n_colors: number of color channels in the image\n",
        "    :param n_timewin: number of time windows in the snippet\n",
        "    :return: a pointer to the output of last layer\n",
        "    \"\"\"\n",
        "    with tf.name_scope(name):\n",
        "        with tf.name_scope('Parallel_CNNs'):\n",
        "            convnets = []\n",
        "            # Build 7 parallel CNNs with shared weights\n",
        "            for i in range(n_timewin):\n",
        "                if i==0:\n",
        "                    convnet = build_cnn(input_image[i],image_size=image_size,n_colors=n_colors, reuse=reuse)\n",
        "                else:\n",
        "                    convnet = build_cnn(input_image[i],image_size=image_size,n_colors=n_colors, reuse=True)\n",
        "                convnets.append(convnet)\n",
        "            convnets = tf.stack(convnets)\n",
        "            convnets = tf.transpose(convnets, [1,0,2,3,4])\n",
        "\n",
        "        with tf.variable_scope('Conv1d_over_flames'):\n",
        "            convnets = tf.reshape(convnets, shape=[ -1, n_timewin, 4*4*128, 1])\n",
        "            convpool = my_conv2d(convnets, filters=64, kernel_size=(3, 4*4*128), strides=(1, 1), padding='valid', activation=tf.nn.relu, name='convpool_conv1d')\n",
        "\n",
        "\n",
        "        with tf.variable_scope('Output_layers'):\n",
        "            convpool_flat = tf.reshape(convpool, [-1, (n_timewin-2)*64])\n",
        "            h_fc1_drop1 = tf.layers.dropout(convpool_flat, rate=dropout_rate, training=train, name='dropout_1')\n",
        "            h_fc1 = tf.layers.dense(h_fc1_drop1, 256, activation=tf.nn.relu, name='fc_relu_256')\n",
        "            h_fc1_drop2 = tf.layers.dropout(h_fc1, rate=dropout_rate, training=train, name='dropout_2')\n",
        "            prediction = tf.layers.dense(h_fc1_drop2, nb_classes, name='fc_softmax')\n",
        "    \n",
        "    return prediction\n",
        "\n",
        "\n",
        "def build_convpool_lstm(input_image, nb_classes, grad_clip=110, image_size=32, n_colors=3, \n",
        "        n_timewin=7, dropout_rate=0.5, num_units=128, batch_size=32, name='CNN_LSTM', train=True, reuse=False):\n",
        "    \"\"\"\n",
        "    Builds the complete network with LSTM layer to integrate time from sequences of EEG images.\n",
        "\n",
        "    :param input_image: list of EEG images (one image per time window)\n",
        "    :param nb_classes: number of classes\n",
        "    :param grad_clip:  the gradient messages are clipped to the given value during\n",
        "                        the backward pass.\n",
        "    :param image_size: size of the input image (assumes a square input)\n",
        "    :param n_colors: number of color channels in the image\n",
        "    :param n_timewin: number of time windows in the snippet\n",
        "    :param num_units: number of units in the LSTMCell\n",
        "    :return: a pointer to the output of last layer\n",
        "    \"\"\"\n",
        "    with tf.name_scope(name):\n",
        "        with tf.name_scope('Parallel_CNNs'):\n",
        "            convnets = []\n",
        "            # Build 7 parallel CNNs with shared weights\n",
        "            for i in range(n_timewin):\n",
        "                if i==0:\n",
        "                    convnet = build_cnn(input_image[i],image_size=image_size,n_colors=n_colors, reuse=reuse)\n",
        "                else:\n",
        "                    convnet = build_cnn(input_image[i],image_size=image_size,n_colors=n_colors, reuse=True)\n",
        "                convnets.append(convnet)\n",
        "            convnets = tf.stack(convnets)\n",
        "            convnets = tf.transpose(convnets, [1,0,2,3,4]) # 调换轴 shape: (nSamples, n_timewin, 4, 4, 128)\n",
        "\n",
        "        with tf.variable_scope('LSTM_layer'):\n",
        "            # (nSamples, n_timewin, 4, 4, 128) ==>  (nSamples, n_timewin, 4*4*128)\n",
        "            convnets = tf.reshape(convnets, shape=[-1, n_timewin, 4*4*128], name='Reshape_for_lstm')\n",
        "            #lstm cell inputs:[batchs, time_steps, 4*4*128]\n",
        "            with tf.variable_scope('LSTM_Cell'):\n",
        "                lstm_cell = tf.contrib.rnn.BasicLSTMCell(num_units=num_units, forget_bias=1.0, state_is_tuple=True)\n",
        "                outputs, final_state = tf.nn.dynamic_rnn(lstm_cell, convnets, dtype=tf.float32, time_major=False)\n",
        "                # outputs.shape is (batch_size, time_steps, num_units)\n",
        "                outputs = tf.transpose(outputs, [1,0,2])        # (time_steps, batch_size, num_units)\n",
        "                outputs = outputs[-1]\n",
        "\n",
        "        with tf.variable_scope('Output_layers'):\n",
        "            h_fc1_drop1 = tf.layers.dropout(outputs, rate=dropout_rate, training=train, name='dropout_1')\n",
        "            h_fc1 = tf.layers.dense(h_fc1_drop1, 256, activation=tf.nn.relu, name='fc_relu_256')\n",
        "            h_fc1_drop2 = tf.layers.dropout(h_fc1, rate=dropout_rate, training=train, name='dropout_2')\n",
        "            prediction = tf.layers.dense(h_fc1_drop2, nb_classes, name='fc_softmax')\n",
        "\n",
        "    return prediction\n",
        "\n",
        "\n",
        "def build_convpool_mix(input_image, nb_classes, grad_clip=110, image_size=32, n_colors=3, \n",
        "        n_timewin=7, dropout_rate=0.5, num_units=128, batch_size=32, name='CNN_Mix', train=True, reuse=False):\n",
        "    \"\"\"\n",
        "    Builds the complete network with LSTM and 1D-conv layers combined\n",
        "\n",
        "    :param input_image: list of EEG images (one image per time window)\n",
        "    :param nb_classes: number of classes\n",
        "    :param grad_clip:  the gradient messages are clipped to the given value during\n",
        "                        the backward pass.\n",
        "    :param imsize: size of the input image (assumes a square input)\n",
        "    :param n_colors: number of color channels in the image\n",
        "    :param n_timewin: number of time windows in the snippet\n",
        "    :return: a pointer to the output of last layer\n",
        "    \"\"\"\n",
        "    with tf.name_scope(name):\n",
        "        with tf.name_scope('Parallel_CNNs'):\n",
        "            convnets = []\n",
        "            # Build 7 parallel CNNs with shared weights\n",
        "            for i in range(n_timewin):\n",
        "                if i==0:\n",
        "                    convnet = build_cnn(input_image[i],image_size=image_size,n_colors=n_colors, reuse=reuse)\n",
        "                else:\n",
        "                    convnet = build_cnn(input_image[i],image_size=image_size,n_colors=n_colors, reuse=True)\n",
        "                convnets.append(convnet)\n",
        "            convnets = tf.stack(convnets)\n",
        "            convnets = tf.transpose(convnets, [1,0,2,3,4])\n",
        "\n",
        "        with tf.variable_scope('Conv1d_over_flames'):\n",
        "            convpool = tf.reshape(convnets, shape=[ -1, n_timewin, 4*4*128, 1])\n",
        "            convpool = my_conv2d(convpool, filters=64, kernel_size=(3, 4*4*128), strides=(1, 1), padding='valid', activation=tf.nn.relu, name='convpool_conv1d')\n",
        "            conv1d_out = tf.reshape(convpool, [-1, (n_timewin-2)*64])\n",
        "\n",
        "        with tf.variable_scope('LSTM_layer'):\n",
        "            # (nSamples, n_timewin, 4, 4, 128) ==>  (nSamples, n_timewin, 4*4*128)\n",
        "            convnets = tf.reshape(convnets, shape=[-1, n_timewin, 4*4*128], name='Reshape_for_lstm')\n",
        "            #lstm cell inputs:[batchs, time_steps, 4*4*128]\n",
        "            with tf.variable_scope('LSTM_Cell'):\n",
        "                lstm_cell = tf.contrib.rnn.BasicLSTMCell(num_units=num_units, forget_bias=1.0, state_is_tuple=True)\n",
        "                outputs, final_state = tf.nn.dynamic_rnn(lstm_cell, convnets, dtype=tf.float32, time_major=False)\n",
        "                # outputs.shape is (batch_size, time_steps, num_units)\n",
        "                outputs = tf.transpose(outputs, [1,0,2])\n",
        "                lstm_out = outputs[-1]\n",
        "\n",
        "        with tf.variable_scope('Output_layers'):\n",
        "            dense_in = tf.concat((conv1d_out, lstm_out), axis=1, name='concat_conv1d_lstm')    # shape [batch, (n_timewin-2)*64+num_units]\n",
        "            h_fc1_drop1 = tf.layers.dropout(dense_in, rate=dropout_rate, training=train, name='dropout_1')\n",
        "            h_fc1 = tf.layers.dense(h_fc1_drop1, 512, activation=tf.nn.relu, name='fc_relu_512')\n",
        "            h_fc1_drop2 = tf.layers.dropout(h_fc1, rate=dropout_rate, training=train, name='dropout_2')\n",
        "            prediction = tf.layers.dense(h_fc1_drop2, nb_classes, name='fc_softmax')\n",
        "\n",
        "    return prediction\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10F_KOUmjRYt",
        "colab_type": "text"
      },
      "source": [
        "utils below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlhGnt7tjTL8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import math as m\n",
        "import os\n",
        "import scipy.io\n",
        "from scipy.interpolate import griddata\n",
        "from sklearn.preprocessing import scale\n",
        "from functools import reduce\n",
        "\n",
        "\n",
        "def cart2sph(x, y, z):\n",
        "    \"\"\"\n",
        "    Transform Cartesian coordinates to spherical\n",
        "    :param x: X coordinate\n",
        "    :param y: Y coordinate\n",
        "    :param z: Z coordinate\n",
        "    :return: radius, elevation, azimuth\n",
        "    \"\"\"\n",
        "    x2_y2 = x**2 + y**2\n",
        "    r = m.sqrt(x2_y2 + z**2)                    # r     tant^(-1)(y/x)\n",
        "    elev = m.atan2(z, m.sqrt(x2_y2))            # Elevation\n",
        "    az = m.atan2(y, x)                          # Azimuth\n",
        "    return r, elev, az\n",
        "\n",
        "\n",
        "def pol2cart(theta, rho):\n",
        "    \"\"\"\n",
        "    Transform polar coordinates to Cartesian \n",
        "    :param theta: angle value\n",
        "    :param rho: radius value\n",
        "    :return: X, Y\n",
        "    \"\"\"\n",
        "    return rho * m.cos(theta), rho * m.sin(theta)\n",
        "\n",
        "def azim_proj(pos):\n",
        "    \"\"\"\n",
        "    Computes the Azimuthal Equidistant Projection of input point in 3D Cartesian Coordinates.\n",
        "    Imagine a plane being placed against (tangent to) a globe. If\n",
        "    a light source inside the globe projects the graticule onto\n",
        "    the plane the result would be a planar, or azimuthal, map\n",
        "    projection.\n",
        "\n",
        "    :param pos: position in 3D Cartesian coordinates    [x, y, z]\n",
        "    :return: projected coordinates using Azimuthal Equidistant Projection\n",
        "    \"\"\"\n",
        "    [r, elev, az] = cart2sph(pos[0], pos[1], pos[2])\n",
        "    return pol2cart(az, m.pi / 2 - elev)\n",
        "\n",
        "\n",
        "def load_data(data_file, classification=True):\n",
        "    \"\"\"                                               \n",
        "    Loads the data from MAT file. MAT file should contain two\n",
        "    variables. 'featMat' which contains the feature matrix in the\n",
        "    shape of [samples, features] and 'labels' which contains the output\n",
        "    labels as a vector. Label numbers are assumed to start from 1.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    data_file: str\n",
        "                        # load data from .mat [samples, (features:labels)]\n",
        "    Returns \n",
        "    -------\n",
        "    data: array_like\n",
        "    \"\"\"\n",
        "    print(\"Loading data from %s\" % (data_file))\n",
        "    dataMat = scipy.io.loadmat(data_file, mat_dtype=True)\n",
        "    print(\"Data loading complete. Shape is %r\" % (dataMat['features'].shape,))\n",
        "    if classification:\n",
        "        return dataMat['features'][:, :-1], dataMat['features'][:, -1] - 1\n",
        "    else:\n",
        "        return dataMat['features'][:, :-1], dataMat['features'][:, -1]\n",
        "\n",
        "\n",
        "def reformatInput(data, labels, indices):\n",
        "    \"\"\"\n",
        "    Receives the indices for train and test datasets.\n",
        "    param indices: tuple of (train, test) index numbers\n",
        "    Outputs the train, validation, and test data and label datasets.\n",
        "    \"\"\"\n",
        "    np.random.shuffle(indices[0])\n",
        "    np.random.shuffle(indices[0])\n",
        "    trainIndices = indices[0][len(indices[1]):]\n",
        "    validIndices = indices[0][:len(indices[1])]\n",
        "    testIndices = indices[1]\n",
        "\n",
        "    if data.ndim == 4:\n",
        "        return [(data[trainIndices], np.squeeze(labels[trainIndices]).astype(np.int32)),\n",
        "                (data[validIndices], np.squeeze(labels[validIndices]).astype(np.int32)),\n",
        "                (data[testIndices], np.squeeze(labels[testIndices]).astype(np.int32))]\n",
        "    elif data.ndim == 5:\n",
        "        return [(data[:, trainIndices], np.squeeze(labels[trainIndices]).astype(np.int32)),\n",
        "                (data[:, validIndices], np.squeeze(labels[validIndices]).astype(np.int32)),\n",
        "                (data[:, testIndices], np.squeeze(labels[testIndices]).astype(np.int32))]\n",
        "\n",
        "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
        "    \"\"\"\n",
        "    Iterates over the samples returing batches of size batchsize.\n",
        "    :param inputs: input data array. It should be a 4D numpy array for images [n_samples, n_colors, W, H] and 5D numpy\n",
        "                    array if working with sequence of images [n_timewindows, n_samples, n_colors, W, H].\n",
        "    :param targets: vector of target labels.\n",
        "    :param batchsize: Batch size\n",
        "    :param shuffle: Flag whether to shuffle the samples before iterating or not.\n",
        "    :return: images and labels for a batch\n",
        "    \"\"\"\n",
        "    if inputs.ndim == 4:\n",
        "        input_len = inputs.shape[0]\n",
        "    elif inputs.ndim == 5:\n",
        "        input_len = inputs.shape[1]\n",
        "    assert input_len == len(targets)\n",
        "\n",
        "    if shuffle:\n",
        "        indices = np.arange(input_len)  \n",
        "        np.random.shuffle(indices) \n",
        "    for start_idx in range(0, input_len, batchsize):\n",
        "        if shuffle:\n",
        "            excerpt = indices[start_idx:start_idx + batchsize]\n",
        "        else:\n",
        "            excerpt = slice(start_idx, start_idx + batchsize)\n",
        "        if inputs.ndim == 4:\n",
        "            yield inputs[excerpt], targets[excerpt]\n",
        "        elif inputs.ndim == 5:\n",
        "            yield inputs[:, excerpt], targets[excerpt]\n",
        "\n",
        "\n",
        "def gen_images(locs, features, n_gridpoints=32, normalize=True, edgeless=False):\n",
        "    \"\"\"\n",
        "    Generates EEG images given electrode locations in 2D space and multiple feature values for each electrode\n",
        "    :param locs: An array with shape [n_electrodes, 2] containing X, Y\n",
        "                        coordinates for each electrode.\n",
        "    :param features: Feature matrix as [n_samples, n_features]\n",
        "                                Features are as columns.\n",
        "                                Features corresponding to each frequency band are concatenated.\n",
        "                                (alpha1, alpha2, ..., beta1, beta2,...)\n",
        "    :param n_gridpoints: Number of pixels in the output images\n",
        "    :param normalize:   Flag for whether to normalize each band over all samples\n",
        "    :param edgeless:    If True generates edgeless images by adding artificial channels\n",
        "                        at four corners of the image with value = 0 (default=False).\n",
        "    :return:            Tensor of size [samples, colors, W, H] containing generated\n",
        "                        images.\n",
        "    \"\"\"\n",
        "    feat_array_temp = []\n",
        "    nElectrodes = locs.shape[0]     # Number of electrodes\n",
        "    # Test whether the feature vector length is divisible by number of electrodes\n",
        "    assert features.shape[1] % nElectrodes == 0\n",
        "    n_colors = features.shape[1] // nElectrodes\n",
        "    for c in range(n_colors):\n",
        "        feat_array_temp.append(features[:, c * nElectrodes : nElectrodes * (c+1)])  # features.shape为[samples, 3*nElectrodes]\n",
        "\n",
        "    nSamples = features.shape[0]    # sample number 2670\n",
        "    # Interpolate the values        # print(np.mgrid[-1:1:5j]) get [-1.  -0.5  0.   0.5  1. ]\n",
        "    grid_x, grid_y = np.mgrid[\n",
        "                     min(locs[:, 0]):max(locs[:, 0]):n_gridpoints*1j,\n",
        "                     min(locs[:, 1]):max(locs[:, 1]):n_gridpoints*1j\n",
        "                     ]\n",
        "    \n",
        "    temp_interp = []\n",
        "    for c in range(n_colors):\n",
        "        temp_interp.append(np.zeros([nSamples, n_gridpoints, n_gridpoints]))\n",
        "\n",
        "    \n",
        "    # Generate edgeless images\n",
        "    if edgeless:\n",
        "        min_x, min_y = np.min(locs, axis=0)\n",
        "        max_x, max_y = np.max(locs, axis=0)\n",
        "        locs = np.append(locs, np.array([[min_x, min_y], [min_x, max_y],[max_x, min_y],[max_x, max_y]]),axis=0)\n",
        "        for c in range(n_colors):\n",
        "            feat_array_temp[c] = np.append(feat_array_temp[c], np.zeros((nSamples, 4)), axis=1)\n",
        "    \n",
        "    # Interpolating\n",
        "    for i in range(nSamples):\n",
        "        for c in range(n_colors):\n",
        "            temp_interp[c][i, :, :] = griddata(locs, feat_array_temp[c][i, :], (grid_x, grid_y),    # cubic\n",
        "                                    method='cubic', fill_value=np.nan)\n",
        "    \n",
        "    # Normalizing\n",
        "    for c in range(n_colors):\n",
        "        if normalize:\n",
        "            temp_interp[c][~np.isnan(temp_interp[c])] = \\\n",
        "                scale(temp_interp[c][~np.isnan(temp_interp[c])])\n",
        "        \n",
        "        temp_interp[c] = np.nan_to_num(temp_interp[c])\n",
        "        \n",
        "    temp_interp = np.swapaxes(np.asarray(temp_interp), 0, 1)     # swap axes to have [samples, colors, W, H] # WH xy\n",
        "    temp_interp = np.swapaxes(temp_interp, 1, 2)\n",
        "    temp_interp = np.swapaxes(temp_interp, 2, 3)    # [samples, W, H，colors]\n",
        "    return temp_interp\n",
        "\n",
        "\n",
        "\n",
        "def load_or_generate_images(file_path, average_image=3):\n",
        "    \"\"\"\n",
        "    Generates EEG images\n",
        "    :param average_image: average_image 1 for CNN model only, 2 for multi-frame model \n",
        "                        sucn as lstm, 3 for both.\n",
        "\n",
        "    :return:            Tensor of size [window_size, samples, W, H, channel] containing generated\n",
        "                        images.\n",
        "    \"\"\"\n",
        "    print('-'*100)\n",
        "    print('Loading original data...')\n",
        "    locs = scipy.io.loadmat('/content/SampleData/Neuroscan_locs_orig.mat')\n",
        "    locs_3d = locs['A']\n",
        "    locs_2d = []\n",
        "    # Convert to 2D\n",
        "    for e in locs_3d:\n",
        "        locs_2d.append(azim_proj(e))\n",
        "\n",
        "    # Class labels should start from 0\n",
        "    feats, labels = load_data('/content/SampleData/FeatureMat_timeWin.mat')   # 2670*1344 和 2670*1\n",
        "    \n",
        "\n",
        "    if average_image == 1:   # for CNN only\n",
        "        if os.path.exists(file_path + 'images_average.mat'):\n",
        "            images_average = scipy.io.loadmat(file_path + 'images_average.mat')['images_average']\n",
        "            print('\\n')\n",
        "            print('Load images_average done!')\n",
        "        else:\n",
        "            print('\\n')\n",
        "            print('Generating average images over time windows...')\n",
        "            # Find the average response over time windows\n",
        "            for i in range(7):\n",
        "                if i == 0:\n",
        "                    temp  = feats[:, i*192:(i+1)*192]    # each window contains 64*3=192 data\n",
        "                else:\n",
        "                    temp += feats[:, i*192:(i+1)*192]\n",
        "            av_feats = temp / 7\n",
        "            images_average = gen_images(np.array(locs_2d), av_feats, 32, normalize=False)\n",
        "            scipy.io.savemat( file_path+'images_average.mat', {'images_average':images_average})\n",
        "            print('Saving images_average done!')\n",
        "        \n",
        "        del feats\n",
        "        images_average = images_average[np.newaxis,:]\n",
        "        print('The shape of images_average.shape', images_average.shape)\n",
        "        return images_average, labels\n",
        "    \n",
        "    elif average_image == 2:    # for mulit-frame model such as LSTM\n",
        "        if os.path.exists(file_path + 'images_timewin.mat'):\n",
        "            images_timewin = scipy.io.loadmat(file_path + 'images_timewin.mat')['images_timewin']\n",
        "            print('\\n')    \n",
        "            print('Load images_timewin done!')\n",
        "        else:\n",
        "            print('Generating images for all time windows...')\n",
        "            images_timewin = np.array([\n",
        "                gen_images(\n",
        "                    np.array(locs_2d),\n",
        "                    feats[:, i*192:(i+1)*192], 32, normalize=False) for i in range(feats.shape[1]//192)\n",
        "                ])\n",
        "            scipy.io.savemat(file_path + 'images_timewin.mat', {'images_timewin':images_timewin})\n",
        "            print('Saving images for all time windows done!')\n",
        "        \n",
        "        del feats\n",
        "        print('The shape of images_timewin is', images_timewin.shape)   # (7, 2670, 32, 32, 3)\n",
        "        return images_timewin, labels\n",
        "    \n",
        "    else:\n",
        "        if os.path.exists(file_path + 'images_average.mat'):\n",
        "            images_average = scipy.io.loadmat(file_path + 'images_average.mat')['images_average']\n",
        "            print('\\n')\n",
        "            print('Load images_average done!')\n",
        "        else:\n",
        "            print('\\n')\n",
        "            print('Generating average images over time windows...')\n",
        "            # Find the average response over time windows\n",
        "            for i in range(7):\n",
        "                if i == 0:\n",
        "                    temp = feats[:, i*192:(i+1)*192]\n",
        "                else:\n",
        "                    temp += feats[:, i*192:(i+1)*192]\n",
        "            av_feats = temp / 7\n",
        "            images_average = gen_images(np.array(locs_2d), av_feats, 32, normalize=False)\n",
        "            scipy.io.savemat( file_path+'images_average.mat', {'images_average':images_average})\n",
        "            print('Saving images_average done!')\n",
        "\n",
        "        if os.path.exists(file_path + 'images_timewin.mat'):\n",
        "            images_timewin = scipy.io.loadmat(file_path + 'images_timewin.mat')['images_timewin']\n",
        "            print('\\n')    \n",
        "            print('Load images_timewin done!')\n",
        "        else:\n",
        "            print('\\n')\n",
        "            print('Generating images for all time windows...')\n",
        "            images_timewin = np.array([\n",
        "                gen_images(\n",
        "                    np.array(locs_2d),\n",
        "                    feats[:, i*192:(i+1)*192], 32, normalize=False) for i in range(feats.shape[1]//192)\n",
        "                ])\n",
        "            scipy.io.savemat(file_path + 'images_timewin.mat', {'images_timewin':images_timewin})\n",
        "            print('Saving images for all time windows done!')\n",
        "\n",
        "        del feats\n",
        "        images_average = images_average[np.newaxis,:]\n",
        "        print('The shape of labels.shape', labels.shape)\n",
        "        print('The shape of images_average.shape', images_average.shape)    # (1, 2670, 32, 32, 3)\n",
        "        print('The shape of images_timewin is', images_timewin.shape)   # (7, 2670, 32, 32, 3)\n",
        "        return images_average, images_timewin, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-LFcqPwlB1E",
        "colab_type": "text"
      },
      "source": [
        "train below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXNdIzlClD6L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f07a22c0-73b6-466a-8c8e-2aa95fd6ad3f"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import scipy.io\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "#from utils import reformatInput, load_or_generate_images, iterate_minibatches\n",
        "\n",
        "#from model import build_cnn, build_convpool_conv1d, build_convpool_lstm, build_convpool_mix\n",
        "\n",
        "\n",
        "timestamp = datetime.datetime.now().strftime('%Y-%m-%d.%H.%M')\n",
        "log_path = os.path.join(\"runs\", timestamp)\n",
        "\n",
        "\n",
        "model_type = '1dconv'      # ['1dconv', 'maxpool', 'lstm', 'mix', 'cnn']\n",
        "log_path = log_path + '_' + model_type\n",
        "\n",
        "batch_size = 32\n",
        "dropout_rate = 0.5\n",
        "\n",
        "input_shape = [32, 32, 3]   # 1024\n",
        "nb_class = 4\n",
        "n_colors = 3\n",
        "\n",
        "# whether to train cnn first, and load its weight for multi-frame model\n",
        "reuse_cnn_flag = False\n",
        "\n",
        "# learning_rate for different models\n",
        "lrs = {\n",
        "    'cnn': 1e-3,\n",
        "    '1dconv': 1e-4,\n",
        "    'lstm': 1e-4,\n",
        "    'mix': 1e-4,\n",
        "}\n",
        "\n",
        "weight_decay = 1e-4\n",
        "learning_rate = lrs[model_type] / 32 * batch_size\n",
        "optimizer = tf.train.AdamOptimizer\n",
        "\n",
        "num_epochs = 60\n",
        "\n",
        "def train(images, labels, fold, model_type, batch_size, num_epochs, subj_id=0, reuse_cnn=False, \n",
        "    dropout_rate=dropout_rate ,learning_rate_default=1e-3, Optimizer=tf.train.AdamOptimizer, log_path=log_path):\n",
        "    \"\"\"\n",
        "    A sample training function which loops over the training set and evaluates the network\n",
        "    on the validation set after each epoch. Evaluates the network on the training set\n",
        "    whenever the\n",
        "    :param images: input images\n",
        "    :param labels: target labels\n",
        "    :param fold: tuple of (train, test) index numbers\n",
        "    :param model_type: model type ('cnn', '1dconv', 'lstm', 'mix')\n",
        "    :param batch_size: batch size for training\n",
        "    :param num_epochs: number of epochs of dataset to go over for training\n",
        "    :param subj_id: the id of fold for storing log and the best model\n",
        "    :param reuse_cnn: whether to train cnn first, and load its weight for multi-frame model\n",
        "    :return: none\n",
        "    \"\"\"\n",
        "\n",
        "    with tf.name_scope('Inputs'):\n",
        "        input_var = tf.placeholder(tf.float32, [None, None, 32, 32, n_colors], name='X_inputs')\n",
        "        target_var = tf.placeholder(tf.int64, [None], name='y_inputs')\n",
        "        tf_is_training = tf.placeholder(tf.bool, None, name='is_training')\n",
        "\n",
        "    num_classes = len(np.unique(labels))\n",
        "    (X_train, y_train), (X_val, y_val), (X_test, y_test) = reformatInput(images, labels, fold)\n",
        "\n",
        "\n",
        "    print('Train set label and proportion:\\t', np.unique(y_train, return_counts=True))\n",
        "    print('Val   set label and proportion:\\t', np.unique(y_val, return_counts=True))\n",
        "    print('Test  set label and proportion:\\t', np.unique(y_test, return_counts=True))\n",
        "\n",
        "    print('The shape of X_trian:\\t', X_train.shape)\n",
        "    print('The shape of X_val:\\t', X_val.shape)\n",
        "    print('The shape of X_test:\\t', X_test.shape)\n",
        "    \n",
        "\n",
        "    print(\"Building model and compiling functions...\")\n",
        "    if model_type == '1dconv':\n",
        "        network = build_convpool_conv1d(input_var, num_classes, train=tf_is_training, \n",
        "                            dropout_rate=dropout_rate, name='CNN_Conv1d'+'_sbj'+str(subj_id))\n",
        "    elif model_type == 'lstm':\n",
        "        network = build_convpool_lstm(input_var, num_classes, 100, train=tf_is_training, \n",
        "                            dropout_rate=dropout_rate, name='CNN_LSTM'+'_sbj'+str(subj_id))\n",
        "    elif model_type == 'mix':\n",
        "        network = build_convpool_mix(input_var, num_classes, 100, train=tf_is_training, \n",
        "                            dropout_rate=dropout_rate, name='CNN_Mix'+'_sbj'+str(subj_id))\n",
        "    elif model_type == 'cnn':\n",
        "        with tf.name_scope(name='CNN_layer'+'_fold'+str(subj_id)):\n",
        "            network = build_cnn(input_var)  # output shape [None, 4, 4, 128]\n",
        "            convpool_flat = tf.reshape(network, [-1, 4*4*128])\n",
        "            h_fc1_drop1 = tf.layers.dropout(convpool_flat, rate=dropout_rate, training=tf_is_training, name='dropout_1')\n",
        "            h_fc1 = tf.layers.dense(h_fc1_drop1, 256, activation=tf.nn.relu, name='fc_relu_256')\n",
        "            h_fc1_drop2 = tf.layers.dropout(h_fc1, rate=dropout_rate, training=tf_is_training, name='dropout_2')\n",
        "            network = tf.layers.dense(h_fc1_drop2, num_classes, name='fc_softmax')\n",
        "            # the loss function contains the softmax activation\n",
        "    else:\n",
        "        raise ValueError(\"Model not supported ['1dconv', 'maxpool', 'lstm', 'mix', 'cnn']\")\n",
        "\n",
        "    Train_vars = tf.trainable_variables()\n",
        "\n",
        "    prediction = network\n",
        "\n",
        "    with tf.name_scope('Loss'):\n",
        "        l2_loss = tf.add_n([tf.nn.l2_loss(v) for v in Train_vars if 'kernel' in v.name])\n",
        "        ce_loss = tf.losses.sparse_softmax_cross_entropy(labels=target_var, logits=prediction)\n",
        "        _loss = ce_loss + weight_decay*l2_loss\n",
        "\n",
        "    # decay_steps learning rate decay\n",
        "    decay_steps = 3*(len(y_train)//batch_size)   # len(X_train)//batch_size  the training steps for an epcoh\n",
        "    with tf.name_scope('Optimizer'):\n",
        "        # learning_rate = learning_rate_default * Decay_rate^(global_steps/decay_steps)\n",
        "        global_steps = tf.Variable(0, name=\"global_step\", trainable=False)\n",
        "        learning_rate = tf.train.exponential_decay(     # learning rate decay\n",
        "            learning_rate_default,  # Base learning rate.\n",
        "            global_steps,\n",
        "            decay_steps,\n",
        "            0.95,  # Decay rate.\n",
        "            staircase=True)\n",
        "        optimizer = Optimizer(learning_rate)    # GradientDescentOptimizer  AdamOptimizer\n",
        "        train_op = optimizer.minimize(_loss, global_step=global_steps, var_list=Train_vars)\n",
        "\n",
        "    with tf.name_scope('Accuracy'):\n",
        "        prediction = tf.argmax(prediction, axis=1)\n",
        "        correct_prediction = tf.equal(prediction, target_var)\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
        "\n",
        "    # Output directory for models and summaries\n",
        "    # choose different path for different model and subject\n",
        "    out_dir = os.path.abspath(os.path.join(os.path.curdir, log_path, (model_type+'_'+str(subj_id)) ))\n",
        "    print(\"Writing to {}\\n\".format(out_dir))\n",
        "\n",
        "    # Summaries for loss, accuracy and learning_rate\n",
        "    loss_summary = tf.summary.scalar('loss', _loss)\n",
        "    acc_summary = tf.summary.scalar('train_acc', accuracy)\n",
        "    lr_summary = tf.summary.scalar('learning_rate', learning_rate)\n",
        "\n",
        "    # Train Summaries\n",
        "    train_summary_op = tf.summary.merge([loss_summary, acc_summary, lr_summary])\n",
        "    train_summary_dir = os.path.join(out_dir, \"summaries\", \"train\")\n",
        "    train_summary_writer = tf.summary.FileWriter(train_summary_dir, tf.get_default_graph())\n",
        "\n",
        "    # Dev summaries\n",
        "    dev_summary_op = tf.summary.merge([loss_summary, acc_summary])\n",
        "    dev_summary_dir = os.path.join(out_dir, \"summaries\", \"dev\")\n",
        "    dev_summary_writer = tf.summary.FileWriter(dev_summary_dir, tf.get_default_graph())\n",
        "\n",
        "    # Test summaries\n",
        "    test_summary_op = tf.summary.merge([loss_summary, acc_summary])\n",
        "    test_summary_dir = os.path.join(out_dir, \"summaries\", \"test\")\n",
        "    test_summary_writer = tf.summary.FileWriter(test_summary_dir, tf.get_default_graph())\n",
        "\n",
        "\n",
        "    # Checkpoint directory. Tensorflow assumes this directory already exists so we need to create it\n",
        "    checkpoint_dir = os.path.abspath(os.path.join(out_dir, \"checkpoints\"))\n",
        "    checkpoint_prefix = os.path.join(checkpoint_dir, model_type)\n",
        "    if not os.path.exists(checkpoint_dir):\n",
        "        os.makedirs(checkpoint_dir)\n",
        "\n",
        "\n",
        "    if model_type != 'cnn' and reuse_cnn:\n",
        "        # saver for reuse the CNN weight\n",
        "        reuse_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='VGG_NET_CNN')\n",
        "        original_saver = tf.train.Saver(reuse_vars)         # Pass the variables as a list\n",
        "\n",
        "    saver = tf.train.Saver(tf.global_variables(), max_to_keep=1)\n",
        "\n",
        "    print(\"Starting training...\")\n",
        "    total_start_time = time.time()\n",
        "    best_validation_accu = 0\n",
        "\n",
        "    init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
        "    with tf.Session() as sess:\n",
        "        sess.run(init_op)\n",
        "        if model_type != 'cnn' and reuse_cnn:\n",
        "            cnn_model_path = os.path.abspath(\n",
        "                                os.path.join(\n",
        "                                    os.path.curdir, log_path, ('cnn_'+str(subj_id)), 'checkpoints' ))\n",
        "            cnn_model_path = tf.train.latest_checkpoint(cnn_model_path)\n",
        "            print('-'*20)\n",
        "            print('Load cnn model weight for multi-frame model from {}'.format(cnn_model_path))\n",
        "            original_saver.restore(sess, cnn_model_path)\n",
        "\n",
        "        stop_count = 0  # count for earlystopping\n",
        "        for epoch in range(num_epochs):\n",
        "            print('-'*50)\n",
        "            # Train set\n",
        "            train_err = train_acc = train_batches = 0\n",
        "            start_time = time.time()\n",
        "            for batch in iterate_minibatches(X_train, y_train, batch_size, shuffle=False):\n",
        "                inputs, targets = batch\n",
        "                summary, _, pred, loss, acc = sess.run([train_summary_op, train_op, prediction, _loss, accuracy], \n",
        "                    {input_var: inputs, target_var: targets, tf_is_training: True})\n",
        "                train_acc += acc\n",
        "                train_err += loss\n",
        "                train_batches += 1\n",
        "                train_summary_writer.add_summary(summary, sess.run(global_steps))\n",
        "\n",
        "            av_train_err = train_err / train_batches\n",
        "            av_train_acc = train_acc / train_batches\n",
        "\n",
        "            # Val set\n",
        "            summary, pred, av_val_err, av_val_acc = sess.run([dev_summary_op, prediction, _loss, accuracy],\n",
        "                    {input_var: X_val, target_var: y_val, tf_is_training: False})\n",
        "            dev_summary_writer.add_summary(summary, sess.run(global_steps))\n",
        "\n",
        "            \n",
        "            print(\"Epoch {} of {} took {:.3f}s\".format(\n",
        "                epoch + 1, num_epochs, time.time() - start_time))\n",
        "            \n",
        "            fmt_str = \"Train \\tEpoch [{:d}/{:d}]  train_Loss: {:.4f}\\ttrain_Acc: {:.2f}\"\n",
        "            print_str = fmt_str.format(epoch + 1, num_epochs, av_train_err, av_train_acc*100)\n",
        "            print(print_str)\n",
        "\n",
        "            fmt_str = \"Val \\tEpoch [{:d}/{:d}]  val_Loss: {:.4f}\\tval_Acc: {:.2f}\"\n",
        "            print_str = fmt_str.format(epoch + 1, num_epochs, av_val_err, av_val_acc*100)\n",
        "            print(print_str)\n",
        "            \n",
        "            # Test set\n",
        "            summary, pred, av_test_err, av_test_acc = sess.run([test_summary_op, prediction, _loss, accuracy],\n",
        "                {input_var: X_test, target_var: y_test, tf_is_training: False})\n",
        "            test_summary_writer.add_summary(summary, sess.run(global_steps))\n",
        "            \n",
        "            fmt_str = \"Test \\tEpoch [{:d}/{:d}]  test_Loss: {:.4f}\\ttest_Acc: {:.2f}\"\n",
        "            print_str = fmt_str.format(epoch + 1, num_epochs, av_test_err, av_test_acc*100)\n",
        "            print(print_str)\n",
        "\n",
        "            if av_val_acc > best_validation_accu:   # early_stoping\n",
        "                stop_count = 0\n",
        "                eraly_stoping_epoch = epoch\n",
        "                best_validation_accu = av_val_acc\n",
        "                test_acc_val = av_test_acc\n",
        "                saver.save(sess, checkpoint_prefix, global_step=sess.run(global_steps))\n",
        "            else:\n",
        "                stop_count += 1\n",
        "                if stop_count >= 10: # stop training if val_acc dose not imporve for over 10 epochs\n",
        "                    break\n",
        "\n",
        "        train_batches = train_acc = 0\n",
        "        for batch in iterate_minibatches(X_train, y_train, batch_size, shuffle=False):\n",
        "            inputs, targets = batch\n",
        "            acc = sess.run(accuracy, {input_var: X_train, target_var: y_train, tf_is_training: False})\n",
        "            train_acc += acc\n",
        "            train_batches += 1\n",
        "\n",
        "        last_train_acc = train_acc / train_batches\n",
        "        \n",
        "        \n",
        "        last_val_acc = av_val_acc\n",
        "        last_test_acc = av_test_acc\n",
        "        print('-'*50)\n",
        "        print('Time in total:', time.time()-total_start_time)\n",
        "        print(\"Best validation accuracy:\\t\\t{:.2f} %\".format(best_validation_accu * 100))\n",
        "        print(\"Test accuracy when got the best validation accuracy:\\t\\t{:.2f} %\".format(test_acc_val * 100))\n",
        "        print('-'*50)\n",
        "        print(\"Last train accuracy:\\t\\t{:.2f} %\".format(last_train_acc * 100))\n",
        "        print(\"Last validation accuracy:\\t\\t{:.2f} %\".format(last_val_acc * 100))\n",
        "        print(\"Last test accuracy:\\t\\t\\t\\t{:.2f} %\".format(last_test_acc * 100))\n",
        "        print('Early Stopping at epoch: {}'.format(eraly_stoping_epoch+1))\n",
        "\n",
        "    train_summary_writer.close()\n",
        "    dev_summary_writer.close()\n",
        "    test_summary_writer.close()\n",
        "    return [last_train_acc, best_validation_accu, test_acc_val, last_val_acc, last_test_acc]\n",
        "\n",
        "\n",
        "\n",
        "def train_all_model(num_epochs=3000):\n",
        "    nums_subject = 13\n",
        "    # Leave-Subject-Out cross validation\n",
        "    subj_nums = np.squeeze(scipy.io.loadmat('/content/SampleData/trials_subNums.mat')['subjectNum'])\n",
        "    fold_pairs = []\n",
        "    for i in np.unique(subj_nums):\n",
        "        ts = subj_nums == i\n",
        "        tr = np.squeeze(np.nonzero(np.bitwise_not(ts)))\n",
        "        ts = np.squeeze(np.nonzero(ts))\n",
        "        np.random.shuffle(tr)\n",
        "        np.random.shuffle(ts)\n",
        "        fold_pairs.append((tr, ts))\n",
        "\n",
        "\n",
        "    images_average, images_timewin, labels = load_or_generate_images(\n",
        "                                                file_path='/content/SampleData/', average_image=3)\n",
        "\n",
        "\n",
        "    print('*'*200)\n",
        "    acc_buf = []\n",
        "    for subj_id in range(nums_subject):\n",
        "        print('-'*100)\n",
        "        \n",
        "        if model_type == 'cnn':\n",
        "            print('The subjects', subj_id, '\\t\\t Training the ' + 'cnn' + ' Model...')\n",
        "            acc_temp = train(images_average, labels, fold_pairs[subj_id], 'cnn', \n",
        "                                batch_size=batch_size, num_epochs=num_epochs, subj_id=subj_id,\n",
        "                                learning_rate_default=lrs['cnn'], Optimizer=optimizer, log_path=log_path)\n",
        "            acc_buf.append(acc_temp)\n",
        "            tf.reset_default_graph()\n",
        "            print('Done!')\n",
        "\n",
        "        else:\n",
        "            # whether to train cnn first, and load its weight for multi-frame model\n",
        "            if reuse_cnn_flag is True:\n",
        "                print('The subjects', subj_id, '\\t\\t Training the ' + 'cnn' + ' Model...')\n",
        "                acc_temp = train(images_average, labels, fold_pairs[subj_id], 'cnn', \n",
        "                                    batch_size=batch_size, num_epochs=num_epochs, subj_id=subj_id,\n",
        "                                    learning_rate_default=lrs['cnn'], Optimizer=optimizer, log_path=log_path)\n",
        "                # acc_buf.append(acc_temp)\n",
        "                tf.reset_default_graph()\n",
        "                print('Done!')\n",
        "        \n",
        "            print('The subjects', subj_id, '\\t\\t Training the ' + model_type + ' Model...')\n",
        "            print('Load the CNN model weight for backbone...')\n",
        "            acc_temp = train(images_timewin, labels, fold_pairs[subj_id], model_type, \n",
        "                            batch_size=batch_size, num_epochs=num_epochs, subj_id=subj_id, reuse_cnn=reuse_cnn_flag, \n",
        "                            learning_rate_default=learning_rate, Optimizer=optimizer, log_path=log_path)\n",
        "                                \n",
        "            acc_buf.append(acc_temp)\n",
        "            tf.reset_default_graph()\n",
        "            print('Done!')\n",
        "        \n",
        "        # return\n",
        "\n",
        "    print('All folds for {} are done!'.format(model_type))\n",
        "    acc_buf = (np.array(acc_buf)).T\n",
        "    acc_mean = np.mean(acc_buf, axis=1).reshape(-1, 1)\n",
        "    acc_buf = np.concatenate([acc_buf, acc_mean], axis=1)\n",
        "    # the last column is the mean of current row\n",
        "    print('Last_train_acc:\\t', acc_buf[0], '\\tmean :', np.mean(acc_buf[0][-1]))\n",
        "    print('Best_val_acc:\\t', acc_buf[1], '\\tmean :', np.mean(acc_buf[1][-1]))\n",
        "    print('Earlystopping_test_acc:\\t', acc_buf[2], '\\tmean :', np.mean(acc_buf[2][-1]))\n",
        "    print('Last_val_acc:\\t', acc_buf[3], '\\tmean :', np.mean(acc_buf[3][-1]))\n",
        "    print('Last_test_acc:\\t', acc_buf[4], '\\tmean :', np.mean(acc_buf[4][-1]))\n",
        "    np.savetxt('./Accuracy_{}.csv'.format(model_type), acc_buf, fmt='%.4f', delimiter=',')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "    np.random.seed(2018)\n",
        "    tf.set_random_seed(2018)\n",
        "\n",
        "    train_all_model(num_epochs=num_epochs)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "Loading original data...\n",
            "Loading data from /content/SampleData/FeatureMat_timeWin.mat\n",
            "Data loading complete. Shape is (2670, 1345)\n",
            "\n",
            "\n",
            "Load images_average done!\n",
            "\n",
            "\n",
            "Load images_timewin done!\n",
            "The shape of labels.shape (2670,)\n",
            "The shape of images_average.shape (1, 2670, 32, 32, 3)\n",
            "The shape of images_timewin is (7, 2670, 32, 32, 3)\n",
            "********************************************************************************************************************************************************************************************************\n",
            "----------------------------------------------------------------------------------------------------\n",
            "The subjects 0 \t\t Training the 1dconv Model...\n",
            "Load the CNN model weight for backbone...\n",
            "Train set label and proportion:\t (array([0, 1, 2, 3], dtype=int32), array([643, 621, 556, 480]))\n",
            "Val   set label and proportion:\t (array([0, 1, 2, 3], dtype=int32), array([57, 46, 37, 45]))\n",
            "Test  set label and proportion:\t (array([0, 1, 2, 3], dtype=int32), array([57, 48, 47, 33]))\n",
            "The shape of X_trian:\t (7, 2300, 32, 32, 3)\n",
            "The shape of X_val:\t (7, 185, 32, 32, 3)\n",
            "The shape of X_test:\t (7, 185, 32, 32, 3)\n",
            "Building model and compiling functions...\n",
            "WARNING:tensorflow:From <ipython-input-1-f54a0a84f387>:5: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv2D` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From <ipython-input-1-f54a0a84f387>:17: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.MaxPooling2D instead.\n",
            "WARNING:tensorflow:From <ipython-input-1-f54a0a84f387>:106: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dropout instead.\n",
            "WARNING:tensorflow:From <ipython-input-1-f54a0a84f387>:107: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/losses/losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Writing to /content/runs/2020-02-05.14.17_1dconv/1dconv_0\n",
            "\n",
            "Starting training...\n",
            "--------------------------------------------------\n",
            "Epoch 1 of 60 took 9.211s\n",
            "Train \tEpoch [1/60]  train_Loss: 4.1082\ttrain_Acc: 31.39\n",
            "Val \tEpoch [1/60]  val_Loss: 1.4693\tval_Acc: 45.41\n",
            "Test \tEpoch [1/60]  test_Loss: 1.5313\ttest_Acc: 42.16\n",
            "--------------------------------------------------\n",
            "Epoch 2 of 60 took 1.906s\n",
            "Train \tEpoch [2/60]  train_Loss: 1.6738\ttrain_Acc: 37.53\n",
            "Val \tEpoch [2/60]  val_Loss: 1.3912\tval_Acc: 50.81\n",
            "Test \tEpoch [2/60]  test_Loss: 1.3703\ttest_Acc: 49.73\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "--------------------------------------------------\n",
            "Epoch 3 of 60 took 1.923s\n",
            "Train \tEpoch [3/60]  train_Loss: 1.5677\ttrain_Acc: 39.90\n",
            "Val \tEpoch [3/60]  val_Loss: 1.3633\tval_Acc: 58.38\n",
            "Test \tEpoch [3/60]  test_Loss: 1.3970\ttest_Acc: 41.62\n",
            "--------------------------------------------------\n",
            "Epoch 4 of 60 took 1.919s\n",
            "Train \tEpoch [4/60]  train_Loss: 1.4858\ttrain_Acc: 44.63\n",
            "Val \tEpoch [4/60]  val_Loss: 1.2636\tval_Acc: 62.70\n",
            "Test \tEpoch [4/60]  test_Loss: 1.4110\ttest_Acc: 52.97\n",
            "--------------------------------------------------\n",
            "Epoch 5 of 60 took 1.968s\n",
            "Train \tEpoch [5/60]  train_Loss: 1.4304\ttrain_Acc: 48.00\n",
            "Val \tEpoch [5/60]  val_Loss: 1.2130\tval_Acc: 63.24\n",
            "Test \tEpoch [5/60]  test_Loss: 1.3392\ttest_Acc: 50.81\n",
            "--------------------------------------------------\n",
            "Epoch 6 of 60 took 1.941s\n",
            "Train \tEpoch [6/60]  train_Loss: 1.3724\ttrain_Acc: 48.98\n",
            "Val \tEpoch [6/60]  val_Loss: 1.1902\tval_Acc: 63.24\n",
            "Test \tEpoch [6/60]  test_Loss: 1.3250\ttest_Acc: 50.81\n",
            "--------------------------------------------------\n",
            "Epoch 7 of 60 took 1.928s\n",
            "Train \tEpoch [7/60]  train_Loss: 1.3013\ttrain_Acc: 52.93\n",
            "Val \tEpoch [7/60]  val_Loss: 1.0993\tval_Acc: 70.27\n",
            "Test \tEpoch [7/60]  test_Loss: 1.2358\ttest_Acc: 48.65\n",
            "--------------------------------------------------\n",
            "Epoch 8 of 60 took 1.918s\n",
            "Train \tEpoch [8/60]  train_Loss: 1.1917\ttrain_Acc: 59.82\n",
            "Val \tEpoch [8/60]  val_Loss: 0.9787\tval_Acc: 74.59\n",
            "Test \tEpoch [8/60]  test_Loss: 1.2895\ttest_Acc: 55.14\n",
            "--------------------------------------------------\n",
            "Epoch 9 of 60 took 1.918s\n",
            "Train \tEpoch [9/60]  train_Loss: 1.1536\ttrain_Acc: 61.87\n",
            "Val \tEpoch [9/60]  val_Loss: 0.9346\tval_Acc: 76.22\n",
            "Test \tEpoch [9/60]  test_Loss: 1.2164\ttest_Acc: 55.14\n",
            "--------------------------------------------------\n",
            "Epoch 10 of 60 took 1.934s\n",
            "Train \tEpoch [10/60]  train_Loss: 1.0736\ttrain_Acc: 65.08\n",
            "Val \tEpoch [10/60]  val_Loss: 0.8770\tval_Acc: 76.22\n",
            "Test \tEpoch [10/60]  test_Loss: 1.3825\ttest_Acc: 56.22\n",
            "--------------------------------------------------\n",
            "Epoch 11 of 60 took 1.922s\n",
            "Train \tEpoch [11/60]  train_Loss: 1.0239\ttrain_Acc: 66.99\n",
            "Val \tEpoch [11/60]  val_Loss: 0.8359\tval_Acc: 78.92\n",
            "Test \tEpoch [11/60]  test_Loss: 1.3197\ttest_Acc: 56.22\n",
            "--------------------------------------------------\n",
            "Epoch 12 of 60 took 1.924s\n",
            "Train \tEpoch [12/60]  train_Loss: 0.9638\ttrain_Acc: 70.60\n",
            "Val \tEpoch [12/60]  val_Loss: 0.7017\tval_Acc: 86.49\n",
            "Test \tEpoch [12/60]  test_Loss: 1.2917\ttest_Acc: 56.76\n",
            "--------------------------------------------------\n",
            "Epoch 13 of 60 took 1.953s\n",
            "Train \tEpoch [13/60]  train_Loss: 0.8953\ttrain_Acc: 73.60\n",
            "Val \tEpoch [13/60]  val_Loss: 0.6912\tval_Acc: 89.19\n",
            "Test \tEpoch [13/60]  test_Loss: 1.4203\ttest_Acc: 55.14\n",
            "--------------------------------------------------\n",
            "Epoch 14 of 60 took 1.947s\n",
            "Train \tEpoch [14/60]  train_Loss: 0.8299\ttrain_Acc: 76.69\n",
            "Val \tEpoch [14/60]  val_Loss: 0.5908\tval_Acc: 90.27\n",
            "Test \tEpoch [14/60]  test_Loss: 1.4480\ttest_Acc: 57.30\n",
            "--------------------------------------------------\n",
            "Epoch 15 of 60 took 1.923s\n",
            "Train \tEpoch [15/60]  train_Loss: 0.7650\ttrain_Acc: 79.55\n",
            "Val \tEpoch [15/60]  val_Loss: 0.5269\tval_Acc: 91.35\n",
            "Test \tEpoch [15/60]  test_Loss: 1.5442\ttest_Acc: 56.76\n",
            "--------------------------------------------------\n",
            "Epoch 16 of 60 took 1.918s\n",
            "Train \tEpoch [16/60]  train_Loss: 0.7266\ttrain_Acc: 81.34\n",
            "Val \tEpoch [16/60]  val_Loss: 0.5029\tval_Acc: 93.51\n",
            "Test \tEpoch [16/60]  test_Loss: 1.4985\ttest_Acc: 57.84\n",
            "--------------------------------------------------\n",
            "Epoch 17 of 60 took 1.923s\n",
            "Train \tEpoch [17/60]  train_Loss: 0.6871\ttrain_Acc: 82.51\n",
            "Val \tEpoch [17/60]  val_Loss: 0.4793\tval_Acc: 93.51\n",
            "Test \tEpoch [17/60]  test_Loss: 1.5157\ttest_Acc: 62.16\n",
            "--------------------------------------------------\n",
            "Epoch 18 of 60 took 1.910s\n",
            "Train \tEpoch [18/60]  train_Loss: 0.6544\ttrain_Acc: 83.95\n",
            "Val \tEpoch [18/60]  val_Loss: 0.4579\tval_Acc: 92.97\n",
            "Test \tEpoch [18/60]  test_Loss: 1.5877\ttest_Acc: 57.84\n",
            "--------------------------------------------------\n",
            "Epoch 19 of 60 took 1.946s\n",
            "Train \tEpoch [19/60]  train_Loss: 0.6148\ttrain_Acc: 84.98\n",
            "Val \tEpoch [19/60]  val_Loss: 0.4225\tval_Acc: 93.51\n",
            "Test \tEpoch [19/60]  test_Loss: 1.6664\ttest_Acc: 57.30\n",
            "--------------------------------------------------\n",
            "Epoch 20 of 60 took 1.916s\n",
            "Train \tEpoch [20/60]  train_Loss: 0.5722\ttrain_Acc: 87.19\n",
            "Val \tEpoch [20/60]  val_Loss: 0.4073\tval_Acc: 94.05\n",
            "Test \tEpoch [20/60]  test_Loss: 1.5618\ttest_Acc: 60.00\n",
            "--------------------------------------------------\n",
            "Epoch 21 of 60 took 1.935s\n",
            "Train \tEpoch [21/60]  train_Loss: 0.5741\ttrain_Acc: 86.74\n",
            "Val \tEpoch [21/60]  val_Loss: 0.3703\tval_Acc: 96.76\n",
            "Test \tEpoch [21/60]  test_Loss: 1.5697\ttest_Acc: 50.27\n",
            "--------------------------------------------------\n",
            "Epoch 22 of 60 took 1.903s\n",
            "Train \tEpoch [22/60]  train_Loss: 0.5490\ttrain_Acc: 88.65\n",
            "Val \tEpoch [22/60]  val_Loss: 0.3786\tval_Acc: 94.59\n",
            "Test \tEpoch [22/60]  test_Loss: 1.7263\ttest_Acc: 58.38\n",
            "--------------------------------------------------\n",
            "Epoch 23 of 60 took 1.920s\n",
            "Train \tEpoch [23/60]  train_Loss: 0.5238\ttrain_Acc: 89.05\n",
            "Val \tEpoch [23/60]  val_Loss: 0.3729\tval_Acc: 94.05\n",
            "Test \tEpoch [23/60]  test_Loss: 1.6591\ttest_Acc: 60.00\n",
            "--------------------------------------------------\n",
            "Epoch 24 of 60 took 1.907s\n",
            "Train \tEpoch [24/60]  train_Loss: 0.4976\ttrain_Acc: 90.37\n",
            "Val \tEpoch [24/60]  val_Loss: 0.3474\tval_Acc: 96.22\n",
            "Test \tEpoch [24/60]  test_Loss: 1.7545\ttest_Acc: 52.97\n",
            "--------------------------------------------------\n",
            "Epoch 25 of 60 took 1.905s\n",
            "Train \tEpoch [25/60]  train_Loss: 0.4870\ttrain_Acc: 90.66\n",
            "Val \tEpoch [25/60]  val_Loss: 0.3329\tval_Acc: 95.68\n",
            "Test \tEpoch [25/60]  test_Loss: 1.4479\ttest_Acc: 57.84\n",
            "--------------------------------------------------\n",
            "Epoch 26 of 60 took 1.916s\n",
            "Train \tEpoch [26/60]  train_Loss: 0.4930\ttrain_Acc: 90.82\n",
            "Val \tEpoch [26/60]  val_Loss: 0.3338\tval_Acc: 95.68\n",
            "Test \tEpoch [26/60]  test_Loss: 1.7944\ttest_Acc: 47.03\n",
            "--------------------------------------------------\n",
            "Epoch 27 of 60 took 1.912s\n",
            "Train \tEpoch [27/60]  train_Loss: 0.4714\ttrain_Acc: 90.05\n",
            "Val \tEpoch [27/60]  val_Loss: 0.3526\tval_Acc: 95.68\n",
            "Test \tEpoch [27/60]  test_Loss: 1.5163\ttest_Acc: 49.73\n",
            "--------------------------------------------------\n",
            "Epoch 28 of 60 took 1.914s\n",
            "Train \tEpoch [28/60]  train_Loss: 0.4582\ttrain_Acc: 90.74\n",
            "Val \tEpoch [28/60]  val_Loss: 0.3646\tval_Acc: 95.68\n",
            "Test \tEpoch [28/60]  test_Loss: 2.0622\ttest_Acc: 49.73\n",
            "--------------------------------------------------\n",
            "Epoch 29 of 60 took 1.932s\n",
            "Train \tEpoch [29/60]  train_Loss: 0.4566\ttrain_Acc: 91.04\n",
            "Val \tEpoch [29/60]  val_Loss: 0.3707\tval_Acc: 92.97\n",
            "Test \tEpoch [29/60]  test_Loss: 1.5154\ttest_Acc: 62.70\n",
            "--------------------------------------------------\n",
            "Epoch 30 of 60 took 1.939s\n",
            "Train \tEpoch [30/60]  train_Loss: 0.4295\ttrain_Acc: 91.65\n",
            "Val \tEpoch [30/60]  val_Loss: 0.3485\tval_Acc: 95.14\n",
            "Test \tEpoch [30/60]  test_Loss: 1.6381\ttest_Acc: 44.32\n",
            "--------------------------------------------------\n",
            "Epoch 31 of 60 took 1.923s\n",
            "Train \tEpoch [31/60]  train_Loss: 0.4054\ttrain_Acc: 92.87\n",
            "Val \tEpoch [31/60]  val_Loss: 0.3093\tval_Acc: 95.68\n",
            "Test \tEpoch [31/60]  test_Loss: 1.7210\ttest_Acc: 55.14\n",
            "--------------------------------------------------\n",
            "Time in total: 125.43714547157288\n",
            "Best validation accuracy:\t\t96.76 %\n",
            "Test accuracy when got the best validation accuracy:\t\t50.27 %\n",
            "--------------------------------------------------\n",
            "Last train accuracy:\t\t96.96 %\n",
            "Last validation accuracy:\t\t95.68 %\n",
            "Last test accuracy:\t\t\t\t55.14 %\n",
            "Early Stopping at epoch: 21\n",
            "Done!\n",
            "----------------------------------------------------------------------------------------------------\n",
            "The subjects 1 \t\t Training the 1dconv Model...\n",
            "Load the CNN model weight for backbone...\n",
            "Train set label and proportion:\t (array([0, 1, 2, 3], dtype=int32), array([633, 603, 537, 473]))\n",
            "Val   set label and proportion:\t (array([0, 1, 2, 3], dtype=int32), array([60, 67, 49, 36]))\n",
            "Test  set label and proportion:\t (array([0, 1, 2, 3], dtype=int32), array([64, 45, 54, 49]))\n",
            "The shape of X_trian:\t (7, 2246, 32, 32, 3)\n",
            "The shape of X_val:\t (7, 212, 32, 32, 3)\n",
            "The shape of X_test:\t (7, 212, 32, 32, 3)\n",
            "Building model and compiling functions...\n",
            "Writing to /content/runs/2020-02-05.14.17_1dconv/1dconv_1\n",
            "\n",
            "Starting training...\n",
            "--------------------------------------------------\n",
            "Epoch 1 of 60 took 3.029s\n",
            "Train \tEpoch [1/60]  train_Loss: 4.3014\ttrain_Acc: 29.55\n",
            "Val \tEpoch [1/60]  val_Loss: 1.6119\tval_Acc: 40.09\n",
            "Test \tEpoch [1/60]  test_Loss: 1.5015\ttest_Acc: 53.77\n",
            "--------------------------------------------------\n",
            "Epoch 2 of 60 took 1.904s\n",
            "Train \tEpoch [2/60]  train_Loss: 1.7443\ttrain_Acc: 31.97\n",
            "Val \tEpoch [2/60]  val_Loss: 1.5175\tval_Acc: 44.81\n",
            "Test \tEpoch [2/60]  test_Loss: 1.4728\ttest_Acc: 54.72\n",
            "--------------------------------------------------\n",
            "Epoch 3 of 60 took 1.919s\n",
            "Train \tEpoch [3/60]  train_Loss: 1.5996\ttrain_Acc: 35.18\n",
            "Val \tEpoch [3/60]  val_Loss: 1.4835\tval_Acc: 57.55\n",
            "Test \tEpoch [3/60]  test_Loss: 1.4905\ttest_Acc: 41.51\n",
            "--------------------------------------------------\n",
            "Epoch 4 of 60 took 1.905s\n",
            "Train \tEpoch [4/60]  train_Loss: 1.5794\ttrain_Acc: 38.13\n",
            "Val \tEpoch [4/60]  val_Loss: 1.4308\tval_Acc: 60.85\n",
            "Test \tEpoch [4/60]  test_Loss: 1.5296\ttest_Acc: 41.98\n",
            "--------------------------------------------------\n",
            "Epoch 5 of 60 took 1.896s\n",
            "Train \tEpoch [5/60]  train_Loss: 1.4674\ttrain_Acc: 44.15\n",
            "Val \tEpoch [5/60]  val_Loss: 1.3222\tval_Acc: 67.92\n",
            "Test \tEpoch [5/60]  test_Loss: 1.3573\ttest_Acc: 44.81\n",
            "--------------------------------------------------\n",
            "Epoch 6 of 60 took 1.928s\n",
            "Train \tEpoch [6/60]  train_Loss: 1.4374\ttrain_Acc: 47.23\n",
            "Val \tEpoch [6/60]  val_Loss: 1.2451\tval_Acc: 68.40\n",
            "Test \tEpoch [6/60]  test_Loss: 1.3976\ttest_Acc: 53.77\n",
            "--------------------------------------------------\n",
            "Epoch 7 of 60 took 1.910s\n",
            "Train \tEpoch [7/60]  train_Loss: 1.3499\ttrain_Acc: 51.95\n",
            "Val \tEpoch [7/60]  val_Loss: 1.2096\tval_Acc: 68.87\n",
            "Test \tEpoch [7/60]  test_Loss: 1.2800\ttest_Acc: 42.92\n",
            "--------------------------------------------------\n",
            "Epoch 8 of 60 took 1.905s\n",
            "Train \tEpoch [8/60]  train_Loss: 1.2483\ttrain_Acc: 55.77\n",
            "Val \tEpoch [8/60]  val_Loss: 1.0254\tval_Acc: 75.94\n",
            "Test \tEpoch [8/60]  test_Loss: 1.2852\ttest_Acc: 50.00\n",
            "--------------------------------------------------\n",
            "Epoch 9 of 60 took 1.916s\n",
            "Train \tEpoch [9/60]  train_Loss: 1.1777\ttrain_Acc: 59.08\n",
            "Val \tEpoch [9/60]  val_Loss: 0.9368\tval_Acc: 80.19\n",
            "Test \tEpoch [9/60]  test_Loss: 1.3521\ttest_Acc: 51.42\n",
            "--------------------------------------------------\n",
            "Epoch 10 of 60 took 1.891s\n",
            "Train \tEpoch [10/60]  train_Loss: 1.0926\ttrain_Acc: 65.30\n",
            "Val \tEpoch [10/60]  val_Loss: 0.8374\tval_Acc: 84.43\n",
            "Test \tEpoch [10/60]  test_Loss: 1.3250\ttest_Acc: 50.00\n",
            "--------------------------------------------------\n",
            "Epoch 11 of 60 took 1.933s\n",
            "Train \tEpoch [11/60]  train_Loss: 1.0186\ttrain_Acc: 68.05\n",
            "Val \tEpoch [11/60]  val_Loss: 0.8274\tval_Acc: 82.55\n",
            "Test \tEpoch [11/60]  test_Loss: 1.3481\ttest_Acc: 45.75\n",
            "--------------------------------------------------\n",
            "Epoch 12 of 60 took 1.890s\n",
            "Train \tEpoch [12/60]  train_Loss: 0.9516\ttrain_Acc: 70.98\n",
            "Val \tEpoch [12/60]  val_Loss: 0.6986\tval_Acc: 86.79\n",
            "Test \tEpoch [12/60]  test_Loss: 1.2318\ttest_Acc: 51.42\n",
            "--------------------------------------------------\n",
            "Epoch 13 of 60 took 1.903s\n",
            "Train \tEpoch [13/60]  train_Loss: 0.8903\ttrain_Acc: 74.21\n",
            "Val \tEpoch [13/60]  val_Loss: 0.6568\tval_Acc: 90.57\n",
            "Test \tEpoch [13/60]  test_Loss: 1.1892\ttest_Acc: 58.96\n",
            "--------------------------------------------------\n",
            "Epoch 14 of 60 took 1.906s\n",
            "Train \tEpoch [14/60]  train_Loss: 0.8208\ttrain_Acc: 76.67\n",
            "Val \tEpoch [14/60]  val_Loss: 0.5899\tval_Acc: 89.15\n",
            "Test \tEpoch [14/60]  test_Loss: 1.2576\ttest_Acc: 58.49\n",
            "--------------------------------------------------\n",
            "Epoch 15 of 60 took 1.952s\n",
            "Train \tEpoch [15/60]  train_Loss: 0.8115\ttrain_Acc: 78.95\n",
            "Val \tEpoch [15/60]  val_Loss: 0.6101\tval_Acc: 84.91\n",
            "Test \tEpoch [15/60]  test_Loss: 0.9318\ttest_Acc: 76.89\n",
            "--------------------------------------------------\n",
            "Epoch 16 of 60 took 1.926s\n",
            "Train \tEpoch [16/60]  train_Loss: 0.7558\ttrain_Acc: 79.39\n",
            "Val \tEpoch [16/60]  val_Loss: 0.5595\tval_Acc: 91.98\n",
            "Test \tEpoch [16/60]  test_Loss: 1.0924\ttest_Acc: 66.51\n",
            "--------------------------------------------------\n",
            "Epoch 17 of 60 took 1.946s\n",
            "Train \tEpoch [17/60]  train_Loss: 0.6777\ttrain_Acc: 82.63\n",
            "Val \tEpoch [17/60]  val_Loss: 0.5070\tval_Acc: 91.98\n",
            "Test \tEpoch [17/60]  test_Loss: 1.0543\ttest_Acc: 64.15\n",
            "--------------------------------------------------\n",
            "Epoch 18 of 60 took 1.920s\n",
            "Train \tEpoch [18/60]  train_Loss: 0.6699\ttrain_Acc: 83.23\n",
            "Val \tEpoch [18/60]  val_Loss: 0.5025\tval_Acc: 92.45\n",
            "Test \tEpoch [18/60]  test_Loss: 1.0453\ttest_Acc: 63.21\n",
            "--------------------------------------------------\n",
            "Epoch 19 of 60 took 1.904s\n",
            "Train \tEpoch [19/60]  train_Loss: 0.6271\ttrain_Acc: 84.95\n",
            "Val \tEpoch [19/60]  val_Loss: 0.5470\tval_Acc: 87.74\n",
            "Test \tEpoch [19/60]  test_Loss: 0.7675\ttest_Acc: 86.32\n",
            "--------------------------------------------------\n",
            "Epoch 20 of 60 took 1.888s\n",
            "Train \tEpoch [20/60]  train_Loss: 0.6186\ttrain_Acc: 85.48\n",
            "Val \tEpoch [20/60]  val_Loss: 0.4677\tval_Acc: 93.40\n",
            "Test \tEpoch [20/60]  test_Loss: 0.9124\ttest_Acc: 71.23\n",
            "--------------------------------------------------\n",
            "Epoch 21 of 60 took 1.911s\n",
            "Train \tEpoch [21/60]  train_Loss: 0.6066\ttrain_Acc: 85.90\n",
            "Val \tEpoch [21/60]  val_Loss: 0.4758\tval_Acc: 92.92\n",
            "Test \tEpoch [21/60]  test_Loss: 0.8889\ttest_Acc: 74.06\n",
            "--------------------------------------------------\n",
            "Epoch 22 of 60 took 1.927s\n",
            "Train \tEpoch [22/60]  train_Loss: 0.5810\ttrain_Acc: 87.98\n",
            "Val \tEpoch [22/60]  val_Loss: 0.4548\tval_Acc: 94.34\n",
            "Test \tEpoch [22/60]  test_Loss: 0.8950\ttest_Acc: 72.64\n",
            "--------------------------------------------------\n",
            "Epoch 23 of 60 took 1.911s\n",
            "Train \tEpoch [23/60]  train_Loss: 0.5462\ttrain_Acc: 88.25\n",
            "Val \tEpoch [23/60]  val_Loss: 0.4666\tval_Acc: 93.40\n",
            "Test \tEpoch [23/60]  test_Loss: 0.9931\ttest_Acc: 69.34\n",
            "--------------------------------------------------\n",
            "Epoch 24 of 60 took 1.905s\n",
            "Train \tEpoch [24/60]  train_Loss: 0.5266\ttrain_Acc: 89.13\n",
            "Val \tEpoch [24/60]  val_Loss: 0.4340\tval_Acc: 93.40\n",
            "Test \tEpoch [24/60]  test_Loss: 0.9400\ttest_Acc: 71.23\n",
            "--------------------------------------------------\n",
            "Epoch 25 of 60 took 1.889s\n",
            "Train \tEpoch [25/60]  train_Loss: 0.5422\ttrain_Acc: 89.74\n",
            "Val \tEpoch [25/60]  val_Loss: 0.4365\tval_Acc: 93.87\n",
            "Test \tEpoch [25/60]  test_Loss: 0.9456\ttest_Acc: 69.81\n",
            "--------------------------------------------------\n",
            "Epoch 26 of 60 took 1.889s\n",
            "Train \tEpoch [26/60]  train_Loss: 0.5021\ttrain_Acc: 89.83\n",
            "Val \tEpoch [26/60]  val_Loss: 0.4292\tval_Acc: 94.34\n",
            "Test \tEpoch [26/60]  test_Loss: 0.9129\ttest_Acc: 75.00\n",
            "--------------------------------------------------\n",
            "Epoch 27 of 60 took 1.914s\n",
            "Train \tEpoch [27/60]  train_Loss: 0.4966\ttrain_Acc: 90.57\n",
            "Val \tEpoch [27/60]  val_Loss: 0.4211\tval_Acc: 94.34\n",
            "Test \tEpoch [27/60]  test_Loss: 0.7305\ttest_Acc: 74.06\n",
            "--------------------------------------------------\n",
            "Epoch 28 of 60 took 1.886s\n",
            "Train \tEpoch [28/60]  train_Loss: 0.4910\ttrain_Acc: 89.83\n",
            "Val \tEpoch [28/60]  val_Loss: 0.4229\tval_Acc: 94.81\n",
            "Test \tEpoch [28/60]  test_Loss: 0.9322\ttest_Acc: 68.87\n",
            "--------------------------------------------------\n",
            "Epoch 29 of 60 took 1.895s\n",
            "Train \tEpoch [29/60]  train_Loss: 0.5044\ttrain_Acc: 89.66\n",
            "Val \tEpoch [29/60]  val_Loss: 0.4159\tval_Acc: 94.81\n",
            "Test \tEpoch [29/60]  test_Loss: 1.0794\ttest_Acc: 72.17\n",
            "--------------------------------------------------\n",
            "Epoch 30 of 60 took 1.900s\n",
            "Train \tEpoch [30/60]  train_Loss: 0.4583\ttrain_Acc: 91.42\n",
            "Val \tEpoch [30/60]  val_Loss: 0.4124\tval_Acc: 94.81\n",
            "Test \tEpoch [30/60]  test_Loss: 0.7842\ttest_Acc: 75.00\n",
            "--------------------------------------------------\n",
            "Epoch 31 of 60 took 1.899s\n",
            "Train \tEpoch [31/60]  train_Loss: 0.4671\ttrain_Acc: 91.46\n",
            "Val \tEpoch [31/60]  val_Loss: 0.4014\tval_Acc: 94.81\n",
            "Test \tEpoch [31/60]  test_Loss: 0.9695\ttest_Acc: 74.06\n",
            "--------------------------------------------------\n",
            "Epoch 32 of 60 took 1.942s\n",
            "Train \tEpoch [32/60]  train_Loss: 0.4423\ttrain_Acc: 91.59\n",
            "Val \tEpoch [32/60]  val_Loss: 0.3928\tval_Acc: 95.28\n",
            "Test \tEpoch [32/60]  test_Loss: 0.8122\ttest_Acc: 74.06\n",
            "--------------------------------------------------\n",
            "Epoch 33 of 60 took 1.907s\n",
            "Train \tEpoch [33/60]  train_Loss: 0.4405\ttrain_Acc: 91.86\n",
            "Val \tEpoch [33/60]  val_Loss: 0.4041\tval_Acc: 94.34\n",
            "Test \tEpoch [33/60]  test_Loss: 0.8346\ttest_Acc: 66.51\n",
            "--------------------------------------------------\n",
            "Epoch 34 of 60 took 1.916s\n",
            "Train \tEpoch [34/60]  train_Loss: 0.4251\ttrain_Acc: 92.69\n",
            "Val \tEpoch [34/60]  val_Loss: 0.4076\tval_Acc: 95.28\n",
            "Test \tEpoch [34/60]  test_Loss: 0.8877\ttest_Acc: 74.06\n",
            "--------------------------------------------------\n",
            "Epoch 35 of 60 took 1.885s\n",
            "Train \tEpoch [35/60]  train_Loss: 0.4438\ttrain_Acc: 92.15\n",
            "Val \tEpoch [35/60]  val_Loss: 0.4077\tval_Acc: 93.87\n",
            "Test \tEpoch [35/60]  test_Loss: 0.6610\ttest_Acc: 77.83\n",
            "--------------------------------------------------\n",
            "Epoch 36 of 60 took 1.915s\n",
            "Train \tEpoch [36/60]  train_Loss: 0.4307\ttrain_Acc: 91.77\n",
            "Val \tEpoch [36/60]  val_Loss: 0.3858\tval_Acc: 95.75\n",
            "Test \tEpoch [36/60]  test_Loss: 0.9091\ttest_Acc: 71.23\n",
            "--------------------------------------------------\n",
            "Epoch 37 of 60 took 1.909s\n",
            "Train \tEpoch [37/60]  train_Loss: 0.4311\ttrain_Acc: 91.95\n",
            "Val \tEpoch [37/60]  val_Loss: 0.3891\tval_Acc: 94.34\n",
            "Test \tEpoch [37/60]  test_Loss: 0.8725\ttest_Acc: 74.06\n",
            "--------------------------------------------------\n",
            "Epoch 38 of 60 took 1.902s\n",
            "Train \tEpoch [38/60]  train_Loss: 0.4117\ttrain_Acc: 92.87\n",
            "Val \tEpoch [38/60]  val_Loss: 0.3800\tval_Acc: 95.28\n",
            "Test \tEpoch [38/60]  test_Loss: 0.9156\ttest_Acc: 73.58\n",
            "--------------------------------------------------\n",
            "Epoch 39 of 60 took 1.892s\n",
            "Train \tEpoch [39/60]  train_Loss: 0.4123\ttrain_Acc: 92.61\n",
            "Val \tEpoch [39/60]  val_Loss: 0.3945\tval_Acc: 95.28\n",
            "Test \tEpoch [39/60]  test_Loss: 0.8951\ttest_Acc: 74.53\n",
            "--------------------------------------------------\n",
            "Epoch 40 of 60 took 1.886s\n",
            "Train \tEpoch [40/60]  train_Loss: 0.4015\ttrain_Acc: 93.00\n",
            "Val \tEpoch [40/60]  val_Loss: 0.4025\tval_Acc: 94.81\n",
            "Test \tEpoch [40/60]  test_Loss: 0.7146\ttest_Acc: 71.70\n",
            "--------------------------------------------------\n",
            "Epoch 41 of 60 took 1.906s\n",
            "Train \tEpoch [41/60]  train_Loss: 0.4013\ttrain_Acc: 92.61\n",
            "Val \tEpoch [41/60]  val_Loss: 0.3910\tval_Acc: 94.81\n",
            "Test \tEpoch [41/60]  test_Loss: 0.9235\ttest_Acc: 74.06\n",
            "--------------------------------------------------\n",
            "Epoch 42 of 60 took 1.906s\n",
            "Train \tEpoch [42/60]  train_Loss: 0.4077\ttrain_Acc: 92.78\n",
            "Val \tEpoch [42/60]  val_Loss: 0.4129\tval_Acc: 93.87\n",
            "Test \tEpoch [42/60]  test_Loss: 0.6305\ttest_Acc: 81.13\n",
            "--------------------------------------------------\n",
            "Epoch 43 of 60 took 1.885s\n",
            "Train \tEpoch [43/60]  train_Loss: 0.3972\ttrain_Acc: 93.18\n",
            "Val \tEpoch [43/60]  val_Loss: 0.3989\tval_Acc: 95.28\n",
            "Test \tEpoch [43/60]  test_Loss: 0.8077\ttest_Acc: 69.81\n",
            "--------------------------------------------------\n",
            "Epoch 44 of 60 took 1.892s\n",
            "Train \tEpoch [44/60]  train_Loss: 0.3918\ttrain_Acc: 93.53\n",
            "Val \tEpoch [44/60]  val_Loss: 0.4016\tval_Acc: 94.81\n",
            "Test \tEpoch [44/60]  test_Loss: 0.7326\ttest_Acc: 70.28\n",
            "--------------------------------------------------\n",
            "Epoch 45 of 60 took 1.903s\n",
            "Train \tEpoch [45/60]  train_Loss: 0.3896\ttrain_Acc: 93.31\n",
            "Val \tEpoch [45/60]  val_Loss: 0.3847\tval_Acc: 95.75\n",
            "Test \tEpoch [45/60]  test_Loss: 0.8024\ttest_Acc: 70.75\n",
            "--------------------------------------------------\n",
            "Epoch 46 of 60 took 1.920s\n",
            "Train \tEpoch [46/60]  train_Loss: 0.3764\ttrain_Acc: 93.57\n",
            "Val \tEpoch [46/60]  val_Loss: 0.4003\tval_Acc: 95.75\n",
            "Test \tEpoch [46/60]  test_Loss: 0.7352\ttest_Acc: 70.28\n",
            "--------------------------------------------------\n",
            "Time in total: 136.98950242996216\n",
            "Best validation accuracy:\t\t95.75 %\n",
            "Test accuracy when got the best validation accuracy:\t\t71.23 %\n",
            "--------------------------------------------------\n",
            "Last train accuracy:\t\t96.66 %\n",
            "Last validation accuracy:\t\t95.75 %\n",
            "Last test accuracy:\t\t\t\t70.28 %\n",
            "Early Stopping at epoch: 36\n",
            "Done!\n",
            "----------------------------------------------------------------------------------------------------\n",
            "The subjects 2 \t\t Training the 1dconv Model...\n",
            "Load the CNN model weight for backbone...\n",
            "Train set label and proportion:\t (array([0, 1, 2, 3], dtype=int32), array([655, 595, 550, 472]))\n",
            "Val   set label and proportion:\t (array([0, 1, 2, 3], dtype=int32), array([47, 66, 47, 39]))\n",
            "Test  set label and proportion:\t (array([0, 1, 2, 3], dtype=int32), array([55, 54, 43, 47]))\n",
            "The shape of X_trian:\t (7, 2272, 32, 32, 3)\n",
            "The shape of X_val:\t (7, 199, 32, 32, 3)\n",
            "The shape of X_test:\t (7, 199, 32, 32, 3)\n",
            "Building model and compiling functions...\n",
            "Writing to /content/runs/2020-02-05.14.17_1dconv/1dconv_2\n",
            "\n",
            "Starting training...\n",
            "--------------------------------------------------\n",
            "Epoch 1 of 60 took 2.754s\n",
            "Train \tEpoch [1/60]  train_Loss: 5.5217\ttrain_Acc: 29.67\n",
            "Val \tEpoch [1/60]  val_Loss: 1.5337\tval_Acc: 44.22\n",
            "Test \tEpoch [1/60]  test_Loss: 1.7495\ttest_Acc: 48.24\n",
            "--------------------------------------------------\n",
            "Epoch 2 of 60 took 1.902s\n",
            "Train \tEpoch [2/60]  train_Loss: 1.8142\ttrain_Acc: 38.91\n",
            "Val \tEpoch [2/60]  val_Loss: 1.5403\tval_Acc: 54.77\n",
            "Test \tEpoch [2/60]  test_Loss: 1.6699\ttest_Acc: 48.24\n",
            "--------------------------------------------------\n",
            "Epoch 3 of 60 took 1.925s\n",
            "Train \tEpoch [3/60]  train_Loss: 1.6454\ttrain_Acc: 42.34\n",
            "Val \tEpoch [3/60]  val_Loss: 1.4126\tval_Acc: 53.27\n",
            "Test \tEpoch [3/60]  test_Loss: 1.5337\ttest_Acc: 45.73\n",
            "--------------------------------------------------\n",
            "Epoch 4 of 60 took 1.893s\n",
            "Train \tEpoch [4/60]  train_Loss: 1.4908\ttrain_Acc: 46.92\n",
            "Val \tEpoch [4/60]  val_Loss: 1.3226\tval_Acc: 62.31\n",
            "Test \tEpoch [4/60]  test_Loss: 1.4490\ttest_Acc: 55.78\n",
            "--------------------------------------------------\n",
            "Epoch 5 of 60 took 1.908s\n",
            "Train \tEpoch [5/60]  train_Loss: 1.4973\ttrain_Acc: 47.45\n",
            "Val \tEpoch [5/60]  val_Loss: 1.2975\tval_Acc: 67.84\n",
            "Test \tEpoch [5/60]  test_Loss: 1.4046\ttest_Acc: 55.78\n",
            "--------------------------------------------------\n",
            "Epoch 6 of 60 took 1.904s\n",
            "Train \tEpoch [6/60]  train_Loss: 1.3719\ttrain_Acc: 50.84\n",
            "Val \tEpoch [6/60]  val_Loss: 1.2417\tval_Acc: 63.82\n",
            "Test \tEpoch [6/60]  test_Loss: 1.3647\ttest_Acc: 57.29\n",
            "--------------------------------------------------\n",
            "Epoch 7 of 60 took 1.990s\n",
            "Train \tEpoch [7/60]  train_Loss: 1.2864\ttrain_Acc: 55.06\n",
            "Val \tEpoch [7/60]  val_Loss: 1.1070\tval_Acc: 75.38\n",
            "Test \tEpoch [7/60]  test_Loss: 1.3112\ttest_Acc: 63.32\n",
            "--------------------------------------------------\n",
            "Epoch 8 of 60 took 1.961s\n",
            "Train \tEpoch [8/60]  train_Loss: 1.1697\ttrain_Acc: 59.82\n",
            "Val \tEpoch [8/60]  val_Loss: 1.0232\tval_Acc: 75.38\n",
            "Test \tEpoch [8/60]  test_Loss: 1.2297\ttest_Acc: 68.84\n",
            "--------------------------------------------------\n",
            "Epoch 9 of 60 took 1.915s\n",
            "Train \tEpoch [9/60]  train_Loss: 1.1198\ttrain_Acc: 62.54\n",
            "Val \tEpoch [9/60]  val_Loss: 0.9826\tval_Acc: 73.87\n",
            "Test \tEpoch [9/60]  test_Loss: 1.2441\ttest_Acc: 65.83\n",
            "--------------------------------------------------\n",
            "Epoch 10 of 60 took 1.914s\n",
            "Train \tEpoch [10/60]  train_Loss: 1.0721\ttrain_Acc: 65.76\n",
            "Val \tEpoch [10/60]  val_Loss: 0.8688\tval_Acc: 83.42\n",
            "Test \tEpoch [10/60]  test_Loss: 1.1573\ttest_Acc: 74.37\n",
            "--------------------------------------------------\n",
            "Epoch 11 of 60 took 1.927s\n",
            "Train \tEpoch [11/60]  train_Loss: 1.0228\ttrain_Acc: 66.55\n",
            "Val \tEpoch [11/60]  val_Loss: 0.8612\tval_Acc: 84.92\n",
            "Test \tEpoch [11/60]  test_Loss: 1.0962\ttest_Acc: 77.39\n",
            "--------------------------------------------------\n",
            "Epoch 12 of 60 took 1.960s\n",
            "Train \tEpoch [12/60]  train_Loss: 0.9609\ttrain_Acc: 69.28\n",
            "Val \tEpoch [12/60]  val_Loss: 0.7789\tval_Acc: 86.93\n",
            "Test \tEpoch [12/60]  test_Loss: 1.0369\ttest_Acc: 76.88\n",
            "--------------------------------------------------\n",
            "Epoch 13 of 60 took 1.929s\n",
            "Train \tEpoch [13/60]  train_Loss: 0.8902\ttrain_Acc: 72.67\n",
            "Val \tEpoch [13/60]  val_Loss: 0.7415\tval_Acc: 86.43\n",
            "Test \tEpoch [13/60]  test_Loss: 0.9443\ttest_Acc: 82.91\n",
            "--------------------------------------------------\n",
            "Epoch 14 of 60 took 1.895s\n",
            "Train \tEpoch [14/60]  train_Loss: 0.8475\ttrain_Acc: 73.90\n",
            "Val \tEpoch [14/60]  val_Loss: 0.7419\tval_Acc: 88.94\n",
            "Test \tEpoch [14/60]  test_Loss: 0.9584\ttest_Acc: 84.42\n",
            "--------------------------------------------------\n",
            "Epoch 15 of 60 took 1.912s\n",
            "Train \tEpoch [15/60]  train_Loss: 0.8299\ttrain_Acc: 73.68\n",
            "Val \tEpoch [15/60]  val_Loss: 0.6833\tval_Acc: 85.93\n",
            "Test \tEpoch [15/60]  test_Loss: 0.8734\ttest_Acc: 80.90\n",
            "--------------------------------------------------\n",
            "Epoch 16 of 60 took 1.925s\n",
            "Train \tEpoch [16/60]  train_Loss: 0.7915\ttrain_Acc: 76.01\n",
            "Val \tEpoch [16/60]  val_Loss: 0.6327\tval_Acc: 84.42\n",
            "Test \tEpoch [16/60]  test_Loss: 0.8344\ttest_Acc: 79.90\n",
            "--------------------------------------------------\n",
            "Epoch 17 of 60 took 1.915s\n",
            "Train \tEpoch [17/60]  train_Loss: 0.7602\ttrain_Acc: 77.60\n",
            "Val \tEpoch [17/60]  val_Loss: 0.5982\tval_Acc: 91.46\n",
            "Test \tEpoch [17/60]  test_Loss: 0.7395\ttest_Acc: 89.95\n",
            "--------------------------------------------------\n",
            "Epoch 18 of 60 took 1.923s\n",
            "Train \tEpoch [18/60]  train_Loss: 0.7547\ttrain_Acc: 77.33\n",
            "Val \tEpoch [18/60]  val_Loss: 0.5739\tval_Acc: 88.44\n",
            "Test \tEpoch [18/60]  test_Loss: 0.7688\ttest_Acc: 87.44\n",
            "--------------------------------------------------\n",
            "Epoch 19 of 60 took 1.919s\n",
            "Train \tEpoch [19/60]  train_Loss: 0.6857\ttrain_Acc: 80.37\n",
            "Val \tEpoch [19/60]  val_Loss: 0.4701\tval_Acc: 90.95\n",
            "Test \tEpoch [19/60]  test_Loss: 0.7713\ttest_Acc: 86.43\n",
            "--------------------------------------------------\n",
            "Epoch 20 of 60 took 1.919s\n",
            "Train \tEpoch [20/60]  train_Loss: 0.6576\ttrain_Acc: 82.04\n",
            "Val \tEpoch [20/60]  val_Loss: 0.5150\tval_Acc: 91.96\n",
            "Test \tEpoch [20/60]  test_Loss: 0.7067\ttest_Acc: 91.96\n",
            "--------------------------------------------------\n",
            "Epoch 21 of 60 took 1.920s\n",
            "Train \tEpoch [21/60]  train_Loss: 0.6496\ttrain_Acc: 83.32\n",
            "Val \tEpoch [21/60]  val_Loss: 0.4530\tval_Acc: 93.97\n",
            "Test \tEpoch [21/60]  test_Loss: 0.7008\ttest_Acc: 89.45\n",
            "--------------------------------------------------\n",
            "Epoch 22 of 60 took 1.934s\n",
            "Train \tEpoch [22/60]  train_Loss: 0.6090\ttrain_Acc: 84.60\n",
            "Val \tEpoch [22/60]  val_Loss: 0.4749\tval_Acc: 89.45\n",
            "Test \tEpoch [22/60]  test_Loss: 0.6728\ttest_Acc: 88.94\n",
            "--------------------------------------------------\n",
            "Epoch 23 of 60 took 1.929s\n",
            "Train \tEpoch [23/60]  train_Loss: 0.5778\ttrain_Acc: 85.56\n",
            "Val \tEpoch [23/60]  val_Loss: 0.4554\tval_Acc: 90.45\n",
            "Test \tEpoch [23/60]  test_Loss: 0.7428\ttest_Acc: 84.92\n",
            "--------------------------------------------------\n",
            "Epoch 24 of 60 took 1.917s\n",
            "Train \tEpoch [24/60]  train_Loss: 0.5676\ttrain_Acc: 86.40\n",
            "Val \tEpoch [24/60]  val_Loss: 0.4517\tval_Acc: 91.46\n",
            "Test \tEpoch [24/60]  test_Loss: 0.5902\ttest_Acc: 89.95\n",
            "--------------------------------------------------\n",
            "Epoch 25 of 60 took 1.911s\n",
            "Train \tEpoch [25/60]  train_Loss: 0.5626\ttrain_Acc: 87.37\n",
            "Val \tEpoch [25/60]  val_Loss: 0.4667\tval_Acc: 92.46\n",
            "Test \tEpoch [25/60]  test_Loss: 0.6841\ttest_Acc: 88.94\n",
            "--------------------------------------------------\n",
            "Epoch 26 of 60 took 1.909s\n",
            "Train \tEpoch [26/60]  train_Loss: 0.5487\ttrain_Acc: 87.72\n",
            "Val \tEpoch [26/60]  val_Loss: 0.4393\tval_Acc: 89.95\n",
            "Test \tEpoch [26/60]  test_Loss: 0.6107\ttest_Acc: 88.94\n",
            "--------------------------------------------------\n",
            "Epoch 27 of 60 took 1.914s\n",
            "Train \tEpoch [27/60]  train_Loss: 0.5052\ttrain_Acc: 87.94\n",
            "Val \tEpoch [27/60]  val_Loss: 0.4454\tval_Acc: 92.96\n",
            "Test \tEpoch [27/60]  test_Loss: 0.6021\ttest_Acc: 88.44\n",
            "--------------------------------------------------\n",
            "Epoch 28 of 60 took 1.907s\n",
            "Train \tEpoch [28/60]  train_Loss: 0.5254\ttrain_Acc: 88.42\n",
            "Val \tEpoch [28/60]  val_Loss: 0.4644\tval_Acc: 91.96\n",
            "Test \tEpoch [28/60]  test_Loss: 0.6108\ttest_Acc: 85.43\n",
            "--------------------------------------------------\n",
            "Epoch 29 of 60 took 1.908s\n",
            "Train \tEpoch [29/60]  train_Loss: 0.5096\ttrain_Acc: 88.25\n",
            "Val \tEpoch [29/60]  val_Loss: 0.4232\tval_Acc: 90.95\n",
            "Test \tEpoch [29/60]  test_Loss: 0.5272\ttest_Acc: 91.96\n",
            "--------------------------------------------------\n",
            "Epoch 30 of 60 took 1.908s\n",
            "Train \tEpoch [30/60]  train_Loss: 0.5075\ttrain_Acc: 88.82\n",
            "Val \tEpoch [30/60]  val_Loss: 0.4427\tval_Acc: 90.45\n",
            "Test \tEpoch [30/60]  test_Loss: 0.5632\ttest_Acc: 88.94\n",
            "--------------------------------------------------\n",
            "Epoch 31 of 60 took 1.908s\n",
            "Train \tEpoch [31/60]  train_Loss: 0.4849\ttrain_Acc: 89.13\n",
            "Val \tEpoch [31/60]  val_Loss: 0.4754\tval_Acc: 87.94\n",
            "Test \tEpoch [31/60]  test_Loss: 0.6003\ttest_Acc: 89.45\n",
            "--------------------------------------------------\n",
            "Time in total: 107.2611563205719\n",
            "Best validation accuracy:\t\t93.97 %\n",
            "Test accuracy when got the best validation accuracy:\t\t89.45 %\n",
            "--------------------------------------------------\n",
            "Last train accuracy:\t\t93.05 %\n",
            "Last validation accuracy:\t\t87.94 %\n",
            "Last test accuracy:\t\t\t\t89.45 %\n",
            "Early Stopping at epoch: 21\n",
            "Done!\n",
            "----------------------------------------------------------------------------------------------------\n",
            "The subjects 3 \t\t Training the 1dconv Model...\n",
            "Load the CNN model weight for backbone...\n",
            "Train set label and proportion:\t (array([0, 1, 2, 3], dtype=int32), array([643, 610, 543, 472]))\n",
            "Val   set label and proportion:\t (array([0, 1, 2, 3], dtype=int32), array([54, 48, 52, 47]))\n",
            "Test  set label and proportion:\t (array([0, 1, 2, 3], dtype=int32), array([60, 57, 45, 39]))\n",
            "The shape of X_trian:\t (7, 2268, 32, 32, 3)\n",
            "The shape of X_val:\t (7, 201, 32, 32, 3)\n",
            "The shape of X_test:\t (7, 201, 32, 32, 3)\n",
            "Building model and compiling functions...\n",
            "Writing to /content/runs/2020-02-05.14.17_1dconv/1dconv_3\n",
            "\n",
            "Starting training...\n",
            "--------------------------------------------------\n",
            "Epoch 1 of 60 took 2.802s\n",
            "Train \tEpoch [1/60]  train_Loss: 5.4531\ttrain_Acc: 33.01\n",
            "Val \tEpoch [1/60]  val_Loss: 1.4253\tval_Acc: 47.76\n",
            "Test \tEpoch [1/60]  test_Loss: 1.5319\ttest_Acc: 42.29\n",
            "--------------------------------------------------\n",
            "Epoch 2 of 60 took 1.923s\n",
            "Train \tEpoch [2/60]  train_Loss: 1.7336\ttrain_Acc: 36.19\n",
            "Val \tEpoch [2/60]  val_Loss: 1.4353\tval_Acc: 51.24\n",
            "Test \tEpoch [2/60]  test_Loss: 1.4875\ttest_Acc: 56.22\n",
            "--------------------------------------------------\n",
            "Epoch 3 of 60 took 1.933s\n",
            "Train \tEpoch [3/60]  train_Loss: 1.5543\ttrain_Acc: 41.74\n",
            "Val \tEpoch [3/60]  val_Loss: 1.4128\tval_Acc: 47.76\n",
            "Test \tEpoch [3/60]  test_Loss: 1.4170\ttest_Acc: 52.74\n",
            "--------------------------------------------------\n",
            "Epoch 4 of 60 took 1.923s\n",
            "Train \tEpoch [4/60]  train_Loss: 1.4943\ttrain_Acc: 44.47\n",
            "Val \tEpoch [4/60]  val_Loss: 1.3409\tval_Acc: 51.74\n",
            "Test \tEpoch [4/60]  test_Loss: 1.3899\ttest_Acc: 57.71\n",
            "--------------------------------------------------\n",
            "Epoch 5 of 60 took 1.925s\n",
            "Train \tEpoch [5/60]  train_Loss: 1.4374\ttrain_Acc: 44.56\n",
            "Val \tEpoch [5/60]  val_Loss: 1.3287\tval_Acc: 54.23\n",
            "Test \tEpoch [5/60]  test_Loss: 1.4457\ttest_Acc: 36.32\n",
            "--------------------------------------------------\n",
            "Epoch 6 of 60 took 1.924s\n",
            "Train \tEpoch [6/60]  train_Loss: 1.3870\ttrain_Acc: 49.26\n",
            "Val \tEpoch [6/60]  val_Loss: 1.2349\tval_Acc: 59.70\n",
            "Test \tEpoch [6/60]  test_Loss: 1.2422\ttest_Acc: 60.70\n",
            "--------------------------------------------------\n",
            "Epoch 7 of 60 took 1.923s\n",
            "Train \tEpoch [7/60]  train_Loss: 1.3058\ttrain_Acc: 52.33\n",
            "Val \tEpoch [7/60]  val_Loss: 1.1994\tval_Acc: 56.72\n",
            "Test \tEpoch [7/60]  test_Loss: 1.2323\ttest_Acc: 57.71\n",
            "--------------------------------------------------\n",
            "Epoch 8 of 60 took 1.927s\n",
            "Train \tEpoch [8/60]  train_Loss: 1.2580\ttrain_Acc: 56.96\n",
            "Val \tEpoch [8/60]  val_Loss: 1.1619\tval_Acc: 60.70\n",
            "Test \tEpoch [8/60]  test_Loss: 1.1912\ttest_Acc: 64.68\n",
            "--------------------------------------------------\n",
            "Epoch 9 of 60 took 1.942s\n",
            "Train \tEpoch [9/60]  train_Loss: 1.2324\ttrain_Acc: 58.92\n",
            "Val \tEpoch [9/60]  val_Loss: 1.0575\tval_Acc: 66.17\n",
            "Test \tEpoch [9/60]  test_Loss: 1.0474\ttest_Acc: 77.11\n",
            "--------------------------------------------------\n",
            "Epoch 10 of 60 took 1.940s\n",
            "Train \tEpoch [10/60]  train_Loss: 1.1480\ttrain_Acc: 62.68\n",
            "Val \tEpoch [10/60]  val_Loss: 0.9843\tval_Acc: 70.15\n",
            "Test \tEpoch [10/60]  test_Loss: 0.9373\ttest_Acc: 79.60\n",
            "--------------------------------------------------\n",
            "Epoch 11 of 60 took 1.945s\n",
            "Train \tEpoch [11/60]  train_Loss: 1.0562\ttrain_Acc: 65.90\n",
            "Val \tEpoch [11/60]  val_Loss: 0.9188\tval_Acc: 76.62\n",
            "Test \tEpoch [11/60]  test_Loss: 0.7944\ttest_Acc: 93.03\n",
            "--------------------------------------------------\n",
            "Epoch 12 of 60 took 1.993s\n",
            "Train \tEpoch [12/60]  train_Loss: 0.9864\ttrain_Acc: 69.80\n",
            "Val \tEpoch [12/60]  val_Loss: 0.8134\tval_Acc: 81.59\n",
            "Test \tEpoch [12/60]  test_Loss: 0.6991\ttest_Acc: 89.05\n",
            "--------------------------------------------------\n",
            "Epoch 13 of 60 took 1.936s\n",
            "Train \tEpoch [13/60]  train_Loss: 0.9317\ttrain_Acc: 72.80\n",
            "Val \tEpoch [13/60]  val_Loss: 0.7516\tval_Acc: 86.57\n",
            "Test \tEpoch [13/60]  test_Loss: 0.6147\ttest_Acc: 96.52\n",
            "--------------------------------------------------\n",
            "Epoch 14 of 60 took 1.924s\n",
            "Train \tEpoch [14/60]  train_Loss: 0.8921\ttrain_Acc: 74.62\n",
            "Val \tEpoch [14/60]  val_Loss: 0.7096\tval_Acc: 84.58\n",
            "Test \tEpoch [14/60]  test_Loss: 0.5447\ttest_Acc: 97.01\n",
            "--------------------------------------------------\n",
            "Epoch 15 of 60 took 1.929s\n",
            "Train \tEpoch [15/60]  train_Loss: 0.8267\ttrain_Acc: 76.15\n",
            "Val \tEpoch [15/60]  val_Loss: 0.6631\tval_Acc: 86.57\n",
            "Test \tEpoch [15/60]  test_Loss: 0.5138\ttest_Acc: 96.02\n",
            "--------------------------------------------------\n",
            "Epoch 16 of 60 took 1.962s\n",
            "Train \tEpoch [16/60]  train_Loss: 0.8127\ttrain_Acc: 77.49\n",
            "Val \tEpoch [16/60]  val_Loss: 0.6327\tval_Acc: 85.57\n",
            "Test \tEpoch [16/60]  test_Loss: 0.4473\ttest_Acc: 98.01\n",
            "--------------------------------------------------\n",
            "Epoch 17 of 60 took 2.010s\n",
            "Train \tEpoch [17/60]  train_Loss: 0.7629\ttrain_Acc: 77.86\n",
            "Val \tEpoch [17/60]  val_Loss: 0.5839\tval_Acc: 86.07\n",
            "Test \tEpoch [17/60]  test_Loss: 0.3984\ttest_Acc: 97.01\n",
            "--------------------------------------------------\n",
            "Epoch 18 of 60 took 1.919s\n",
            "Train \tEpoch [18/60]  train_Loss: 0.7439\ttrain_Acc: 79.45\n",
            "Val \tEpoch [18/60]  val_Loss: 0.5707\tval_Acc: 87.06\n",
            "Test \tEpoch [18/60]  test_Loss: 0.4171\ttest_Acc: 97.51\n",
            "--------------------------------------------------\n",
            "Epoch 19 of 60 took 1.925s\n",
            "Train \tEpoch [19/60]  train_Loss: 0.7086\ttrain_Acc: 81.04\n",
            "Val \tEpoch [19/60]  val_Loss: 0.5571\tval_Acc: 88.56\n",
            "Test \tEpoch [19/60]  test_Loss: 0.3864\ttest_Acc: 98.51\n",
            "--------------------------------------------------\n",
            "Epoch 20 of 60 took 1.920s\n",
            "Train \tEpoch [20/60]  train_Loss: 0.6751\ttrain_Acc: 82.20\n",
            "Val \tEpoch [20/60]  val_Loss: 0.5706\tval_Acc: 85.07\n",
            "Test \tEpoch [20/60]  test_Loss: 0.4056\ttest_Acc: 96.52\n",
            "--------------------------------------------------\n",
            "Epoch 21 of 60 took 1.921s\n",
            "Train \tEpoch [21/60]  train_Loss: 0.6686\ttrain_Acc: 82.55\n",
            "Val \tEpoch [21/60]  val_Loss: 0.5274\tval_Acc: 86.57\n",
            "Test \tEpoch [21/60]  test_Loss: 0.3288\ttest_Acc: 99.00\n",
            "--------------------------------------------------\n",
            "Epoch 22 of 60 took 1.908s\n",
            "Train \tEpoch [22/60]  train_Loss: 0.6265\ttrain_Acc: 84.15\n",
            "Val \tEpoch [22/60]  val_Loss: 0.5164\tval_Acc: 89.05\n",
            "Test \tEpoch [22/60]  test_Loss: 0.3354\ttest_Acc: 98.51\n",
            "--------------------------------------------------\n",
            "Epoch 23 of 60 took 1.910s\n",
            "Train \tEpoch [23/60]  train_Loss: 0.6252\ttrain_Acc: 83.70\n",
            "Val \tEpoch [23/60]  val_Loss: 0.5247\tval_Acc: 88.56\n",
            "Test \tEpoch [23/60]  test_Loss: 0.3370\ttest_Acc: 99.00\n",
            "--------------------------------------------------\n",
            "Epoch 24 of 60 took 1.944s\n",
            "Train \tEpoch [24/60]  train_Loss: 0.6085\ttrain_Acc: 85.04\n",
            "Val \tEpoch [24/60]  val_Loss: 0.4729\tval_Acc: 89.55\n",
            "Test \tEpoch [24/60]  test_Loss: 0.2942\ttest_Acc: 99.00\n",
            "--------------------------------------------------\n",
            "Epoch 25 of 60 took 1.915s\n",
            "Train \tEpoch [25/60]  train_Loss: 0.5799\ttrain_Acc: 85.63\n",
            "Val \tEpoch [25/60]  val_Loss: 0.4799\tval_Acc: 88.06\n",
            "Test \tEpoch [25/60]  test_Loss: 0.2921\ttest_Acc: 99.50\n",
            "--------------------------------------------------\n",
            "Epoch 26 of 60 took 1.907s\n",
            "Train \tEpoch [26/60]  train_Loss: 0.5729\ttrain_Acc: 85.47\n",
            "Val \tEpoch [26/60]  val_Loss: 0.4903\tval_Acc: 88.56\n",
            "Test \tEpoch [26/60]  test_Loss: 0.3192\ttest_Acc: 99.00\n",
            "--------------------------------------------------\n",
            "Epoch 27 of 60 took 1.991s\n",
            "Train \tEpoch [27/60]  train_Loss: 0.5677\ttrain_Acc: 85.37\n",
            "Val \tEpoch [27/60]  val_Loss: 0.4935\tval_Acc: 89.55\n",
            "Test \tEpoch [27/60]  test_Loss: 0.3139\ttest_Acc: 97.51\n",
            "--------------------------------------------------\n",
            "Epoch 28 of 60 took 1.917s\n",
            "Train \tEpoch [28/60]  train_Loss: 0.5429\ttrain_Acc: 86.81\n",
            "Val \tEpoch [28/60]  val_Loss: 0.4501\tval_Acc: 88.56\n",
            "Test \tEpoch [28/60]  test_Loss: 0.2618\ttest_Acc: 100.00\n",
            "--------------------------------------------------\n",
            "Epoch 29 of 60 took 1.933s\n",
            "Train \tEpoch [29/60]  train_Loss: 0.5351\ttrain_Acc: 86.86\n",
            "Val \tEpoch [29/60]  val_Loss: 0.4670\tval_Acc: 88.56\n",
            "Test \tEpoch [29/60]  test_Loss: 0.2763\ttest_Acc: 99.00\n",
            "--------------------------------------------------\n",
            "Epoch 30 of 60 took 1.931s\n",
            "Train \tEpoch [30/60]  train_Loss: 0.5335\ttrain_Acc: 87.85\n",
            "Val \tEpoch [30/60]  val_Loss: 0.4544\tval_Acc: 89.05\n",
            "Test \tEpoch [30/60]  test_Loss: 0.2728\ttest_Acc: 99.00\n",
            "--------------------------------------------------\n",
            "Epoch 31 of 60 took 1.914s\n",
            "Train \tEpoch [31/60]  train_Loss: 0.5240\ttrain_Acc: 87.98\n",
            "Val \tEpoch [31/60]  val_Loss: 0.4450\tval_Acc: 89.05\n",
            "Test \tEpoch [31/60]  test_Loss: 0.2698\ttest_Acc: 99.00\n",
            "--------------------------------------------------\n",
            "Epoch 32 of 60 took 1.934s\n",
            "Train \tEpoch [32/60]  train_Loss: 0.5112\ttrain_Acc: 88.20\n",
            "Val \tEpoch [32/60]  val_Loss: 0.4322\tval_Acc: 89.55\n",
            "Test \tEpoch [32/60]  test_Loss: 0.2651\ttest_Acc: 99.50\n",
            "--------------------------------------------------\n",
            "Epoch 33 of 60 took 1.910s\n",
            "Train \tEpoch [33/60]  train_Loss: 0.5083\ttrain_Acc: 87.75\n",
            "Val \tEpoch [33/60]  val_Loss: 0.4443\tval_Acc: 89.05\n",
            "Test \tEpoch [33/60]  test_Loss: 0.2583\ttest_Acc: 99.00\n",
            "--------------------------------------------------\n",
            "Epoch 34 of 60 took 1.918s\n",
            "Train \tEpoch [34/60]  train_Loss: 0.4801\ttrain_Acc: 89.15\n",
            "Val \tEpoch [34/60]  val_Loss: 0.4556\tval_Acc: 88.56\n",
            "Test \tEpoch [34/60]  test_Loss: 0.2664\ttest_Acc: 99.00\n",
            "--------------------------------------------------\n",
            "Time in total: 113.74878144264221\n",
            "Best validation accuracy:\t\t89.55 %\n",
            "Test accuracy when got the best validation accuracy:\t\t99.00 %\n",
            "--------------------------------------------------\n",
            "Last train accuracy:\t\t94.27 %\n",
            "Last validation accuracy:\t\t88.56 %\n",
            "Last test accuracy:\t\t\t\t99.00 %\n",
            "Early Stopping at epoch: 24\n",
            "Done!\n",
            "----------------------------------------------------------------------------------------------------\n",
            "The subjects 4 \t\t Training the 1dconv Model...\n",
            "Load the CNN model weight for backbone...\n",
            "Train set label and proportion:\t (array([0, 1, 2, 3], dtype=int32), array([645, 600, 551, 482]))\n",
            "Val   set label and proportion:\t (array([0, 1, 2, 3], dtype=int32), array([53, 59, 44, 40]))\n",
            "Test  set label and proportion:\t (array([0, 1, 2, 3], dtype=int32), array([59, 56, 45, 36]))\n",
            "The shape of X_trian:\t (7, 2278, 32, 32, 3)\n",
            "The shape of X_val:\t (7, 196, 32, 32, 3)\n",
            "The shape of X_test:\t (7, 196, 32, 32, 3)\n",
            "Building model and compiling functions...\n",
            "Writing to /content/runs/2020-02-05.14.17_1dconv/1dconv_4\n",
            "\n",
            "Starting training...\n",
            "--------------------------------------------------\n",
            "Epoch 1 of 60 took 2.856s\n",
            "Train \tEpoch [1/60]  train_Loss: 6.2123\ttrain_Acc: 32.68\n",
            "Val \tEpoch [1/60]  val_Loss: 1.3995\tval_Acc: 56.12\n",
            "Test \tEpoch [1/60]  test_Loss: 1.3820\ttest_Acc: 56.12\n",
            "--------------------------------------------------\n",
            "Epoch 2 of 60 took 1.955s\n",
            "Train \tEpoch [2/60]  train_Loss: 1.7207\ttrain_Acc: 41.39\n",
            "Val \tEpoch [2/60]  val_Loss: 1.3379\tval_Acc: 54.08\n",
            "Test \tEpoch [2/60]  test_Loss: 1.2288\ttest_Acc: 60.20\n",
            "--------------------------------------------------\n",
            "Epoch 3 of 60 took 1.946s\n",
            "Train \tEpoch [3/60]  train_Loss: 1.5499\ttrain_Acc: 46.15\n",
            "Val \tEpoch [3/60]  val_Loss: 1.3031\tval_Acc: 62.76\n",
            "Test \tEpoch [3/60]  test_Loss: 1.2150\ttest_Acc: 73.47\n",
            "--------------------------------------------------\n",
            "Epoch 4 of 60 took 1.951s\n",
            "Train \tEpoch [4/60]  train_Loss: 1.4369\ttrain_Acc: 48.87\n",
            "Val \tEpoch [4/60]  val_Loss: 1.2581\tval_Acc: 65.31\n",
            "Test \tEpoch [4/60]  test_Loss: 1.1357\ttest_Acc: 77.04\n",
            "--------------------------------------------------\n",
            "Epoch 5 of 60 took 1.958s\n",
            "Train \tEpoch [5/60]  train_Loss: 1.3693\ttrain_Acc: 49.20\n",
            "Val \tEpoch [5/60]  val_Loss: 1.2131\tval_Acc: 66.84\n",
            "Test \tEpoch [5/60]  test_Loss: 1.1043\ttest_Acc: 75.51\n",
            "--------------------------------------------------\n",
            "Epoch 6 of 60 took 1.964s\n",
            "Train \tEpoch [6/60]  train_Loss: 1.3251\ttrain_Acc: 52.60\n",
            "Val \tEpoch [6/60]  val_Loss: 1.1603\tval_Acc: 66.33\n",
            "Test \tEpoch [6/60]  test_Loss: 1.0351\ttest_Acc: 71.94\n",
            "--------------------------------------------------\n",
            "Epoch 7 of 60 took 1.945s\n",
            "Train \tEpoch [7/60]  train_Loss: 1.2790\ttrain_Acc: 56.32\n",
            "Val \tEpoch [7/60]  val_Loss: 1.0985\tval_Acc: 72.45\n",
            "Test \tEpoch [7/60]  test_Loss: 0.8982\ttest_Acc: 85.71\n",
            "--------------------------------------------------\n",
            "Epoch 8 of 60 took 1.977s\n",
            "Train \tEpoch [8/60]  train_Loss: 1.2227\ttrain_Acc: 58.52\n",
            "Val \tEpoch [8/60]  val_Loss: 1.0380\tval_Acc: 75.00\n",
            "Test \tEpoch [8/60]  test_Loss: 0.8541\ttest_Acc: 90.82\n",
            "--------------------------------------------------\n",
            "Epoch 9 of 60 took 1.959s\n",
            "Train \tEpoch [9/60]  train_Loss: 1.1526\ttrain_Acc: 61.70\n",
            "Val \tEpoch [9/60]  val_Loss: 1.0002\tval_Acc: 72.45\n",
            "Test \tEpoch [9/60]  test_Loss: 0.7877\ttest_Acc: 86.73\n",
            "--------------------------------------------------\n",
            "Epoch 10 of 60 took 1.952s\n",
            "Train \tEpoch [10/60]  train_Loss: 1.1375\ttrain_Acc: 61.73\n",
            "Val \tEpoch [10/60]  val_Loss: 0.9571\tval_Acc: 73.98\n",
            "Test \tEpoch [10/60]  test_Loss: 0.7069\ttest_Acc: 88.78\n",
            "--------------------------------------------------\n",
            "Epoch 11 of 60 took 1.958s\n",
            "Train \tEpoch [11/60]  train_Loss: 1.0542\ttrain_Acc: 66.29\n",
            "Val \tEpoch [11/60]  val_Loss: 0.8963\tval_Acc: 78.06\n",
            "Test \tEpoch [11/60]  test_Loss: 0.5709\ttest_Acc: 92.86\n",
            "--------------------------------------------------\n",
            "Epoch 12 of 60 took 1.971s\n",
            "Train \tEpoch [12/60]  train_Loss: 1.0023\ttrain_Acc: 68.39\n",
            "Val \tEpoch [12/60]  val_Loss: 0.8396\tval_Acc: 82.14\n",
            "Test \tEpoch [12/60]  test_Loss: 0.5472\ttest_Acc: 94.39\n",
            "--------------------------------------------------\n",
            "Epoch 13 of 60 took 1.990s\n",
            "Train \tEpoch [13/60]  train_Loss: 0.9581\ttrain_Acc: 70.20\n",
            "Val \tEpoch [13/60]  val_Loss: 0.8388\tval_Acc: 78.57\n",
            "Test \tEpoch [13/60]  test_Loss: 0.5354\ttest_Acc: 92.35\n",
            "--------------------------------------------------\n",
            "Epoch 14 of 60 took 1.976s\n",
            "Train \tEpoch [14/60]  train_Loss: 0.9166\ttrain_Acc: 71.66\n",
            "Val \tEpoch [14/60]  val_Loss: 0.7695\tval_Acc: 80.61\n",
            "Test \tEpoch [14/60]  test_Loss: 0.4832\ttest_Acc: 94.39\n",
            "--------------------------------------------------\n",
            "Epoch 15 of 60 took 1.962s\n",
            "Train \tEpoch [15/60]  train_Loss: 0.8673\ttrain_Acc: 74.00\n",
            "Val \tEpoch [15/60]  val_Loss: 0.7093\tval_Acc: 83.67\n",
            "Test \tEpoch [15/60]  test_Loss: 0.4198\ttest_Acc: 96.43\n",
            "--------------------------------------------------\n",
            "Epoch 16 of 60 took 1.973s\n",
            "Train \tEpoch [16/60]  train_Loss: 0.8194\ttrain_Acc: 76.53\n",
            "Val \tEpoch [16/60]  val_Loss: 0.6961\tval_Acc: 83.16\n",
            "Test \tEpoch [16/60]  test_Loss: 0.3669\ttest_Acc: 98.98\n",
            "--------------------------------------------------\n",
            "Epoch 17 of 60 took 1.966s\n",
            "Train \tEpoch [17/60]  train_Loss: 0.7746\ttrain_Acc: 77.99\n",
            "Val \tEpoch [17/60]  val_Loss: 0.6444\tval_Acc: 86.22\n",
            "Test \tEpoch [17/60]  test_Loss: 0.3313\ttest_Acc: 98.98\n",
            "--------------------------------------------------\n",
            "Epoch 18 of 60 took 1.968s\n",
            "Train \tEpoch [18/60]  train_Loss: 0.7850\ttrain_Acc: 77.21\n",
            "Val \tEpoch [18/60]  val_Loss: 0.7180\tval_Acc: 82.14\n",
            "Test \tEpoch [18/60]  test_Loss: 0.4565\ttest_Acc: 96.43\n",
            "--------------------------------------------------\n",
            "Epoch 19 of 60 took 1.987s\n",
            "Train \tEpoch [19/60]  train_Loss: 0.7267\ttrain_Acc: 80.58\n",
            "Val \tEpoch [19/60]  val_Loss: 0.6222\tval_Acc: 87.24\n",
            "Test \tEpoch [19/60]  test_Loss: 0.3133\ttest_Acc: 98.98\n",
            "--------------------------------------------------\n",
            "Epoch 20 of 60 took 1.933s\n",
            "Train \tEpoch [20/60]  train_Loss: 0.6816\ttrain_Acc: 81.38\n",
            "Val \tEpoch [20/60]  val_Loss: 0.5584\tval_Acc: 89.29\n",
            "Test \tEpoch [20/60]  test_Loss: 0.2850\ttest_Acc: 98.98\n",
            "--------------------------------------------------\n",
            "Epoch 21 of 60 took 1.935s\n",
            "Train \tEpoch [21/60]  train_Loss: 0.6446\ttrain_Acc: 83.67\n",
            "Val \tEpoch [21/60]  val_Loss: 0.5769\tval_Acc: 87.76\n",
            "Test \tEpoch [21/60]  test_Loss: 0.2816\ttest_Acc: 99.49\n",
            "--------------------------------------------------\n",
            "Epoch 22 of 60 took 1.989s\n",
            "Train \tEpoch [22/60]  train_Loss: 0.6316\ttrain_Acc: 83.90\n",
            "Val \tEpoch [22/60]  val_Loss: 0.5518\tval_Acc: 89.80\n",
            "Test \tEpoch [22/60]  test_Loss: 0.2685\ttest_Acc: 99.49\n",
            "--------------------------------------------------\n",
            "Epoch 23 of 60 took 1.978s\n",
            "Train \tEpoch [23/60]  train_Loss: 0.6048\ttrain_Acc: 85.07\n",
            "Val \tEpoch [23/60]  val_Loss: 0.5583\tval_Acc: 87.76\n",
            "Test \tEpoch [23/60]  test_Loss: 0.2782\ttest_Acc: 98.98\n",
            "--------------------------------------------------\n",
            "Epoch 24 of 60 took 1.959s\n",
            "Train \tEpoch [24/60]  train_Loss: 0.6064\ttrain_Acc: 85.23\n",
            "Val \tEpoch [24/60]  val_Loss: 0.5279\tval_Acc: 89.80\n",
            "Test \tEpoch [24/60]  test_Loss: 0.2496\ttest_Acc: 100.00\n",
            "--------------------------------------------------\n",
            "Epoch 25 of 60 took 1.981s\n",
            "Train \tEpoch [25/60]  train_Loss: 0.5507\ttrain_Acc: 87.63\n",
            "Val \tEpoch [25/60]  val_Loss: 0.5130\tval_Acc: 89.29\n",
            "Test \tEpoch [25/60]  test_Loss: 0.2674\ttest_Acc: 98.47\n",
            "--------------------------------------------------\n",
            "Epoch 26 of 60 took 1.969s\n",
            "Train \tEpoch [26/60]  train_Loss: 0.5608\ttrain_Acc: 87.24\n",
            "Val \tEpoch [26/60]  val_Loss: 0.5218\tval_Acc: 88.27\n",
            "Test \tEpoch [26/60]  test_Loss: 0.2584\ttest_Acc: 98.98\n",
            "--------------------------------------------------\n",
            "Epoch 27 of 60 took 1.974s\n",
            "Train \tEpoch [27/60]  train_Loss: 0.5424\ttrain_Acc: 86.63\n",
            "Val \tEpoch [27/60]  val_Loss: 0.4862\tval_Acc: 89.80\n",
            "Test \tEpoch [27/60]  test_Loss: 0.2406\ttest_Acc: 99.49\n",
            "--------------------------------------------------\n",
            "Epoch 28 of 60 took 1.948s\n",
            "Train \tEpoch [28/60]  train_Loss: 0.5379\ttrain_Acc: 87.28\n",
            "Val \tEpoch [28/60]  val_Loss: 0.5287\tval_Acc: 89.80\n",
            "Test \tEpoch [28/60]  test_Loss: 0.2486\ttest_Acc: 100.00\n",
            "--------------------------------------------------\n",
            "Epoch 29 of 60 took 1.975s\n",
            "Train \tEpoch [29/60]  train_Loss: 0.5248\ttrain_Acc: 88.06\n",
            "Val \tEpoch [29/60]  val_Loss: 0.5221\tval_Acc: 90.31\n",
            "Test \tEpoch [29/60]  test_Loss: 0.2412\ttest_Acc: 100.00\n",
            "--------------------------------------------------\n",
            "Epoch 30 of 60 took 1.957s\n",
            "Train \tEpoch [30/60]  train_Loss: 0.5034\ttrain_Acc: 88.59\n",
            "Val \tEpoch [30/60]  val_Loss: 0.5038\tval_Acc: 90.31\n",
            "Test \tEpoch [30/60]  test_Loss: 0.2279\ttest_Acc: 100.00\n",
            "--------------------------------------------------\n",
            "Epoch 31 of 60 took 1.952s\n",
            "Train \tEpoch [31/60]  train_Loss: 0.4734\ttrain_Acc: 90.32\n",
            "Val \tEpoch [31/60]  val_Loss: 0.5224\tval_Acc: 90.31\n",
            "Test \tEpoch [31/60]  test_Loss: 0.2363\ttest_Acc: 98.98\n",
            "--------------------------------------------------\n",
            "Epoch 32 of 60 took 1.928s\n",
            "Train \tEpoch [32/60]  train_Loss: 0.5054\ttrain_Acc: 88.89\n",
            "Val \tEpoch [32/60]  val_Loss: 0.4827\tval_Acc: 90.82\n",
            "Test \tEpoch [32/60]  test_Loss: 0.2276\ttest_Acc: 100.00\n",
            "--------------------------------------------------\n",
            "Epoch 33 of 60 took 1.930s\n",
            "Train \tEpoch [33/60]  train_Loss: 0.4759\ttrain_Acc: 90.23\n",
            "Val \tEpoch [33/60]  val_Loss: 0.5015\tval_Acc: 89.29\n",
            "Test \tEpoch [33/60]  test_Loss: 0.2308\ttest_Acc: 100.00\n",
            "--------------------------------------------------\n",
            "Epoch 34 of 60 took 1.944s\n",
            "Train \tEpoch [34/60]  train_Loss: 0.4752\ttrain_Acc: 89.80\n",
            "Val \tEpoch [34/60]  val_Loss: 0.4870\tval_Acc: 90.31\n",
            "Test \tEpoch [34/60]  test_Loss: 0.2225\ttest_Acc: 100.00\n",
            "--------------------------------------------------\n",
            "Epoch 35 of 60 took 1.939s\n",
            "Train \tEpoch [35/60]  train_Loss: 0.4693\ttrain_Acc: 90.15\n",
            "Val \tEpoch [35/60]  val_Loss: 0.4920\tval_Acc: 87.76\n",
            "Test \tEpoch [35/60]  test_Loss: 0.2271\ttest_Acc: 99.49\n",
            "--------------------------------------------------\n",
            "Epoch 36 of 60 took 1.939s\n",
            "Train \tEpoch [36/60]  train_Loss: 0.4586\ttrain_Acc: 90.06\n",
            "Val \tEpoch [36/60]  val_Loss: 0.4802\tval_Acc: 89.80\n",
            "Test \tEpoch [36/60]  test_Loss: 0.2287\ttest_Acc: 99.49\n",
            "--------------------------------------------------\n",
            "Epoch 37 of 60 took 1.945s\n",
            "Train \tEpoch [37/60]  train_Loss: 0.4437\ttrain_Acc: 90.54\n",
            "Val \tEpoch [37/60]  val_Loss: 0.5133\tval_Acc: 89.29\n",
            "Test \tEpoch [37/60]  test_Loss: 0.2238\ttest_Acc: 100.00\n",
            "--------------------------------------------------\n",
            "Epoch 38 of 60 took 1.939s\n",
            "Train \tEpoch [38/60]  train_Loss: 0.4377\ttrain_Acc: 90.45\n",
            "Val \tEpoch [38/60]  val_Loss: 0.5008\tval_Acc: 90.31\n",
            "Test \tEpoch [38/60]  test_Loss: 0.2354\ttest_Acc: 99.49\n",
            "--------------------------------------------------\n",
            "Epoch 39 of 60 took 1.936s\n",
            "Train \tEpoch [39/60]  train_Loss: 0.4495\ttrain_Acc: 90.19\n",
            "Val \tEpoch [39/60]  val_Loss: 0.4885\tval_Acc: 88.78\n",
            "Test \tEpoch [39/60]  test_Loss: 0.2179\ttest_Acc: 100.00\n",
            "--------------------------------------------------\n",
            "Epoch 40 of 60 took 1.944s\n",
            "Train \tEpoch [40/60]  train_Loss: 0.4251\ttrain_Acc: 91.06\n",
            "Val \tEpoch [40/60]  val_Loss: 0.4555\tval_Acc: 89.80\n",
            "Test \tEpoch [40/60]  test_Loss: 0.2188\ttest_Acc: 99.49\n",
            "--------------------------------------------------\n",
            "Epoch 41 of 60 took 1.988s\n",
            "Train \tEpoch [41/60]  train_Loss: 0.4246\ttrain_Acc: 91.02\n",
            "Val \tEpoch [41/60]  val_Loss: 0.4932\tval_Acc: 90.82\n",
            "Test \tEpoch [41/60]  test_Loss: 0.2310\ttest_Acc: 99.49\n",
            "--------------------------------------------------\n",
            "Epoch 42 of 60 took 1.983s\n",
            "Train \tEpoch [42/60]  train_Loss: 0.4190\ttrain_Acc: 91.13\n",
            "Val \tEpoch [42/60]  val_Loss: 0.4566\tval_Acc: 89.80\n",
            "Test \tEpoch [42/60]  test_Loss: 0.2185\ttest_Acc: 100.00\n",
            "--------------------------------------------------\n",
            "Time in total: 131.65471172332764\n",
            "Best validation accuracy:\t\t90.82 %\n",
            "Test accuracy when got the best validation accuracy:\t\t100.00 %\n",
            "--------------------------------------------------\n",
            "Last train accuracy:\t\t94.86 %\n",
            "Last validation accuracy:\t\t89.80 %\n",
            "Last test accuracy:\t\t\t\t100.00 %\n",
            "Early Stopping at epoch: 32\n",
            "Done!\n",
            "----------------------------------------------------------------------------------------------------\n",
            "The subjects 5 \t\t Training the 1dconv Model...\n",
            "Load the CNN model weight for backbone...\n",
            "Train set label and proportion:\t (array([0, 1, 2, 3], dtype=int32), array([637, 612, 538, 481]))\n",
            "Val   set label and proportion:\t (array([0, 1, 2, 3], dtype=int32), array([62, 49, 55, 35]))\n",
            "Test  set label and proportion:\t (array([0, 1, 2, 3], dtype=int32), array([58, 54, 47, 42]))\n",
            "The shape of X_trian:\t (7, 2268, 32, 32, 3)\n",
            "The shape of X_val:\t (7, 201, 32, 32, 3)\n",
            "The shape of X_test:\t (7, 201, 32, 32, 3)\n",
            "Building model and compiling functions...\n",
            "Writing to /content/runs/2020-02-05.14.17_1dconv/1dconv_5\n",
            "\n",
            "Starting training...\n",
            "--------------------------------------------------\n",
            "Epoch 1 of 60 took 2.738s\n",
            "Train \tEpoch [1/60]  train_Loss: 4.5226\ttrain_Acc: 34.26\n",
            "Val \tEpoch [1/60]  val_Loss: 1.4954\tval_Acc: 55.72\n",
            "Test \tEpoch [1/60]  test_Loss: 1.5448\ttest_Acc: 40.80\n",
            "--------------------------------------------------\n",
            "Epoch 2 of 60 took 1.907s\n",
            "Train \tEpoch [2/60]  train_Loss: 1.6606\ttrain_Acc: 38.36\n",
            "Val \tEpoch [2/60]  val_Loss: 1.3844\tval_Acc: 54.23\n",
            "Test \tEpoch [2/60]  test_Loss: 1.4776\ttest_Acc: 44.28\n",
            "--------------------------------------------------\n",
            "Epoch 3 of 60 took 1.929s\n",
            "Train \tEpoch [3/60]  train_Loss: 1.5287\ttrain_Acc: 43.56\n",
            "Val \tEpoch [3/60]  val_Loss: 1.3516\tval_Acc: 60.20\n",
            "Test \tEpoch [3/60]  test_Loss: 1.4072\ttest_Acc: 51.24\n",
            "--------------------------------------------------\n",
            "Epoch 4 of 60 took 1.935s\n",
            "Train \tEpoch [4/60]  train_Loss: 1.4122\ttrain_Acc: 49.41\n",
            "Val \tEpoch [4/60]  val_Loss: 1.2721\tval_Acc: 60.70\n",
            "Test \tEpoch [4/60]  test_Loss: 1.3544\ttest_Acc: 59.70\n",
            "--------------------------------------------------\n",
            "Epoch 5 of 60 took 1.929s\n",
            "Train \tEpoch [5/60]  train_Loss: 1.3774\ttrain_Acc: 49.77\n",
            "Val \tEpoch [5/60]  val_Loss: 1.1771\tval_Acc: 67.66\n",
            "Test \tEpoch [5/60]  test_Loss: 1.2631\ttest_Acc: 61.69\n",
            "--------------------------------------------------\n",
            "Epoch 6 of 60 took 1.939s\n",
            "Train \tEpoch [6/60]  train_Loss: 1.3036\ttrain_Acc: 53.52\n",
            "Val \tEpoch [6/60]  val_Loss: 1.1738\tval_Acc: 74.63\n",
            "Test \tEpoch [6/60]  test_Loss: 1.1858\ttest_Acc: 73.63\n",
            "--------------------------------------------------\n",
            "Epoch 7 of 60 took 1.955s\n",
            "Train \tEpoch [7/60]  train_Loss: 1.2323\ttrain_Acc: 57.65\n",
            "Val \tEpoch [7/60]  val_Loss: 0.9837\tval_Acc: 75.62\n",
            "Test \tEpoch [7/60]  test_Loss: 1.0250\ttest_Acc: 73.63\n",
            "--------------------------------------------------\n",
            "Epoch 8 of 60 took 1.946s\n",
            "Train \tEpoch [8/60]  train_Loss: 1.1473\ttrain_Acc: 60.37\n",
            "Val \tEpoch [8/60]  val_Loss: 0.8862\tval_Acc: 83.08\n",
            "Test \tEpoch [8/60]  test_Loss: 0.8769\ttest_Acc: 77.61\n",
            "--------------------------------------------------\n",
            "Epoch 9 of 60 took 1.935s\n",
            "Train \tEpoch [9/60]  train_Loss: 1.0814\ttrain_Acc: 64.51\n",
            "Val \tEpoch [9/60]  val_Loss: 0.8633\tval_Acc: 83.58\n",
            "Test \tEpoch [9/60]  test_Loss: 0.8645\ttest_Acc: 82.09\n",
            "--------------------------------------------------\n",
            "Epoch 10 of 60 took 1.937s\n",
            "Train \tEpoch [10/60]  train_Loss: 0.9868\ttrain_Acc: 68.05\n",
            "Val \tEpoch [10/60]  val_Loss: 0.7998\tval_Acc: 87.06\n",
            "Test \tEpoch [10/60]  test_Loss: 0.8194\ttest_Acc: 81.59\n",
            "--------------------------------------------------\n",
            "Epoch 11 of 60 took 1.954s\n",
            "Train \tEpoch [11/60]  train_Loss: 0.9589\ttrain_Acc: 69.71\n",
            "Val \tEpoch [11/60]  val_Loss: 0.7556\tval_Acc: 85.07\n",
            "Test \tEpoch [11/60]  test_Loss: 0.7260\ttest_Acc: 86.57\n",
            "--------------------------------------------------\n",
            "Epoch 12 of 60 took 1.979s\n",
            "Train \tEpoch [12/60]  train_Loss: 0.9005\ttrain_Acc: 72.76\n",
            "Val \tEpoch [12/60]  val_Loss: 0.6655\tval_Acc: 90.05\n",
            "Test \tEpoch [12/60]  test_Loss: 0.6138\ttest_Acc: 91.54\n",
            "--------------------------------------------------\n",
            "Epoch 13 of 60 took 1.919s\n",
            "Train \tEpoch [13/60]  train_Loss: 0.8497\ttrain_Acc: 74.86\n",
            "Val \tEpoch [13/60]  val_Loss: 0.6112\tval_Acc: 87.06\n",
            "Test \tEpoch [13/60]  test_Loss: 0.6072\ttest_Acc: 87.06\n",
            "--------------------------------------------------\n",
            "Epoch 14 of 60 took 1.915s\n",
            "Train \tEpoch [14/60]  train_Loss: 0.7905\ttrain_Acc: 78.76\n",
            "Val \tEpoch [14/60]  val_Loss: 0.5526\tval_Acc: 88.56\n",
            "Test \tEpoch [14/60]  test_Loss: 0.5152\ttest_Acc: 88.56\n",
            "--------------------------------------------------\n",
            "Epoch 15 of 60 took 1.924s\n",
            "Train \tEpoch [15/60]  train_Loss: 0.7420\ttrain_Acc: 80.89\n",
            "Val \tEpoch [15/60]  val_Loss: 0.5845\tval_Acc: 88.06\n",
            "Test \tEpoch [15/60]  test_Loss: 0.4988\ttest_Acc: 87.56\n",
            "--------------------------------------------------\n",
            "Epoch 16 of 60 took 1.925s\n",
            "Train \tEpoch [16/60]  train_Loss: 0.6849\ttrain_Acc: 83.44\n",
            "Val \tEpoch [16/60]  val_Loss: 0.5245\tval_Acc: 90.55\n",
            "Test \tEpoch [16/60]  test_Loss: 0.4429\ttest_Acc: 95.52\n",
            "--------------------------------------------------\n",
            "Epoch 17 of 60 took 1.937s\n",
            "Train \tEpoch [17/60]  train_Loss: 0.6551\ttrain_Acc: 83.80\n",
            "Val \tEpoch [17/60]  val_Loss: 0.5266\tval_Acc: 90.05\n",
            "Test \tEpoch [17/60]  test_Loss: 0.3954\ttest_Acc: 95.02\n",
            "--------------------------------------------------\n",
            "Epoch 18 of 60 took 1.922s\n",
            "Train \tEpoch [18/60]  train_Loss: 0.6737\ttrain_Acc: 84.19\n",
            "Val \tEpoch [18/60]  val_Loss: 0.4848\tval_Acc: 89.55\n",
            "Test \tEpoch [18/60]  test_Loss: 0.3797\ttest_Acc: 96.52\n",
            "--------------------------------------------------\n",
            "Epoch 19 of 60 took 1.942s\n",
            "Train \tEpoch [19/60]  train_Loss: 0.6312\ttrain_Acc: 84.49\n",
            "Val \tEpoch [19/60]  val_Loss: 0.4429\tval_Acc: 92.04\n",
            "Test \tEpoch [19/60]  test_Loss: 0.3164\ttest_Acc: 98.01\n",
            "--------------------------------------------------\n",
            "Epoch 20 of 60 took 1.918s\n",
            "Train \tEpoch [20/60]  train_Loss: 0.6074\ttrain_Acc: 85.78\n",
            "Val \tEpoch [20/60]  val_Loss: 0.4727\tval_Acc: 90.55\n",
            "Test \tEpoch [20/60]  test_Loss: 0.3467\ttest_Acc: 97.01\n",
            "--------------------------------------------------\n",
            "Epoch 21 of 60 took 1.923s\n",
            "Train \tEpoch [21/60]  train_Loss: 0.6023\ttrain_Acc: 85.87\n",
            "Val \tEpoch [21/60]  val_Loss: 0.4350\tval_Acc: 90.05\n",
            "Test \tEpoch [21/60]  test_Loss: 0.3360\ttest_Acc: 96.52\n",
            "--------------------------------------------------\n",
            "Epoch 22 of 60 took 1.960s\n",
            "Train \tEpoch [22/60]  train_Loss: 0.5674\ttrain_Acc: 86.73\n",
            "Val \tEpoch [22/60]  val_Loss: 0.4299\tval_Acc: 93.53\n",
            "Test \tEpoch [22/60]  test_Loss: 0.3128\ttest_Acc: 98.01\n",
            "--------------------------------------------------\n",
            "Epoch 23 of 60 took 1.936s\n",
            "Train \tEpoch [23/60]  train_Loss: 0.5719\ttrain_Acc: 86.54\n",
            "Val \tEpoch [23/60]  val_Loss: 0.4510\tval_Acc: 90.55\n",
            "Test \tEpoch [23/60]  test_Loss: 0.2969\ttest_Acc: 97.51\n",
            "--------------------------------------------------\n",
            "Epoch 24 of 60 took 1.918s\n",
            "Train \tEpoch [24/60]  train_Loss: 0.5551\ttrain_Acc: 87.75\n",
            "Val \tEpoch [24/60]  val_Loss: 0.4385\tval_Acc: 91.04\n",
            "Test \tEpoch [24/60]  test_Loss: 0.2909\ttest_Acc: 98.01\n",
            "--------------------------------------------------\n",
            "Epoch 25 of 60 took 1.924s\n",
            "Train \tEpoch [25/60]  train_Loss: 0.5359\ttrain_Acc: 88.06\n",
            "Val \tEpoch [25/60]  val_Loss: 0.4184\tval_Acc: 90.55\n",
            "Test \tEpoch [25/60]  test_Loss: 0.2937\ttest_Acc: 98.01\n",
            "--------------------------------------------------\n",
            "Epoch 26 of 60 took 1.920s\n",
            "Train \tEpoch [26/60]  train_Loss: 0.5297\ttrain_Acc: 88.32\n",
            "Val \tEpoch [26/60]  val_Loss: 0.4191\tval_Acc: 90.55\n",
            "Test \tEpoch [26/60]  test_Loss: 0.3148\ttest_Acc: 97.01\n",
            "--------------------------------------------------\n",
            "Epoch 27 of 60 took 1.924s\n",
            "Train \tEpoch [27/60]  train_Loss: 0.5498\ttrain_Acc: 87.05\n",
            "Val \tEpoch [27/60]  val_Loss: 0.4621\tval_Acc: 90.55\n",
            "Test \tEpoch [27/60]  test_Loss: 0.3244\ttest_Acc: 97.01\n",
            "--------------------------------------------------\n",
            "Epoch 28 of 60 took 1.919s\n",
            "Train \tEpoch [28/60]  train_Loss: 0.5223\ttrain_Acc: 87.97\n",
            "Val \tEpoch [28/60]  val_Loss: 0.4016\tval_Acc: 91.54\n",
            "Test \tEpoch [28/60]  test_Loss: 0.2778\ttest_Acc: 99.00\n",
            "--------------------------------------------------\n",
            "Epoch 29 of 60 took 1.917s\n",
            "Train \tEpoch [29/60]  train_Loss: 0.4942\ttrain_Acc: 89.11\n",
            "Val \tEpoch [29/60]  val_Loss: 0.4339\tval_Acc: 90.55\n",
            "Test \tEpoch [29/60]  test_Loss: 0.2887\ttest_Acc: 97.51\n",
            "--------------------------------------------------\n",
            "Epoch 30 of 60 took 1.916s\n",
            "Train \tEpoch [30/60]  train_Loss: 0.4995\ttrain_Acc: 89.25\n",
            "Val \tEpoch [30/60]  val_Loss: 0.4022\tval_Acc: 90.05\n",
            "Test \tEpoch [30/60]  test_Loss: 0.2782\ttest_Acc: 98.01\n",
            "--------------------------------------------------\n",
            "Epoch 31 of 60 took 1.915s\n",
            "Train \tEpoch [31/60]  train_Loss: 0.4873\ttrain_Acc: 89.69\n",
            "Val \tEpoch [31/60]  val_Loss: 0.3997\tval_Acc: 91.54\n",
            "Test \tEpoch [31/60]  test_Loss: 0.2893\ttest_Acc: 97.51\n",
            "--------------------------------------------------\n",
            "Epoch 32 of 60 took 1.937s\n",
            "Train \tEpoch [32/60]  train_Loss: 0.4866\ttrain_Acc: 89.42\n",
            "Val \tEpoch [32/60]  val_Loss: 0.4114\tval_Acc: 90.55\n",
            "Test \tEpoch [32/60]  test_Loss: 0.2674\ttest_Acc: 98.01\n",
            "--------------------------------------------------\n",
            "Time in total: 108.87344098091125\n",
            "Best validation accuracy:\t\t93.53 %\n",
            "Test accuracy when got the best validation accuracy:\t\t98.01 %\n",
            "--------------------------------------------------\n",
            "Last train accuracy:\t\t92.64 %\n",
            "Last validation accuracy:\t\t90.55 %\n",
            "Last test accuracy:\t\t\t\t98.01 %\n",
            "Early Stopping at epoch: 22\n",
            "Done!\n",
            "----------------------------------------------------------------------------------------------------\n",
            "The subjects 6 \t\t Training the 1dconv Model...\n",
            "Load the CNN model weight for backbone...\n",
            "Train set label and proportion:\t (array([0, 1, 2, 3], dtype=int32), array([651, 616, 540, 477]))\n",
            "Val   set label and proportion:\t (array([0, 1, 2, 3], dtype=int32), array([50, 46, 58, 39]))\n",
            "Test  set label and proportion:\t (array([0, 1, 2, 3], dtype=int32), array([56, 53, 42, 42]))\n",
            "The shape of X_trian:\t (7, 2284, 32, 32, 3)\n",
            "The shape of X_val:\t (7, 193, 32, 32, 3)\n",
            "The shape of X_test:\t (7, 193, 32, 32, 3)\n",
            "Building model and compiling functions...\n",
            "Writing to /content/runs/2020-02-05.14.17_1dconv/1dconv_6\n",
            "\n",
            "Starting training...\n",
            "--------------------------------------------------\n",
            "Epoch 1 of 60 took 3.013s\n",
            "Train \tEpoch [1/60]  train_Loss: 5.3511\ttrain_Acc: 29.66\n",
            "Val \tEpoch [1/60]  val_Loss: 1.4245\tval_Acc: 45.60\n",
            "Test \tEpoch [1/60]  test_Loss: 1.6097\ttest_Acc: 40.93\n",
            "--------------------------------------------------\n",
            "Epoch 2 of 60 took 1.948s\n",
            "Train \tEpoch [2/60]  train_Loss: 1.8304\ttrain_Acc: 33.23\n",
            "Val \tEpoch [2/60]  val_Loss: 1.4178\tval_Acc: 46.63\n",
            "Test \tEpoch [2/60]  test_Loss: 1.4912\ttest_Acc: 49.74\n",
            "--------------------------------------------------\n",
            "Epoch 3 of 60 took 1.981s\n",
            "Train \tEpoch [3/60]  train_Loss: 1.6571\ttrain_Acc: 37.67\n",
            "Val \tEpoch [3/60]  val_Loss: 1.3462\tval_Acc: 52.85\n",
            "Test \tEpoch [3/60]  test_Loss: 1.3662\ttest_Acc: 51.81\n",
            "--------------------------------------------------\n",
            "Epoch 4 of 60 took 1.967s\n",
            "Train \tEpoch [4/60]  train_Loss: 1.5438\ttrain_Acc: 43.20\n",
            "Val \tEpoch [4/60]  val_Loss: 1.3471\tval_Acc: 52.33\n",
            "Test \tEpoch [4/60]  test_Loss: 1.3291\ttest_Acc: 55.44\n",
            "--------------------------------------------------\n",
            "Epoch 5 of 60 took 1.953s\n",
            "Train \tEpoch [5/60]  train_Loss: 1.4444\ttrain_Acc: 45.21\n",
            "Val \tEpoch [5/60]  val_Loss: 1.2374\tval_Acc: 53.37\n",
            "Test \tEpoch [5/60]  test_Loss: 1.2112\ttest_Acc: 59.07\n",
            "--------------------------------------------------\n",
            "Epoch 6 of 60 took 1.987s\n",
            "Train \tEpoch [6/60]  train_Loss: 1.3617\ttrain_Acc: 49.38\n",
            "Val \tEpoch [6/60]  val_Loss: 1.2087\tval_Acc: 58.03\n",
            "Test \tEpoch [6/60]  test_Loss: 1.1836\ttest_Acc: 58.03\n",
            "--------------------------------------------------\n",
            "Epoch 7 of 60 took 1.970s\n",
            "Train \tEpoch [7/60]  train_Loss: 1.3273\ttrain_Acc: 49.59\n",
            "Val \tEpoch [7/60]  val_Loss: 1.1696\tval_Acc: 57.51\n",
            "Test \tEpoch [7/60]  test_Loss: 1.1337\ttest_Acc: 66.32\n",
            "--------------------------------------------------\n",
            "Epoch 8 of 60 took 1.977s\n",
            "Train \tEpoch [8/60]  train_Loss: 1.2873\ttrain_Acc: 51.88\n",
            "Val \tEpoch [8/60]  val_Loss: 1.1248\tval_Acc: 64.25\n",
            "Test \tEpoch [8/60]  test_Loss: 1.0848\ttest_Acc: 69.43\n",
            "--------------------------------------------------\n",
            "Epoch 9 of 60 took 1.980s\n",
            "Train \tEpoch [9/60]  train_Loss: 1.1959\ttrain_Acc: 56.81\n",
            "Val \tEpoch [9/60]  val_Loss: 1.0603\tval_Acc: 66.84\n",
            "Test \tEpoch [9/60]  test_Loss: 1.0123\ttest_Acc: 69.95\n",
            "--------------------------------------------------\n",
            "Epoch 10 of 60 took 2.027s\n",
            "Train \tEpoch [10/60]  train_Loss: 1.1636\ttrain_Acc: 58.17\n",
            "Val \tEpoch [10/60]  val_Loss: 1.0047\tval_Acc: 69.95\n",
            "Test \tEpoch [10/60]  test_Loss: 0.9377\ttest_Acc: 74.61\n",
            "--------------------------------------------------\n",
            "Epoch 11 of 60 took 1.975s\n",
            "Train \tEpoch [11/60]  train_Loss: 1.1240\ttrain_Acc: 60.94\n",
            "Val \tEpoch [11/60]  val_Loss: 0.9398\tval_Acc: 74.61\n",
            "Test \tEpoch [11/60]  test_Loss: 0.8658\ttest_Acc: 78.76\n",
            "--------------------------------------------------\n",
            "Epoch 12 of 60 took 1.965s\n",
            "Train \tEpoch [12/60]  train_Loss: 1.0681\ttrain_Acc: 63.70\n",
            "Val \tEpoch [12/60]  val_Loss: 0.9365\tval_Acc: 80.31\n",
            "Test \tEpoch [12/60]  test_Loss: 0.8746\ttest_Acc: 81.87\n",
            "--------------------------------------------------\n",
            "Epoch 13 of 60 took 1.977s\n",
            "Train \tEpoch [13/60]  train_Loss: 1.0068\ttrain_Acc: 67.74\n",
            "Val \tEpoch [13/60]  val_Loss: 0.8149\tval_Acc: 80.31\n",
            "Test \tEpoch [13/60]  test_Loss: 0.7521\ttest_Acc: 84.46\n",
            "--------------------------------------------------\n",
            "Epoch 14 of 60 took 1.935s\n",
            "Train \tEpoch [14/60]  train_Loss: 0.9521\ttrain_Acc: 71.27\n",
            "Val \tEpoch [14/60]  val_Loss: 0.7953\tval_Acc: 80.31\n",
            "Test \tEpoch [14/60]  test_Loss: 0.7688\ttest_Acc: 83.42\n",
            "--------------------------------------------------\n",
            "Epoch 15 of 60 took 2.014s\n",
            "Train \tEpoch [15/60]  train_Loss: 0.9172\ttrain_Acc: 71.60\n",
            "Val \tEpoch [15/60]  val_Loss: 0.7189\tval_Acc: 83.42\n",
            "Test \tEpoch [15/60]  test_Loss: 0.6601\ttest_Acc: 86.53\n",
            "--------------------------------------------------\n",
            "Epoch 16 of 60 took 1.978s\n",
            "Train \tEpoch [16/60]  train_Loss: 0.8504\ttrain_Acc: 75.14\n",
            "Val \tEpoch [16/60]  val_Loss: 0.6913\tval_Acc: 85.49\n",
            "Test \tEpoch [16/60]  test_Loss: 0.6281\ttest_Acc: 90.16\n",
            "--------------------------------------------------\n",
            "Epoch 17 of 60 took 1.969s\n",
            "Train \tEpoch [17/60]  train_Loss: 0.8329\ttrain_Acc: 75.90\n",
            "Val \tEpoch [17/60]  val_Loss: 0.6279\tval_Acc: 87.56\n",
            "Test \tEpoch [17/60]  test_Loss: 0.5219\ttest_Acc: 93.78\n",
            "--------------------------------------------------\n",
            "Epoch 18 of 60 took 1.976s\n",
            "Train \tEpoch [18/60]  train_Loss: 0.7693\ttrain_Acc: 78.63\n",
            "Val \tEpoch [18/60]  val_Loss: 0.5874\tval_Acc: 87.05\n",
            "Test \tEpoch [18/60]  test_Loss: 0.5012\ttest_Acc: 92.23\n",
            "--------------------------------------------------\n",
            "Epoch 19 of 60 took 1.966s\n",
            "Train \tEpoch [19/60]  train_Loss: 0.7286\ttrain_Acc: 78.67\n",
            "Val \tEpoch [19/60]  val_Loss: 0.5741\tval_Acc: 86.53\n",
            "Test \tEpoch [19/60]  test_Loss: 0.4649\ttest_Acc: 93.26\n",
            "--------------------------------------------------\n",
            "Epoch 20 of 60 took 1.979s\n",
            "Train \tEpoch [20/60]  train_Loss: 0.7191\ttrain_Acc: 79.63\n",
            "Val \tEpoch [20/60]  val_Loss: 0.5106\tval_Acc: 89.12\n",
            "Test \tEpoch [20/60]  test_Loss: 0.4309\ttest_Acc: 93.78\n",
            "--------------------------------------------------\n",
            "Epoch 21 of 60 took 1.974s\n",
            "Train \tEpoch [21/60]  train_Loss: 0.6632\ttrain_Acc: 81.99\n",
            "Val \tEpoch [21/60]  val_Loss: 0.5129\tval_Acc: 89.64\n",
            "Test \tEpoch [21/60]  test_Loss: 0.3805\ttest_Acc: 95.85\n",
            "--------------------------------------------------\n",
            "Epoch 22 of 60 took 1.961s\n",
            "Train \tEpoch [22/60]  train_Loss: 0.6410\ttrain_Acc: 83.45\n",
            "Val \tEpoch [22/60]  val_Loss: 0.4976\tval_Acc: 89.64\n",
            "Test \tEpoch [22/60]  test_Loss: 0.4040\ttest_Acc: 94.82\n",
            "--------------------------------------------------\n",
            "Epoch 23 of 60 took 1.947s\n",
            "Train \tEpoch [23/60]  train_Loss: 0.6525\ttrain_Acc: 83.52\n",
            "Val \tEpoch [23/60]  val_Loss: 0.4862\tval_Acc: 88.60\n",
            "Test \tEpoch [23/60]  test_Loss: 0.4248\ttest_Acc: 94.30\n",
            "--------------------------------------------------\n",
            "Epoch 24 of 60 took 1.958s\n",
            "Train \tEpoch [24/60]  train_Loss: 0.6289\ttrain_Acc: 83.87\n",
            "Val \tEpoch [24/60]  val_Loss: 0.4591\tval_Acc: 90.67\n",
            "Test \tEpoch [24/60]  test_Loss: 0.3476\ttest_Acc: 96.37\n",
            "--------------------------------------------------\n",
            "Epoch 25 of 60 took 2.003s\n",
            "Train \tEpoch [25/60]  train_Loss: 0.5809\ttrain_Acc: 85.34\n",
            "Val \tEpoch [25/60]  val_Loss: 0.4778\tval_Acc: 89.64\n",
            "Test \tEpoch [25/60]  test_Loss: 0.3723\ttest_Acc: 95.85\n",
            "--------------------------------------------------\n",
            "Epoch 26 of 60 took 1.953s\n",
            "Train \tEpoch [26/60]  train_Loss: 0.5855\ttrain_Acc: 85.39\n",
            "Val \tEpoch [26/60]  val_Loss: 0.4753\tval_Acc: 88.60\n",
            "Test \tEpoch [26/60]  test_Loss: 0.4032\ttest_Acc: 94.30\n",
            "--------------------------------------------------\n",
            "Epoch 27 of 60 took 1.945s\n",
            "Train \tEpoch [27/60]  train_Loss: 0.5799\ttrain_Acc: 85.33\n",
            "Val \tEpoch [27/60]  val_Loss: 0.4502\tval_Acc: 90.67\n",
            "Test \tEpoch [27/60]  test_Loss: 0.3476\ttest_Acc: 97.41\n",
            "--------------------------------------------------\n",
            "Epoch 28 of 60 took 1.958s\n",
            "Train \tEpoch [28/60]  train_Loss: 0.5486\ttrain_Acc: 87.11\n",
            "Val \tEpoch [28/60]  val_Loss: 0.4330\tval_Acc: 91.19\n",
            "Test \tEpoch [28/60]  test_Loss: 0.3593\ttest_Acc: 95.85\n",
            "--------------------------------------------------\n",
            "Epoch 29 of 60 took 1.960s\n",
            "Train \tEpoch [29/60]  train_Loss: 0.5316\ttrain_Acc: 86.46\n",
            "Val \tEpoch [29/60]  val_Loss: 0.4337\tval_Acc: 89.64\n",
            "Test \tEpoch [29/60]  test_Loss: 0.3442\ttest_Acc: 95.34\n",
            "--------------------------------------------------\n",
            "Epoch 30 of 60 took 1.959s\n",
            "Train \tEpoch [30/60]  train_Loss: 0.5160\ttrain_Acc: 87.63\n",
            "Val \tEpoch [30/60]  val_Loss: 0.4540\tval_Acc: 90.16\n",
            "Test \tEpoch [30/60]  test_Loss: 0.3333\ttest_Acc: 94.30\n",
            "--------------------------------------------------\n",
            "Epoch 31 of 60 took 1.956s\n",
            "Train \tEpoch [31/60]  train_Loss: 0.5340\ttrain_Acc: 86.70\n",
            "Val \tEpoch [31/60]  val_Loss: 0.4176\tval_Acc: 90.67\n",
            "Test \tEpoch [31/60]  test_Loss: 0.3227\ttest_Acc: 96.89\n",
            "--------------------------------------------------\n",
            "Epoch 32 of 60 took 1.949s\n",
            "Train \tEpoch [32/60]  train_Loss: 0.5194\ttrain_Acc: 87.34\n",
            "Val \tEpoch [32/60]  val_Loss: 0.4331\tval_Acc: 90.67\n",
            "Test \tEpoch [32/60]  test_Loss: 0.3382\ttest_Acc: 96.89\n",
            "--------------------------------------------------\n",
            "Epoch 33 of 60 took 1.961s\n",
            "Train \tEpoch [33/60]  train_Loss: 0.5189\ttrain_Acc: 87.56\n",
            "Val \tEpoch [33/60]  val_Loss: 0.4086\tval_Acc: 91.71\n",
            "Test \tEpoch [33/60]  test_Loss: 0.3224\ttest_Acc: 96.89\n",
            "--------------------------------------------------\n",
            "Epoch 34 of 60 took 1.953s\n",
            "Train \tEpoch [34/60]  train_Loss: 0.5016\ttrain_Acc: 88.70\n",
            "Val \tEpoch [34/60]  val_Loss: 0.4189\tval_Acc: 91.19\n",
            "Test \tEpoch [34/60]  test_Loss: 0.3495\ttest_Acc: 96.89\n",
            "--------------------------------------------------\n",
            "Epoch 35 of 60 took 1.956s\n",
            "Train \tEpoch [35/60]  train_Loss: 0.4948\ttrain_Acc: 88.59\n",
            "Val \tEpoch [35/60]  val_Loss: 0.4020\tval_Acc: 91.71\n",
            "Test \tEpoch [35/60]  test_Loss: 0.3080\ttest_Acc: 97.93\n",
            "--------------------------------------------------\n",
            "Epoch 36 of 60 took 1.943s\n",
            "Train \tEpoch [36/60]  train_Loss: 0.4778\ttrain_Acc: 88.90\n",
            "Val \tEpoch [36/60]  val_Loss: 0.4045\tval_Acc: 91.19\n",
            "Test \tEpoch [36/60]  test_Loss: 0.3079\ttest_Acc: 97.93\n",
            "--------------------------------------------------\n",
            "Epoch 37 of 60 took 1.971s\n",
            "Train \tEpoch [37/60]  train_Loss: 0.4781\ttrain_Acc: 89.18\n",
            "Val \tEpoch [37/60]  val_Loss: 0.4029\tval_Acc: 91.19\n",
            "Test \tEpoch [37/60]  test_Loss: 0.2996\ttest_Acc: 97.41\n",
            "--------------------------------------------------\n",
            "Epoch 38 of 60 took 1.976s\n",
            "Train \tEpoch [38/60]  train_Loss: 0.4814\ttrain_Acc: 89.13\n",
            "Val \tEpoch [38/60]  val_Loss: 0.3991\tval_Acc: 91.19\n",
            "Test \tEpoch [38/60]  test_Loss: 0.3130\ttest_Acc: 96.89\n",
            "--------------------------------------------------\n",
            "Epoch 39 of 60 took 2.013s\n",
            "Train \tEpoch [39/60]  train_Loss: 0.4665\ttrain_Acc: 89.13\n",
            "Val \tEpoch [39/60]  val_Loss: 0.3890\tval_Acc: 90.67\n",
            "Test \tEpoch [39/60]  test_Loss: 0.3007\ttest_Acc: 98.96\n",
            "--------------------------------------------------\n",
            "Epoch 40 of 60 took 1.969s\n",
            "Train \tEpoch [40/60]  train_Loss: 0.4683\ttrain_Acc: 89.41\n",
            "Val \tEpoch [40/60]  val_Loss: 0.3896\tval_Acc: 91.71\n",
            "Test \tEpoch [40/60]  test_Loss: 0.2957\ttest_Acc: 97.41\n",
            "--------------------------------------------------\n",
            "Epoch 41 of 60 took 1.981s\n",
            "Train \tEpoch [41/60]  train_Loss: 0.4479\ttrain_Acc: 90.97\n",
            "Val \tEpoch [41/60]  val_Loss: 0.3843\tval_Acc: 93.26\n",
            "Test \tEpoch [41/60]  test_Loss: 0.2631\ttest_Acc: 98.96\n",
            "--------------------------------------------------\n",
            "Epoch 42 of 60 took 1.944s\n",
            "Train \tEpoch [42/60]  train_Loss: 0.4568\ttrain_Acc: 89.58\n",
            "Val \tEpoch [42/60]  val_Loss: 0.3837\tval_Acc: 92.23\n",
            "Test \tEpoch [42/60]  test_Loss: 0.2821\ttest_Acc: 98.96\n",
            "--------------------------------------------------\n",
            "Epoch 43 of 60 took 1.961s\n",
            "Train \tEpoch [43/60]  train_Loss: 0.4415\ttrain_Acc: 90.25\n",
            "Val \tEpoch [43/60]  val_Loss: 0.3825\tval_Acc: 91.19\n",
            "Test \tEpoch [43/60]  test_Loss: 0.3044\ttest_Acc: 97.93\n",
            "--------------------------------------------------\n",
            "Epoch 44 of 60 took 2.004s\n",
            "Train \tEpoch [44/60]  train_Loss: 0.4691\ttrain_Acc: 88.92\n",
            "Val \tEpoch [44/60]  val_Loss: 0.3921\tval_Acc: 91.71\n",
            "Test \tEpoch [44/60]  test_Loss: 0.2925\ttest_Acc: 97.93\n",
            "--------------------------------------------------\n",
            "Epoch 45 of 60 took 1.963s\n",
            "Train \tEpoch [45/60]  train_Loss: 0.4404\ttrain_Acc: 90.28\n",
            "Val \tEpoch [45/60]  val_Loss: 0.3787\tval_Acc: 92.23\n",
            "Test \tEpoch [45/60]  test_Loss: 0.2703\ttest_Acc: 97.93\n",
            "--------------------------------------------------\n",
            "Epoch 46 of 60 took 1.939s\n",
            "Train \tEpoch [46/60]  train_Loss: 0.4249\ttrain_Acc: 90.99\n",
            "Val \tEpoch [46/60]  val_Loss: 0.3814\tval_Acc: 91.71\n",
            "Test \tEpoch [46/60]  test_Loss: 0.2778\ttest_Acc: 97.93\n",
            "--------------------------------------------------\n",
            "Epoch 47 of 60 took 1.940s\n",
            "Train \tEpoch [47/60]  train_Loss: 0.4433\ttrain_Acc: 90.65\n",
            "Val \tEpoch [47/60]  val_Loss: 0.3789\tval_Acc: 91.19\n",
            "Test \tEpoch [47/60]  test_Loss: 0.2953\ttest_Acc: 98.45\n",
            "--------------------------------------------------\n",
            "Epoch 48 of 60 took 1.960s\n",
            "Train \tEpoch [48/60]  train_Loss: 0.4255\ttrain_Acc: 90.68\n",
            "Val \tEpoch [48/60]  val_Loss: 0.3793\tval_Acc: 91.71\n",
            "Test \tEpoch [48/60]  test_Loss: 0.2943\ttest_Acc: 97.41\n",
            "--------------------------------------------------\n",
            "Epoch 49 of 60 took 1.965s\n",
            "Train \tEpoch [49/60]  train_Loss: 0.4151\ttrain_Acc: 90.87\n",
            "Val \tEpoch [49/60]  val_Loss: 0.3820\tval_Acc: 91.71\n",
            "Test \tEpoch [49/60]  test_Loss: 0.2866\ttest_Acc: 97.41\n",
            "--------------------------------------------------\n",
            "Epoch 50 of 60 took 1.954s\n",
            "Train \tEpoch [50/60]  train_Loss: 0.4260\ttrain_Acc: 90.90\n",
            "Val \tEpoch [50/60]  val_Loss: 0.3892\tval_Acc: 90.16\n",
            "Test \tEpoch [50/60]  test_Loss: 0.2839\ttest_Acc: 96.89\n",
            "--------------------------------------------------\n",
            "Epoch 51 of 60 took 1.956s\n",
            "Train \tEpoch [51/60]  train_Loss: 0.4385\ttrain_Acc: 89.66\n",
            "Val \tEpoch [51/60]  val_Loss: 0.4181\tval_Acc: 90.16\n",
            "Test \tEpoch [51/60]  test_Loss: 0.2653\ttest_Acc: 98.45\n",
            "--------------------------------------------------\n",
            "Time in total: 151.03079795837402\n",
            "Best validation accuracy:\t\t93.26 %\n",
            "Test accuracy when got the best validation accuracy:\t\t98.96 %\n",
            "--------------------------------------------------\n",
            "Last train accuracy:\t\t94.00 %\n",
            "Last validation accuracy:\t\t90.16 %\n",
            "Last test accuracy:\t\t\t\t98.45 %\n",
            "Early Stopping at epoch: 41\n",
            "Done!\n",
            "----------------------------------------------------------------------------------------------------\n",
            "The subjects 7 \t\t Training the 1dconv Model...\n",
            "Load the CNN model weight for backbone...\n",
            "Train set label and proportion:\t (array([0, 1, 2, 3], dtype=int32), array([650, 592, 540, 484]))\n",
            "Val   set label and proportion:\t (array([0, 1, 2, 3], dtype=int32), array([49, 65, 50, 38]))\n",
            "Test  set label and proportion:\t (array([0, 1, 2, 3], dtype=int32), array([58, 58, 50, 36]))\n",
            "The shape of X_trian:\t (7, 2266, 32, 32, 3)\n",
            "The shape of X_val:\t (7, 202, 32, 32, 3)\n",
            "The shape of X_test:\t (7, 202, 32, 32, 3)\n",
            "Building model and compiling functions...\n",
            "Writing to /content/runs/2020-02-05.14.17_1dconv/1dconv_7\n",
            "\n",
            "Starting training...\n",
            "--------------------------------------------------\n",
            "Epoch 1 of 60 took 3.064s\n",
            "Train \tEpoch [1/60]  train_Loss: 5.8794\ttrain_Acc: 30.23\n",
            "Val \tEpoch [1/60]  val_Loss: 1.5831\tval_Acc: 44.55\n",
            "Test \tEpoch [1/60]  test_Loss: 1.5685\ttest_Acc: 41.58\n",
            "--------------------------------------------------\n",
            "Epoch 2 of 60 took 1.940s\n",
            "Train \tEpoch [2/60]  train_Loss: 1.8573\ttrain_Acc: 31.13\n",
            "Val \tEpoch [2/60]  val_Loss: 1.5374\tval_Acc: 37.13\n",
            "Test \tEpoch [2/60]  test_Loss: 1.4529\ttest_Acc: 47.03\n",
            "--------------------------------------------------\n",
            "Epoch 3 of 60 took 1.946s\n",
            "Train \tEpoch [3/60]  train_Loss: 1.7275\ttrain_Acc: 31.93\n",
            "Val \tEpoch [3/60]  val_Loss: 1.5242\tval_Acc: 50.99\n",
            "Test \tEpoch [3/60]  test_Loss: 1.4920\ttest_Acc: 41.09\n",
            "--------------------------------------------------\n",
            "Epoch 4 of 60 took 1.980s\n",
            "Train \tEpoch [4/60]  train_Loss: 1.6130\ttrain_Acc: 35.72\n",
            "Val \tEpoch [4/60]  val_Loss: 1.4257\tval_Acc: 59.41\n",
            "Test \tEpoch [4/60]  test_Loss: 1.3773\ttest_Acc: 48.02\n",
            "--------------------------------------------------\n",
            "Epoch 5 of 60 took 2.145s\n",
            "Train \tEpoch [5/60]  train_Loss: 1.5355\ttrain_Acc: 39.17\n",
            "Val \tEpoch [5/60]  val_Loss: 1.3771\tval_Acc: 57.92\n",
            "Test \tEpoch [5/60]  test_Loss: 1.3669\ttest_Acc: 49.01\n",
            "--------------------------------------------------\n",
            "Epoch 6 of 60 took 1.987s\n",
            "Train \tEpoch [6/60]  train_Loss: 1.4838\ttrain_Acc: 41.24\n",
            "Val \tEpoch [6/60]  val_Loss: 1.3032\tval_Acc: 51.98\n",
            "Test \tEpoch [6/60]  test_Loss: 1.2698\ttest_Acc: 52.97\n",
            "--------------------------------------------------\n",
            "Epoch 7 of 60 took 1.957s\n",
            "Train \tEpoch [7/60]  train_Loss: 1.4265\ttrain_Acc: 43.51\n",
            "Val \tEpoch [7/60]  val_Loss: 1.2777\tval_Acc: 60.89\n",
            "Test \tEpoch [7/60]  test_Loss: 1.2434\ttest_Acc: 64.36\n",
            "--------------------------------------------------\n",
            "Epoch 8 of 60 took 1.961s\n",
            "Train \tEpoch [8/60]  train_Loss: 1.3785\ttrain_Acc: 47.54\n",
            "Val \tEpoch [8/60]  val_Loss: 1.1969\tval_Acc: 69.31\n",
            "Test \tEpoch [8/60]  test_Loss: 1.1627\ttest_Acc: 63.37\n",
            "--------------------------------------------------\n",
            "Epoch 9 of 60 took 1.983s\n",
            "Train \tEpoch [9/60]  train_Loss: 1.3504\ttrain_Acc: 49.09\n",
            "Val \tEpoch [9/60]  val_Loss: 1.1971\tval_Acc: 71.29\n",
            "Test \tEpoch [9/60]  test_Loss: 1.1379\ttest_Acc: 75.74\n",
            "--------------------------------------------------\n",
            "Epoch 10 of 60 took 1.956s\n",
            "Train \tEpoch [10/60]  train_Loss: 1.3079\ttrain_Acc: 52.00\n",
            "Val \tEpoch [10/60]  val_Loss: 1.0668\tval_Acc: 73.76\n",
            "Test \tEpoch [10/60]  test_Loss: 1.0481\ttest_Acc: 75.25\n",
            "--------------------------------------------------\n",
            "Epoch 11 of 60 took 1.951s\n",
            "Train \tEpoch [11/60]  train_Loss: 1.2402\ttrain_Acc: 54.86\n",
            "Val \tEpoch [11/60]  val_Loss: 1.0232\tval_Acc: 74.26\n",
            "Test \tEpoch [11/60]  test_Loss: 0.9937\ttest_Acc: 85.15\n",
            "--------------------------------------------------\n",
            "Epoch 12 of 60 took 1.936s\n",
            "Train \tEpoch [12/60]  train_Loss: 1.1985\ttrain_Acc: 58.12\n",
            "Val \tEpoch [12/60]  val_Loss: 0.9687\tval_Acc: 74.75\n",
            "Test \tEpoch [12/60]  test_Loss: 0.9509\ttest_Acc: 77.72\n",
            "--------------------------------------------------\n",
            "Epoch 13 of 60 took 1.974s\n",
            "Train \tEpoch [13/60]  train_Loss: 1.1782\ttrain_Acc: 59.55\n",
            "Val \tEpoch [13/60]  val_Loss: 0.8694\tval_Acc: 77.72\n",
            "Test \tEpoch [13/60]  test_Loss: 0.8298\ttest_Acc: 82.67\n",
            "--------------------------------------------------\n",
            "Epoch 14 of 60 took 1.950s\n",
            "Train \tEpoch [14/60]  train_Loss: 1.1097\ttrain_Acc: 61.93\n",
            "Val \tEpoch [14/60]  val_Loss: 0.8437\tval_Acc: 78.22\n",
            "Test \tEpoch [14/60]  test_Loss: 0.7779\ttest_Acc: 83.66\n",
            "--------------------------------------------------\n",
            "Epoch 15 of 60 took 1.967s\n",
            "Train \tEpoch [15/60]  train_Loss: 1.0392\ttrain_Acc: 65.58\n",
            "Val \tEpoch [15/60]  val_Loss: 0.7972\tval_Acc: 79.70\n",
            "Test \tEpoch [15/60]  test_Loss: 0.7195\ttest_Acc: 84.65\n",
            "--------------------------------------------------\n",
            "Epoch 16 of 60 took 1.951s\n",
            "Train \tEpoch [16/60]  train_Loss: 1.0068\ttrain_Acc: 66.90\n",
            "Val \tEpoch [16/60]  val_Loss: 0.7363\tval_Acc: 79.70\n",
            "Test \tEpoch [16/60]  test_Loss: 0.6400\ttest_Acc: 88.61\n",
            "--------------------------------------------------\n",
            "Epoch 17 of 60 took 1.952s\n",
            "Train \tEpoch [17/60]  train_Loss: 0.9484\ttrain_Acc: 70.14\n",
            "Val \tEpoch [17/60]  val_Loss: 0.7429\tval_Acc: 79.21\n",
            "Test \tEpoch [17/60]  test_Loss: 0.6218\ttest_Acc: 89.11\n",
            "--------------------------------------------------\n",
            "Epoch 18 of 60 took 1.976s\n",
            "Train \tEpoch [18/60]  train_Loss: 0.9023\ttrain_Acc: 73.42\n",
            "Val \tEpoch [18/60]  val_Loss: 0.6417\tval_Acc: 85.64\n",
            "Test \tEpoch [18/60]  test_Loss: 0.5193\ttest_Acc: 93.07\n",
            "--------------------------------------------------\n",
            "Epoch 19 of 60 took 1.968s\n",
            "Train \tEpoch [19/60]  train_Loss: 0.8747\ttrain_Acc: 72.75\n",
            "Val \tEpoch [19/60]  val_Loss: 0.6000\tval_Acc: 86.14\n",
            "Test \tEpoch [19/60]  test_Loss: 0.4749\ttest_Acc: 94.55\n",
            "--------------------------------------------------\n",
            "Epoch 20 of 60 took 1.939s\n",
            "Train \tEpoch [20/60]  train_Loss: 0.8311\ttrain_Acc: 75.39\n",
            "Val \tEpoch [20/60]  val_Loss: 0.6407\tval_Acc: 83.66\n",
            "Test \tEpoch [20/60]  test_Loss: 0.4755\ttest_Acc: 94.06\n",
            "--------------------------------------------------\n",
            "Epoch 21 of 60 took 1.972s\n",
            "Train \tEpoch [21/60]  train_Loss: 0.7879\ttrain_Acc: 76.44\n",
            "Val \tEpoch [21/60]  val_Loss: 0.5821\tval_Acc: 85.64\n",
            "Test \tEpoch [21/60]  test_Loss: 0.3951\ttest_Acc: 98.02\n",
            "--------------------------------------------------\n",
            "Epoch 22 of 60 took 1.965s\n",
            "Train \tEpoch [22/60]  train_Loss: 0.7772\ttrain_Acc: 76.97\n",
            "Val \tEpoch [22/60]  val_Loss: 0.5388\tval_Acc: 88.61\n",
            "Test \tEpoch [22/60]  test_Loss: 0.3631\ttest_Acc: 98.02\n",
            "--------------------------------------------------\n",
            "Epoch 23 of 60 took 1.995s\n",
            "Train \tEpoch [23/60]  train_Loss: 0.7275\ttrain_Acc: 79.78\n",
            "Val \tEpoch [23/60]  val_Loss: 0.5342\tval_Acc: 89.11\n",
            "Test \tEpoch [23/60]  test_Loss: 0.3714\ttest_Acc: 98.02\n",
            "--------------------------------------------------\n",
            "Epoch 24 of 60 took 1.970s\n",
            "Train \tEpoch [24/60]  train_Loss: 0.6926\ttrain_Acc: 81.75\n",
            "Val \tEpoch [24/60]  val_Loss: 0.5188\tval_Acc: 89.60\n",
            "Test \tEpoch [24/60]  test_Loss: 0.3670\ttest_Acc: 98.51\n",
            "--------------------------------------------------\n",
            "Epoch 25 of 60 took 1.971s\n",
            "Train \tEpoch [25/60]  train_Loss: 0.6753\ttrain_Acc: 81.99\n",
            "Val \tEpoch [25/60]  val_Loss: 0.5070\tval_Acc: 90.10\n",
            "Test \tEpoch [25/60]  test_Loss: 0.3558\ttest_Acc: 98.02\n",
            "--------------------------------------------------\n",
            "Epoch 26 of 60 took 1.969s\n",
            "Train \tEpoch [26/60]  train_Loss: 0.6535\ttrain_Acc: 83.69\n",
            "Val \tEpoch [26/60]  val_Loss: 0.4629\tval_Acc: 92.08\n",
            "Test \tEpoch [26/60]  test_Loss: 0.2940\ttest_Acc: 99.01\n",
            "--------------------------------------------------\n",
            "Epoch 27 of 60 took 1.973s\n",
            "Train \tEpoch [27/60]  train_Loss: 0.6264\ttrain_Acc: 85.27\n",
            "Val \tEpoch [27/60]  val_Loss: 0.4308\tval_Acc: 93.56\n",
            "Test \tEpoch [27/60]  test_Loss: 0.2820\ttest_Acc: 99.01\n",
            "--------------------------------------------------\n",
            "Epoch 28 of 60 took 1.991s\n",
            "Train \tEpoch [28/60]  train_Loss: 0.5944\ttrain_Acc: 86.26\n",
            "Val \tEpoch [28/60]  val_Loss: 0.4312\tval_Acc: 92.57\n",
            "Test \tEpoch [28/60]  test_Loss: 0.3011\ttest_Acc: 99.01\n",
            "--------------------------------------------------\n",
            "Epoch 29 of 60 took 1.999s\n",
            "Train \tEpoch [29/60]  train_Loss: 0.5869\ttrain_Acc: 87.79\n",
            "Val \tEpoch [29/60]  val_Loss: 0.4224\tval_Acc: 93.07\n",
            "Test \tEpoch [29/60]  test_Loss: 0.2685\ttest_Acc: 99.01\n",
            "--------------------------------------------------\n",
            "Epoch 30 of 60 took 1.999s\n",
            "Train \tEpoch [30/60]  train_Loss: 0.5768\ttrain_Acc: 86.40\n",
            "Val \tEpoch [30/60]  val_Loss: 0.4215\tval_Acc: 91.58\n",
            "Test \tEpoch [30/60]  test_Loss: 0.2656\ttest_Acc: 99.01\n",
            "--------------------------------------------------\n",
            "Epoch 31 of 60 took 1.977s\n",
            "Train \tEpoch [31/60]  train_Loss: 0.5359\ttrain_Acc: 87.37\n",
            "Val \tEpoch [31/60]  val_Loss: 0.4092\tval_Acc: 94.06\n",
            "Test \tEpoch [31/60]  test_Loss: 0.2610\ttest_Acc: 99.01\n",
            "--------------------------------------------------\n",
            "Epoch 32 of 60 took 2.008s\n",
            "Train \tEpoch [32/60]  train_Loss: 0.5471\ttrain_Acc: 87.68\n",
            "Val \tEpoch [32/60]  val_Loss: 0.3971\tval_Acc: 93.56\n",
            "Test \tEpoch [32/60]  test_Loss: 0.2506\ttest_Acc: 99.01\n",
            "--------------------------------------------------\n",
            "Epoch 33 of 60 took 1.982s\n",
            "Train \tEpoch [33/60]  train_Loss: 0.5524\ttrain_Acc: 88.00\n",
            "Val \tEpoch [33/60]  val_Loss: 0.3875\tval_Acc: 94.06\n",
            "Test \tEpoch [33/60]  test_Loss: 0.2523\ttest_Acc: 99.01\n",
            "--------------------------------------------------\n",
            "Epoch 34 of 60 took 1.973s\n",
            "Train \tEpoch [34/60]  train_Loss: 0.5326\ttrain_Acc: 87.83\n",
            "Val \tEpoch [34/60]  val_Loss: 0.3799\tval_Acc: 94.06\n",
            "Test \tEpoch [34/60]  test_Loss: 0.2535\ttest_Acc: 99.01\n",
            "--------------------------------------------------\n",
            "Epoch 35 of 60 took 1.963s\n",
            "Train \tEpoch [35/60]  train_Loss: 0.5095\ttrain_Acc: 87.55\n",
            "Val \tEpoch [35/60]  val_Loss: 0.3906\tval_Acc: 95.05\n",
            "Test \tEpoch [35/60]  test_Loss: 0.2565\ttest_Acc: 99.01\n",
            "--------------------------------------------------\n",
            "Epoch 36 of 60 took 1.978s\n",
            "Train \tEpoch [36/60]  train_Loss: 0.4980\ttrain_Acc: 89.61\n",
            "Val \tEpoch [36/60]  val_Loss: 0.4298\tval_Acc: 93.07\n",
            "Test \tEpoch [36/60]  test_Loss: 0.2687\ttest_Acc: 99.01\n",
            "--------------------------------------------------\n",
            "Epoch 37 of 60 took 1.968s\n",
            "Train \tEpoch [37/60]  train_Loss: 0.5197\ttrain_Acc: 88.24\n",
            "Val \tEpoch [37/60]  val_Loss: 0.3856\tval_Acc: 92.08\n",
            "Test \tEpoch [37/60]  test_Loss: 0.2455\ttest_Acc: 99.01\n",
            "--------------------------------------------------\n",
            "Epoch 38 of 60 took 1.973s\n",
            "Train \tEpoch [38/60]  train_Loss: 0.4909\ttrain_Acc: 89.26\n",
            "Val \tEpoch [38/60]  val_Loss: 0.3747\tval_Acc: 94.55\n",
            "Test \tEpoch [38/60]  test_Loss: 0.2377\ttest_Acc: 99.01\n",
            "--------------------------------------------------\n",
            "Epoch 39 of 60 took 1.956s\n",
            "Train \tEpoch [39/60]  train_Loss: 0.4730\ttrain_Acc: 89.59\n",
            "Val \tEpoch [39/60]  val_Loss: 0.3638\tval_Acc: 94.06\n",
            "Test \tEpoch [39/60]  test_Loss: 0.2431\ttest_Acc: 99.01\n",
            "--------------------------------------------------\n",
            "Epoch 40 of 60 took 1.932s\n",
            "Train \tEpoch [40/60]  train_Loss: 0.4847\ttrain_Acc: 88.89\n",
            "Val \tEpoch [40/60]  val_Loss: 0.3826\tval_Acc: 92.57\n",
            "Test \tEpoch [40/60]  test_Loss: 0.2334\ttest_Acc: 99.01\n",
            "--------------------------------------------------\n",
            "Epoch 41 of 60 took 1.973s\n",
            "Train \tEpoch [41/60]  train_Loss: 0.4621\ttrain_Acc: 90.45\n",
            "Val \tEpoch [41/60]  val_Loss: 0.3648\tval_Acc: 94.06\n",
            "Test \tEpoch [41/60]  test_Loss: 0.2286\ttest_Acc: 99.50\n",
            "--------------------------------------------------\n",
            "Epoch 42 of 60 took 1.961s\n",
            "Train \tEpoch [42/60]  train_Loss: 0.4686\ttrain_Acc: 89.91\n",
            "Val \tEpoch [42/60]  val_Loss: 0.3658\tval_Acc: 94.55\n",
            "Test \tEpoch [42/60]  test_Loss: 0.2366\ttest_Acc: 99.01\n",
            "--------------------------------------------------\n",
            "Epoch 43 of 60 took 1.936s\n",
            "Train \tEpoch [43/60]  train_Loss: 0.4441\ttrain_Acc: 90.76\n",
            "Val \tEpoch [43/60]  val_Loss: 0.3717\tval_Acc: 93.56\n",
            "Test \tEpoch [43/60]  test_Loss: 0.2334\ttest_Acc: 99.01\n",
            "--------------------------------------------------\n",
            "Epoch 44 of 60 took 1.959s\n",
            "Train \tEpoch [44/60]  train_Loss: 0.4510\ttrain_Acc: 90.12\n",
            "Val \tEpoch [44/60]  val_Loss: 0.3652\tval_Acc: 93.07\n",
            "Test \tEpoch [44/60]  test_Loss: 0.2294\ttest_Acc: 99.50\n",
            "--------------------------------------------------\n",
            "Epoch 45 of 60 took 1.946s\n",
            "Train \tEpoch [45/60]  train_Loss: 0.4338\ttrain_Acc: 90.60\n",
            "Val \tEpoch [45/60]  val_Loss: 0.3952\tval_Acc: 93.56\n",
            "Test \tEpoch [45/60]  test_Loss: 0.2324\ttest_Acc: 99.01\n",
            "--------------------------------------------------\n",
            "Time in total: 138.4711709022522\n",
            "Best validation accuracy:\t\t95.05 %\n",
            "Test accuracy when got the best validation accuracy:\t\t99.01 %\n",
            "--------------------------------------------------\n",
            "Last train accuracy:\t\t93.29 %\n",
            "Last validation accuracy:\t\t93.56 %\n",
            "Last test accuracy:\t\t\t\t99.01 %\n",
            "Early Stopping at epoch: 35\n",
            "Done!\n",
            "----------------------------------------------------------------------------------------------------\n",
            "The subjects 8 \t\t Training the 1dconv Model...\n",
            "Load the CNN model weight for backbone...\n",
            "Train set label and proportion:\t (array([0, 1, 2, 3], dtype=int32), array([643, 600, 535, 472]))\n",
            "Val   set label and proportion:\t (array([0, 1, 2, 3], dtype=int32), array([57, 57, 54, 42]))\n",
            "Test  set label and proportion:\t (array([0, 1, 2, 3], dtype=int32), array([57, 58, 51, 44]))\n",
            "The shape of X_trian:\t (7, 2250, 32, 32, 3)\n",
            "The shape of X_val:\t (7, 210, 32, 32, 3)\n",
            "The shape of X_test:\t (7, 210, 32, 32, 3)\n",
            "Building model and compiling functions...\n",
            "Writing to /content/runs/2020-02-05.14.17_1dconv/1dconv_8\n",
            "\n",
            "Starting training...\n",
            "--------------------------------------------------\n",
            "Epoch 1 of 60 took 2.890s\n",
            "Train \tEpoch [1/60]  train_Loss: 6.5440\ttrain_Acc: 28.68\n",
            "Val \tEpoch [1/60]  val_Loss: 1.6005\tval_Acc: 40.00\n",
            "Test \tEpoch [1/60]  test_Loss: 1.5438\ttest_Acc: 39.52\n",
            "--------------------------------------------------\n",
            "Epoch 2 of 60 took 1.907s\n",
            "Train \tEpoch [2/60]  train_Loss: 1.9604\ttrain_Acc: 34.02\n",
            "Val \tEpoch [2/60]  val_Loss: 1.5296\tval_Acc: 42.38\n",
            "Test \tEpoch [2/60]  test_Loss: 1.5498\ttest_Acc: 45.71\n",
            "--------------------------------------------------\n",
            "Epoch 3 of 60 took 1.939s\n",
            "Train \tEpoch [3/60]  train_Loss: 1.6922\ttrain_Acc: 39.75\n",
            "Val \tEpoch [3/60]  val_Loss: 1.4725\tval_Acc: 46.67\n",
            "Test \tEpoch [3/60]  test_Loss: 1.4949\ttest_Acc: 50.48\n",
            "--------------------------------------------------\n",
            "Epoch 4 of 60 took 1.907s\n",
            "Train \tEpoch [4/60]  train_Loss: 1.6409\ttrain_Acc: 39.52\n",
            "Val \tEpoch [4/60]  val_Loss: 1.4653\tval_Acc: 49.05\n",
            "Test \tEpoch [4/60]  test_Loss: 1.4944\ttest_Acc: 50.95\n",
            "--------------------------------------------------\n",
            "Epoch 5 of 60 took 1.905s\n",
            "Train \tEpoch [5/60]  train_Loss: 1.5646\ttrain_Acc: 40.23\n",
            "Val \tEpoch [5/60]  val_Loss: 1.4119\tval_Acc: 47.14\n",
            "Test \tEpoch [5/60]  test_Loss: 1.4085\ttest_Acc: 49.52\n",
            "--------------------------------------------------\n",
            "Epoch 6 of 60 took 1.907s\n",
            "Train \tEpoch [6/60]  train_Loss: 1.5194\ttrain_Acc: 42.21\n",
            "Val \tEpoch [6/60]  val_Loss: 1.4028\tval_Acc: 50.48\n",
            "Test \tEpoch [6/60]  test_Loss: 1.4160\ttest_Acc: 51.90\n",
            "--------------------------------------------------\n",
            "Epoch 7 of 60 took 1.899s\n",
            "Train \tEpoch [7/60]  train_Loss: 1.4844\ttrain_Acc: 42.78\n",
            "Val \tEpoch [7/60]  val_Loss: 1.3878\tval_Acc: 50.00\n",
            "Test \tEpoch [7/60]  test_Loss: 1.3747\ttest_Acc: 50.95\n",
            "--------------------------------------------------\n",
            "Epoch 8 of 60 took 1.888s\n",
            "Train \tEpoch [8/60]  train_Loss: 1.4582\ttrain_Acc: 44.43\n",
            "Val \tEpoch [8/60]  val_Loss: 1.3734\tval_Acc: 50.95\n",
            "Test \tEpoch [8/60]  test_Loss: 1.3649\ttest_Acc: 50.48\n",
            "--------------------------------------------------\n",
            "Epoch 9 of 60 took 1.910s\n",
            "Train \tEpoch [9/60]  train_Loss: 1.4433\ttrain_Acc: 44.95\n",
            "Val \tEpoch [9/60]  val_Loss: 1.3546\tval_Acc: 50.95\n",
            "Test \tEpoch [9/60]  test_Loss: 1.3524\ttest_Acc: 51.43\n",
            "--------------------------------------------------\n",
            "Epoch 10 of 60 took 1.911s\n",
            "Train \tEpoch [10/60]  train_Loss: 1.4233\ttrain_Acc: 45.84\n",
            "Val \tEpoch [10/60]  val_Loss: 1.3362\tval_Acc: 51.43\n",
            "Test \tEpoch [10/60]  test_Loss: 1.3446\ttest_Acc: 51.90\n",
            "--------------------------------------------------\n",
            "Epoch 11 of 60 took 1.908s\n",
            "Train \tEpoch [11/60]  train_Loss: 1.4208\ttrain_Acc: 45.52\n",
            "Val \tEpoch [11/60]  val_Loss: 1.3328\tval_Acc: 50.95\n",
            "Test \tEpoch [11/60]  test_Loss: 1.3365\ttest_Acc: 51.90\n",
            "--------------------------------------------------\n",
            "Epoch 12 of 60 took 1.925s\n",
            "Train \tEpoch [12/60]  train_Loss: 1.3673\ttrain_Acc: 48.35\n",
            "Val \tEpoch [12/60]  val_Loss: 1.3325\tval_Acc: 45.24\n",
            "Test \tEpoch [12/60]  test_Loss: 1.3023\ttest_Acc: 44.76\n",
            "--------------------------------------------------\n",
            "Epoch 13 of 60 took 1.943s\n",
            "Train \tEpoch [13/60]  train_Loss: 1.3500\ttrain_Acc: 49.09\n",
            "Val \tEpoch [13/60]  val_Loss: 1.3066\tval_Acc: 49.05\n",
            "Test \tEpoch [13/60]  test_Loss: 1.2930\ttest_Acc: 48.57\n",
            "--------------------------------------------------\n",
            "Epoch 14 of 60 took 1.930s\n",
            "Train \tEpoch [14/60]  train_Loss: 1.3376\ttrain_Acc: 50.07\n",
            "Val \tEpoch [14/60]  val_Loss: 1.3020\tval_Acc: 45.71\n",
            "Test \tEpoch [14/60]  test_Loss: 1.2868\ttest_Acc: 47.14\n",
            "--------------------------------------------------\n",
            "Epoch 15 of 60 took 1.902s\n",
            "Train \tEpoch [15/60]  train_Loss: 1.3267\ttrain_Acc: 50.06\n",
            "Val \tEpoch [15/60]  val_Loss: 1.2852\tval_Acc: 49.52\n",
            "Test \tEpoch [15/60]  test_Loss: 1.2781\ttest_Acc: 51.90\n",
            "--------------------------------------------------\n",
            "Epoch 16 of 60 took 1.917s\n",
            "Train \tEpoch [16/60]  train_Loss: 1.2964\ttrain_Acc: 51.52\n",
            "Val \tEpoch [16/60]  val_Loss: 1.2853\tval_Acc: 51.43\n",
            "Test \tEpoch [16/60]  test_Loss: 1.2624\ttest_Acc: 52.38\n",
            "--------------------------------------------------\n",
            "Epoch 17 of 60 took 1.915s\n",
            "Train \tEpoch [17/60]  train_Loss: 1.2873\ttrain_Acc: 51.48\n",
            "Val \tEpoch [17/60]  val_Loss: 1.2839\tval_Acc: 50.00\n",
            "Test \tEpoch [17/60]  test_Loss: 1.2553\ttest_Acc: 52.38\n",
            "--------------------------------------------------\n",
            "Epoch 18 of 60 took 1.924s\n",
            "Train \tEpoch [18/60]  train_Loss: 1.2885\ttrain_Acc: 50.28\n",
            "Val \tEpoch [18/60]  val_Loss: 1.2710\tval_Acc: 50.48\n",
            "Test \tEpoch [18/60]  test_Loss: 1.2526\ttest_Acc: 52.38\n",
            "--------------------------------------------------\n",
            "Epoch 19 of 60 took 1.912s\n",
            "Train \tEpoch [19/60]  train_Loss: 1.2799\ttrain_Acc: 51.30\n",
            "Val \tEpoch [19/60]  val_Loss: 1.2805\tval_Acc: 47.62\n",
            "Test \tEpoch [19/60]  test_Loss: 1.2488\ttest_Acc: 52.38\n",
            "--------------------------------------------------\n",
            "Epoch 20 of 60 took 1.916s\n",
            "Train \tEpoch [20/60]  train_Loss: 1.2637\ttrain_Acc: 51.65\n",
            "Val \tEpoch [20/60]  val_Loss: 1.2556\tval_Acc: 52.86\n",
            "Test \tEpoch [20/60]  test_Loss: 1.2381\ttest_Acc: 53.33\n",
            "--------------------------------------------------\n",
            "Epoch 21 of 60 took 1.912s\n",
            "Train \tEpoch [21/60]  train_Loss: 1.2710\ttrain_Acc: 51.48\n",
            "Val \tEpoch [21/60]  val_Loss: 1.2672\tval_Acc: 50.00\n",
            "Test \tEpoch [21/60]  test_Loss: 1.2392\ttest_Acc: 50.95\n",
            "--------------------------------------------------\n",
            "Epoch 22 of 60 took 1.913s\n",
            "Train \tEpoch [22/60]  train_Loss: 1.2584\ttrain_Acc: 52.05\n",
            "Val \tEpoch [22/60]  val_Loss: 1.2529\tval_Acc: 53.81\n",
            "Test \tEpoch [22/60]  test_Loss: 1.2265\ttest_Acc: 53.33\n",
            "--------------------------------------------------\n",
            "Epoch 23 of 60 took 1.909s\n",
            "Train \tEpoch [23/60]  train_Loss: 1.2489\ttrain_Acc: 52.10\n",
            "Val \tEpoch [23/60]  val_Loss: 1.2464\tval_Acc: 53.33\n",
            "Test \tEpoch [23/60]  test_Loss: 1.2213\ttest_Acc: 53.33\n",
            "--------------------------------------------------\n",
            "Epoch 24 of 60 took 1.915s\n",
            "Train \tEpoch [24/60]  train_Loss: 1.2520\ttrain_Acc: 51.61\n",
            "Val \tEpoch [24/60]  val_Loss: 1.2400\tval_Acc: 52.86\n",
            "Test \tEpoch [24/60]  test_Loss: 1.2292\ttest_Acc: 53.33\n",
            "--------------------------------------------------\n",
            "Epoch 25 of 60 took 1.910s\n",
            "Train \tEpoch [25/60]  train_Loss: 1.2393\ttrain_Acc: 52.36\n",
            "Val \tEpoch [25/60]  val_Loss: 1.2311\tval_Acc: 51.43\n",
            "Test \tEpoch [25/60]  test_Loss: 1.2144\ttest_Acc: 53.33\n",
            "--------------------------------------------------\n",
            "Epoch 26 of 60 took 1.920s\n",
            "Train \tEpoch [26/60]  train_Loss: 1.2363\ttrain_Acc: 52.40\n",
            "Val \tEpoch [26/60]  val_Loss: 1.2307\tval_Acc: 51.90\n",
            "Test \tEpoch [26/60]  test_Loss: 1.2156\ttest_Acc: 51.43\n",
            "--------------------------------------------------\n",
            "Epoch 27 of 60 took 1.911s\n",
            "Train \tEpoch [27/60]  train_Loss: 1.2265\ttrain_Acc: 52.76\n",
            "Val \tEpoch [27/60]  val_Loss: 1.2209\tval_Acc: 56.67\n",
            "Test \tEpoch [27/60]  test_Loss: 1.2082\ttest_Acc: 53.33\n",
            "--------------------------------------------------\n",
            "Epoch 28 of 60 took 1.911s\n",
            "Train \tEpoch [28/60]  train_Loss: 1.2118\ttrain_Acc: 52.17\n",
            "Val \tEpoch [28/60]  val_Loss: 1.2113\tval_Acc: 53.33\n",
            "Test \tEpoch [28/60]  test_Loss: 1.2049\ttest_Acc: 53.33\n",
            "--------------------------------------------------\n",
            "Epoch 29 of 60 took 1.935s\n",
            "Train \tEpoch [29/60]  train_Loss: 1.2083\ttrain_Acc: 52.05\n",
            "Val \tEpoch [29/60]  val_Loss: 1.1848\tval_Acc: 51.90\n",
            "Test \tEpoch [29/60]  test_Loss: 1.1932\ttest_Acc: 54.29\n",
            "--------------------------------------------------\n",
            "Epoch 30 of 60 took 1.907s\n",
            "Train \tEpoch [30/60]  train_Loss: 1.1717\ttrain_Acc: 53.24\n",
            "Val \tEpoch [30/60]  val_Loss: 1.1353\tval_Acc: 53.33\n",
            "Test \tEpoch [30/60]  test_Loss: 1.1489\ttest_Acc: 53.33\n",
            "--------------------------------------------------\n",
            "Epoch 31 of 60 took 1.904s\n",
            "Train \tEpoch [31/60]  train_Loss: 1.1383\ttrain_Acc: 54.24\n",
            "Val \tEpoch [31/60]  val_Loss: 1.1218\tval_Acc: 54.29\n",
            "Test \tEpoch [31/60]  test_Loss: 1.1342\ttest_Acc: 56.67\n",
            "--------------------------------------------------\n",
            "Epoch 32 of 60 took 1.911s\n",
            "Train \tEpoch [32/60]  train_Loss: 1.1500\ttrain_Acc: 53.19\n",
            "Val \tEpoch [32/60]  val_Loss: 1.0825\tval_Acc: 55.71\n",
            "Test \tEpoch [32/60]  test_Loss: 1.1026\ttest_Acc: 56.19\n",
            "--------------------------------------------------\n",
            "Epoch 33 of 60 took 1.945s\n",
            "Train \tEpoch [33/60]  train_Loss: 1.1272\ttrain_Acc: 56.19\n",
            "Val \tEpoch [33/60]  val_Loss: 1.0549\tval_Acc: 54.29\n",
            "Test \tEpoch [33/60]  test_Loss: 1.0526\ttest_Acc: 54.76\n",
            "--------------------------------------------------\n",
            "Epoch 34 of 60 took 1.898s\n",
            "Train \tEpoch [34/60]  train_Loss: 1.1026\ttrain_Acc: 54.78\n",
            "Val \tEpoch [34/60]  val_Loss: 1.0282\tval_Acc: 56.19\n",
            "Test \tEpoch [34/60]  test_Loss: 1.0097\ttest_Acc: 56.19\n",
            "--------------------------------------------------\n",
            "Epoch 35 of 60 took 1.920s\n",
            "Train \tEpoch [35/60]  train_Loss: 1.0921\ttrain_Acc: 57.32\n",
            "Val \tEpoch [35/60]  val_Loss: 1.0467\tval_Acc: 72.86\n",
            "Test \tEpoch [35/60]  test_Loss: 1.0316\ttest_Acc: 75.71\n",
            "--------------------------------------------------\n",
            "Epoch 36 of 60 took 1.930s\n",
            "Train \tEpoch [36/60]  train_Loss: 1.0847\ttrain_Acc: 57.82\n",
            "Val \tEpoch [36/60]  val_Loss: 1.0012\tval_Acc: 71.43\n",
            "Test \tEpoch [36/60]  test_Loss: 0.9873\ttest_Acc: 74.29\n",
            "--------------------------------------------------\n",
            "Epoch 37 of 60 took 1.919s\n",
            "Train \tEpoch [37/60]  train_Loss: 1.0876\ttrain_Acc: 59.42\n",
            "Val \tEpoch [37/60]  val_Loss: 0.9869\tval_Acc: 73.33\n",
            "Test \tEpoch [37/60]  test_Loss: 0.9561\ttest_Acc: 74.29\n",
            "--------------------------------------------------\n",
            "Epoch 38 of 60 took 1.917s\n",
            "Train \tEpoch [38/60]  train_Loss: 1.0770\ttrain_Acc: 59.49\n",
            "Val \tEpoch [38/60]  val_Loss: 1.0399\tval_Acc: 70.48\n",
            "Test \tEpoch [38/60]  test_Loss: 0.9943\ttest_Acc: 75.71\n",
            "--------------------------------------------------\n",
            "Epoch 39 of 60 took 1.912s\n",
            "Train \tEpoch [39/60]  train_Loss: 1.0558\ttrain_Acc: 60.84\n",
            "Val \tEpoch [39/60]  val_Loss: 1.0056\tval_Acc: 71.90\n",
            "Test \tEpoch [39/60]  test_Loss: 0.9716\ttest_Acc: 79.05\n",
            "--------------------------------------------------\n",
            "Epoch 40 of 60 took 1.913s\n",
            "Train \tEpoch [40/60]  train_Loss: 1.0489\ttrain_Acc: 61.82\n",
            "Val \tEpoch [40/60]  val_Loss: 0.9793\tval_Acc: 71.90\n",
            "Test \tEpoch [40/60]  test_Loss: 0.9103\ttest_Acc: 81.90\n",
            "--------------------------------------------------\n",
            "Epoch 41 of 60 took 1.923s\n",
            "Train \tEpoch [41/60]  train_Loss: 1.0334\ttrain_Acc: 61.67\n",
            "Val \tEpoch [41/60]  val_Loss: 0.9505\tval_Acc: 75.24\n",
            "Test \tEpoch [41/60]  test_Loss: 0.8573\ttest_Acc: 86.19\n",
            "--------------------------------------------------\n",
            "Epoch 42 of 60 took 1.905s\n",
            "Train \tEpoch [42/60]  train_Loss: 1.0262\ttrain_Acc: 62.13\n",
            "Val \tEpoch [42/60]  val_Loss: 0.9361\tval_Acc: 77.62\n",
            "Test \tEpoch [42/60]  test_Loss: 0.7731\ttest_Acc: 89.52\n",
            "--------------------------------------------------\n",
            "Epoch 43 of 60 took 1.953s\n",
            "Train \tEpoch [43/60]  train_Loss: 1.0135\ttrain_Acc: 62.83\n",
            "Val \tEpoch [43/60]  val_Loss: 0.9459\tval_Acc: 71.90\n",
            "Test \tEpoch [43/60]  test_Loss: 0.7467\ttest_Acc: 80.48\n",
            "--------------------------------------------------\n",
            "Epoch 44 of 60 took 1.923s\n",
            "Train \tEpoch [44/60]  train_Loss: 0.9962\ttrain_Acc: 65.65\n",
            "Val \tEpoch [44/60]  val_Loss: 0.8768\tval_Acc: 76.19\n",
            "Test \tEpoch [44/60]  test_Loss: 0.6887\ttest_Acc: 81.43\n",
            "--------------------------------------------------\n",
            "Epoch 45 of 60 took 1.897s\n",
            "Train \tEpoch [45/60]  train_Loss: 0.9898\ttrain_Acc: 66.23\n",
            "Val \tEpoch [45/60]  val_Loss: 0.9211\tval_Acc: 73.81\n",
            "Test \tEpoch [45/60]  test_Loss: 0.7415\ttest_Acc: 90.95\n",
            "--------------------------------------------------\n",
            "Epoch 46 of 60 took 1.899s\n",
            "Train \tEpoch [46/60]  train_Loss: 0.9635\ttrain_Acc: 68.61\n",
            "Val \tEpoch [46/60]  val_Loss: 0.8571\tval_Acc: 78.57\n",
            "Test \tEpoch [46/60]  test_Loss: 0.6756\ttest_Acc: 80.95\n",
            "--------------------------------------------------\n",
            "Epoch 47 of 60 took 1.899s\n",
            "Train \tEpoch [47/60]  train_Loss: 0.9338\ttrain_Acc: 71.95\n",
            "Val \tEpoch [47/60]  val_Loss: 0.8441\tval_Acc: 79.05\n",
            "Test \tEpoch [47/60]  test_Loss: 0.6458\ttest_Acc: 88.10\n",
            "--------------------------------------------------\n",
            "Epoch 48 of 60 took 1.927s\n",
            "Train \tEpoch [48/60]  train_Loss: 0.8817\ttrain_Acc: 74.99\n",
            "Val \tEpoch [48/60]  val_Loss: 0.7750\tval_Acc: 76.67\n",
            "Test \tEpoch [48/60]  test_Loss: 0.6238\ttest_Acc: 80.48\n",
            "--------------------------------------------------\n",
            "Epoch 49 of 60 took 1.916s\n",
            "Train \tEpoch [49/60]  train_Loss: 0.8471\ttrain_Acc: 76.27\n",
            "Val \tEpoch [49/60]  val_Loss: 0.7521\tval_Acc: 80.00\n",
            "Test \tEpoch [49/60]  test_Loss: 0.6019\ttest_Acc: 83.81\n",
            "--------------------------------------------------\n",
            "Epoch 50 of 60 took 1.908s\n",
            "Train \tEpoch [50/60]  train_Loss: 0.8008\ttrain_Acc: 78.51\n",
            "Val \tEpoch [50/60]  val_Loss: 0.7243\tval_Acc: 84.29\n",
            "Test \tEpoch [50/60]  test_Loss: 0.6067\ttest_Acc: 85.24\n",
            "--------------------------------------------------\n",
            "Epoch 51 of 60 took 1.931s\n",
            "Train \tEpoch [51/60]  train_Loss: 0.7715\ttrain_Acc: 80.40\n",
            "Val \tEpoch [51/60]  val_Loss: 0.6593\tval_Acc: 85.71\n",
            "Test \tEpoch [51/60]  test_Loss: 0.5617\ttest_Acc: 90.95\n",
            "--------------------------------------------------\n",
            "Epoch 52 of 60 took 1.915s\n",
            "Train \tEpoch [52/60]  train_Loss: 0.6996\ttrain_Acc: 82.39\n",
            "Val \tEpoch [52/60]  val_Loss: 0.5668\tval_Acc: 90.00\n",
            "Test \tEpoch [52/60]  test_Loss: 0.4483\ttest_Acc: 97.62\n",
            "--------------------------------------------------\n",
            "Epoch 53 of 60 took 1.925s\n",
            "Train \tEpoch [53/60]  train_Loss: 0.6571\ttrain_Acc: 84.20\n",
            "Val \tEpoch [53/60]  val_Loss: 0.5600\tval_Acc: 90.48\n",
            "Test \tEpoch [53/60]  test_Loss: 0.4226\ttest_Acc: 98.10\n",
            "--------------------------------------------------\n",
            "Epoch 54 of 60 took 1.912s\n",
            "Train \tEpoch [54/60]  train_Loss: 0.6492\ttrain_Acc: 84.15\n",
            "Val \tEpoch [54/60]  val_Loss: 0.5304\tval_Acc: 91.43\n",
            "Test \tEpoch [54/60]  test_Loss: 0.4174\ttest_Acc: 95.24\n",
            "--------------------------------------------------\n",
            "Epoch 55 of 60 took 1.908s\n",
            "Train \tEpoch [55/60]  train_Loss: 0.6160\ttrain_Acc: 85.74\n",
            "Val \tEpoch [55/60]  val_Loss: 0.5151\tval_Acc: 90.95\n",
            "Test \tEpoch [55/60]  test_Loss: 0.3658\ttest_Acc: 98.57\n",
            "--------------------------------------------------\n",
            "Epoch 56 of 60 took 1.914s\n",
            "Train \tEpoch [56/60]  train_Loss: 0.6175\ttrain_Acc: 85.64\n",
            "Val \tEpoch [56/60]  val_Loss: 0.4884\tval_Acc: 90.95\n",
            "Test \tEpoch [56/60]  test_Loss: 0.3702\ttest_Acc: 98.10\n",
            "--------------------------------------------------\n",
            "Epoch 57 of 60 took 1.901s\n",
            "Train \tEpoch [57/60]  train_Loss: 0.5976\ttrain_Acc: 87.28\n",
            "Val \tEpoch [57/60]  val_Loss: 0.5232\tval_Acc: 89.52\n",
            "Test \tEpoch [57/60]  test_Loss: 0.3639\ttest_Acc: 99.05\n",
            "--------------------------------------------------\n",
            "Epoch 58 of 60 took 1.919s\n",
            "Train \tEpoch [58/60]  train_Loss: 0.5780\ttrain_Acc: 87.32\n",
            "Val \tEpoch [58/60]  val_Loss: 0.5203\tval_Acc: 89.52\n",
            "Test \tEpoch [58/60]  test_Loss: 0.3609\ttest_Acc: 98.10\n",
            "--------------------------------------------------\n",
            "Epoch 59 of 60 took 1.905s\n",
            "Train \tEpoch [59/60]  train_Loss: 0.5801\ttrain_Acc: 87.32\n",
            "Val \tEpoch [59/60]  val_Loss: 0.4884\tval_Acc: 90.00\n",
            "Test \tEpoch [59/60]  test_Loss: 0.3360\ttest_Acc: 99.05\n",
            "--------------------------------------------------\n",
            "Epoch 60 of 60 took 1.902s\n",
            "Train \tEpoch [60/60]  train_Loss: 0.5518\ttrain_Acc: 88.42\n",
            "Val \tEpoch [60/60]  val_Loss: 0.4724\tval_Acc: 90.48\n",
            "Test \tEpoch [60/60]  test_Loss: 0.3224\ttest_Acc: 99.05\n",
            "--------------------------------------------------\n",
            "Time in total: 165.3501467704773\n",
            "Best validation accuracy:\t\t91.43 %\n",
            "Test accuracy when got the best validation accuracy:\t\t95.24 %\n",
            "--------------------------------------------------\n",
            "Last train accuracy:\t\t93.24 %\n",
            "Last validation accuracy:\t\t90.48 %\n",
            "Last test accuracy:\t\t\t\t99.05 %\n",
            "Early Stopping at epoch: 54\n",
            "Done!\n",
            "----------------------------------------------------------------------------------------------------\n",
            "The subjects 9 \t\t Training the 1dconv Model...\n",
            "Load the CNN model weight for backbone...\n",
            "Train set label and proportion:\t (array([0, 1, 2, 3], dtype=int32), array([643, 599, 527, 451]))\n",
            "Val   set label and proportion:\t (array([0, 1, 2, 3], dtype=int32), array([56, 57, 56, 56]))\n",
            "Test  set label and proportion:\t (array([0, 1, 2, 3], dtype=int32), array([58, 59, 57, 51]))\n",
            "The shape of X_trian:\t (7, 2220, 32, 32, 3)\n",
            "The shape of X_val:\t (7, 225, 32, 32, 3)\n",
            "The shape of X_test:\t (7, 225, 32, 32, 3)\n",
            "Building model and compiling functions...\n",
            "Writing to /content/runs/2020-02-05.14.17_1dconv/1dconv_9\n",
            "\n",
            "Starting training...\n",
            "--------------------------------------------------\n",
            "Epoch 1 of 60 took 2.743s\n",
            "Train \tEpoch [1/60]  train_Loss: 5.7217\ttrain_Acc: 30.73\n",
            "Val \tEpoch [1/60]  val_Loss: 1.5139\tval_Acc: 56.00\n",
            "Test \tEpoch [1/60]  test_Loss: 1.3324\ttest_Acc: 58.22\n",
            "--------------------------------------------------\n",
            "Epoch 2 of 60 took 1.882s\n",
            "Train \tEpoch [2/60]  train_Loss: 1.7432\ttrain_Acc: 41.28\n",
            "Val \tEpoch [2/60]  val_Loss: 1.4796\tval_Acc: 51.56\n",
            "Test \tEpoch [2/60]  test_Loss: 1.3080\ttest_Acc: 57.33\n",
            "--------------------------------------------------\n",
            "Epoch 3 of 60 took 1.903s\n",
            "Train \tEpoch [3/60]  train_Loss: 1.6165\ttrain_Acc: 45.64\n",
            "Val \tEpoch [3/60]  val_Loss: 1.4419\tval_Acc: 52.89\n",
            "Test \tEpoch [3/60]  test_Loss: 1.2925\ttest_Acc: 57.78\n",
            "--------------------------------------------------\n",
            "Epoch 4 of 60 took 1.898s\n",
            "Train \tEpoch [4/60]  train_Loss: 1.4975\ttrain_Acc: 44.63\n",
            "Val \tEpoch [4/60]  val_Loss: 1.4007\tval_Acc: 57.78\n",
            "Test \tEpoch [4/60]  test_Loss: 1.2687\ttest_Acc: 59.56\n",
            "--------------------------------------------------\n",
            "Epoch 5 of 60 took 1.954s\n",
            "Train \tEpoch [5/60]  train_Loss: 1.4891\ttrain_Acc: 47.72\n",
            "Val \tEpoch [5/60]  val_Loss: 1.3455\tval_Acc: 57.33\n",
            "Test \tEpoch [5/60]  test_Loss: 1.2222\ttest_Acc: 54.22\n",
            "--------------------------------------------------\n",
            "Epoch 6 of 60 took 1.890s\n",
            "Train \tEpoch [6/60]  train_Loss: 1.4190\ttrain_Acc: 48.63\n",
            "Val \tEpoch [6/60]  val_Loss: 1.3069\tval_Acc: 60.89\n",
            "Test \tEpoch [6/60]  test_Loss: 1.1943\ttest_Acc: 64.89\n",
            "--------------------------------------------------\n",
            "Epoch 7 of 60 took 1.885s\n",
            "Train \tEpoch [7/60]  train_Loss: 1.3281\ttrain_Acc: 53.41\n",
            "Val \tEpoch [7/60]  val_Loss: 1.2170\tval_Acc: 63.56\n",
            "Test \tEpoch [7/60]  test_Loss: 1.1059\ttest_Acc: 68.89\n",
            "--------------------------------------------------\n",
            "Epoch 8 of 60 took 1.902s\n",
            "Train \tEpoch [8/60]  train_Loss: 1.2484\ttrain_Acc: 57.22\n",
            "Val \tEpoch [8/60]  val_Loss: 1.1481\tval_Acc: 65.78\n",
            "Test \tEpoch [8/60]  test_Loss: 0.9395\ttest_Acc: 77.78\n",
            "--------------------------------------------------\n",
            "Epoch 9 of 60 took 1.928s\n",
            "Train \tEpoch [9/60]  train_Loss: 1.2186\ttrain_Acc: 60.25\n",
            "Val \tEpoch [9/60]  val_Loss: 1.0806\tval_Acc: 71.56\n",
            "Test \tEpoch [9/60]  test_Loss: 0.9177\ttest_Acc: 80.00\n",
            "--------------------------------------------------\n",
            "Epoch 10 of 60 took 1.919s\n",
            "Train \tEpoch [10/60]  train_Loss: 1.0991\ttrain_Acc: 65.09\n",
            "Val \tEpoch [10/60]  val_Loss: 1.0040\tval_Acc: 75.56\n",
            "Test \tEpoch [10/60]  test_Loss: 0.8496\ttest_Acc: 83.11\n",
            "--------------------------------------------------\n",
            "Epoch 11 of 60 took 1.879s\n",
            "Train \tEpoch [11/60]  train_Loss: 1.0594\ttrain_Acc: 67.31\n",
            "Val \tEpoch [11/60]  val_Loss: 0.9499\tval_Acc: 78.22\n",
            "Test \tEpoch [11/60]  test_Loss: 0.8138\ttest_Acc: 80.00\n",
            "--------------------------------------------------\n",
            "Epoch 12 of 60 took 1.904s\n",
            "Train \tEpoch [12/60]  train_Loss: 1.0100\ttrain_Acc: 69.88\n",
            "Val \tEpoch [12/60]  val_Loss: 0.8787\tval_Acc: 79.56\n",
            "Test \tEpoch [12/60]  test_Loss: 0.6683\ttest_Acc: 90.22\n",
            "--------------------------------------------------\n",
            "Epoch 13 of 60 took 1.900s\n",
            "Train \tEpoch [13/60]  train_Loss: 0.9262\ttrain_Acc: 73.81\n",
            "Val \tEpoch [13/60]  val_Loss: 0.8073\tval_Acc: 83.11\n",
            "Test \tEpoch [13/60]  test_Loss: 0.6579\ttest_Acc: 90.67\n",
            "--------------------------------------------------\n",
            "Epoch 14 of 60 took 1.881s\n",
            "Train \tEpoch [14/60]  train_Loss: 0.8705\ttrain_Acc: 75.18\n",
            "Val \tEpoch [14/60]  val_Loss: 0.7444\tval_Acc: 84.89\n",
            "Test \tEpoch [14/60]  test_Loss: 0.5876\ttest_Acc: 93.78\n",
            "--------------------------------------------------\n",
            "Epoch 15 of 60 took 1.888s\n",
            "Train \tEpoch [15/60]  train_Loss: 0.8015\ttrain_Acc: 80.00\n",
            "Val \tEpoch [15/60]  val_Loss: 0.7127\tval_Acc: 86.67\n",
            "Test \tEpoch [15/60]  test_Loss: 0.5498\ttest_Acc: 92.44\n",
            "--------------------------------------------------\n",
            "Epoch 16 of 60 took 1.889s\n",
            "Train \tEpoch [16/60]  train_Loss: 0.7783\ttrain_Acc: 79.29\n",
            "Val \tEpoch [16/60]  val_Loss: 0.6824\tval_Acc: 85.78\n",
            "Test \tEpoch [16/60]  test_Loss: 0.4726\ttest_Acc: 95.11\n",
            "--------------------------------------------------\n",
            "Epoch 17 of 60 took 1.918s\n",
            "Train \tEpoch [17/60]  train_Loss: 0.7292\ttrain_Acc: 81.58\n",
            "Val \tEpoch [17/60]  val_Loss: 0.6036\tval_Acc: 88.44\n",
            "Test \tEpoch [17/60]  test_Loss: 0.4709\ttest_Acc: 92.89\n",
            "--------------------------------------------------\n",
            "Epoch 18 of 60 took 1.909s\n",
            "Train \tEpoch [18/60]  train_Loss: 0.6945\ttrain_Acc: 83.15\n",
            "Val \tEpoch [18/60]  val_Loss: 0.6131\tval_Acc: 88.89\n",
            "Test \tEpoch [18/60]  test_Loss: 0.4462\ttest_Acc: 95.11\n",
            "--------------------------------------------------\n",
            "Epoch 19 of 60 took 1.935s\n",
            "Train \tEpoch [19/60]  train_Loss: 0.6766\ttrain_Acc: 83.15\n",
            "Val \tEpoch [19/60]  val_Loss: 0.5780\tval_Acc: 89.78\n",
            "Test \tEpoch [19/60]  test_Loss: 0.4071\ttest_Acc: 95.11\n",
            "--------------------------------------------------\n",
            "Epoch 20 of 60 took 1.903s\n",
            "Train \tEpoch [20/60]  train_Loss: 0.6577\ttrain_Acc: 84.75\n",
            "Val \tEpoch [20/60]  val_Loss: 0.5481\tval_Acc: 90.22\n",
            "Test \tEpoch [20/60]  test_Loss: 0.3952\ttest_Acc: 95.11\n",
            "--------------------------------------------------\n",
            "Epoch 21 of 60 took 1.887s\n",
            "Train \tEpoch [21/60]  train_Loss: 0.6118\ttrain_Acc: 86.26\n",
            "Val \tEpoch [21/60]  val_Loss: 0.5133\tval_Acc: 89.78\n",
            "Test \tEpoch [21/60]  test_Loss: 0.3830\ttest_Acc: 96.00\n",
            "--------------------------------------------------\n",
            "Epoch 22 of 60 took 1.894s\n",
            "Train \tEpoch [22/60]  train_Loss: 0.6053\ttrain_Acc: 86.28\n",
            "Val \tEpoch [22/60]  val_Loss: 0.5254\tval_Acc: 89.78\n",
            "Test \tEpoch [22/60]  test_Loss: 0.3874\ttest_Acc: 96.89\n",
            "--------------------------------------------------\n",
            "Epoch 23 of 60 took 1.864s\n",
            "Train \tEpoch [23/60]  train_Loss: 0.6012\ttrain_Acc: 86.59\n",
            "Val \tEpoch [23/60]  val_Loss: 0.4761\tval_Acc: 90.67\n",
            "Test \tEpoch [23/60]  test_Loss: 0.3355\ttest_Acc: 97.33\n",
            "--------------------------------------------------\n",
            "Epoch 24 of 60 took 1.942s\n",
            "Train \tEpoch [24/60]  train_Loss: 0.5454\ttrain_Acc: 88.15\n",
            "Val \tEpoch [24/60]  val_Loss: 0.4718\tval_Acc: 91.56\n",
            "Test \tEpoch [24/60]  test_Loss: 0.3275\ttest_Acc: 97.78\n",
            "--------------------------------------------------\n",
            "Epoch 25 of 60 took 1.889s\n",
            "Train \tEpoch [25/60]  train_Loss: 0.5489\ttrain_Acc: 88.20\n",
            "Val \tEpoch [25/60]  val_Loss: 0.4571\tval_Acc: 91.11\n",
            "Test \tEpoch [25/60]  test_Loss: 0.3310\ttest_Acc: 96.89\n",
            "--------------------------------------------------\n",
            "Epoch 26 of 60 took 1.878s\n",
            "Train \tEpoch [26/60]  train_Loss: 0.5452\ttrain_Acc: 88.08\n",
            "Val \tEpoch [26/60]  val_Loss: 0.4600\tval_Acc: 89.78\n",
            "Test \tEpoch [26/60]  test_Loss: 0.3302\ttest_Acc: 96.89\n",
            "--------------------------------------------------\n",
            "Epoch 27 of 60 took 1.909s\n",
            "Train \tEpoch [27/60]  train_Loss: 0.5269\ttrain_Acc: 88.84\n",
            "Val \tEpoch [27/60]  val_Loss: 0.4628\tval_Acc: 90.67\n",
            "Test \tEpoch [27/60]  test_Loss: 0.3080\ttest_Acc: 96.89\n",
            "--------------------------------------------------\n",
            "Epoch 28 of 60 took 1.887s\n",
            "Train \tEpoch [28/60]  train_Loss: 0.5446\ttrain_Acc: 87.66\n",
            "Val \tEpoch [28/60]  val_Loss: 0.4825\tval_Acc: 91.56\n",
            "Test \tEpoch [28/60]  test_Loss: 0.3134\ttest_Acc: 99.11\n",
            "--------------------------------------------------\n",
            "Epoch 29 of 60 took 1.908s\n",
            "Train \tEpoch [29/60]  train_Loss: 0.5167\ttrain_Acc: 89.33\n",
            "Val \tEpoch [29/60]  val_Loss: 0.4728\tval_Acc: 91.56\n",
            "Test \tEpoch [29/60]  test_Loss: 0.2923\ttest_Acc: 97.78\n",
            "--------------------------------------------------\n",
            "Epoch 30 of 60 took 1.921s\n",
            "Train \tEpoch [30/60]  train_Loss: 0.4996\ttrain_Acc: 89.35\n",
            "Val \tEpoch [30/60]  val_Loss: 0.4860\tval_Acc: 90.67\n",
            "Test \tEpoch [30/60]  test_Loss: 0.3167\ttest_Acc: 96.89\n",
            "--------------------------------------------------\n",
            "Epoch 31 of 60 took 1.905s\n",
            "Train \tEpoch [31/60]  train_Loss: 0.4933\ttrain_Acc: 89.87\n",
            "Val \tEpoch [31/60]  val_Loss: 0.4298\tval_Acc: 91.56\n",
            "Test \tEpoch [31/60]  test_Loss: 0.2883\ttest_Acc: 97.78\n",
            "--------------------------------------------------\n",
            "Epoch 32 of 60 took 1.921s\n",
            "Train \tEpoch [32/60]  train_Loss: 0.4928\ttrain_Acc: 89.76\n",
            "Val \tEpoch [32/60]  val_Loss: 0.4362\tval_Acc: 91.56\n",
            "Test \tEpoch [32/60]  test_Loss: 0.3120\ttest_Acc: 96.44\n",
            "--------------------------------------------------\n",
            "Epoch 33 of 60 took 1.916s\n",
            "Train \tEpoch [33/60]  train_Loss: 0.5014\ttrain_Acc: 89.60\n",
            "Val \tEpoch [33/60]  val_Loss: 0.4370\tval_Acc: 91.56\n",
            "Test \tEpoch [33/60]  test_Loss: 0.2875\ttest_Acc: 96.89\n",
            "--------------------------------------------------\n",
            "Epoch 34 of 60 took 1.980s\n",
            "Train \tEpoch [34/60]  train_Loss: 0.4614\ttrain_Acc: 91.21\n",
            "Val \tEpoch [34/60]  val_Loss: 0.4553\tval_Acc: 91.56\n",
            "Test \tEpoch [34/60]  test_Loss: 0.2745\ttest_Acc: 97.33\n",
            "--------------------------------------------------\n",
            "Time in total: 112.19867300987244\n",
            "Best validation accuracy:\t\t91.56 %\n",
            "Test accuracy when got the best validation accuracy:\t\t97.78 %\n",
            "--------------------------------------------------\n",
            "Last train accuracy:\t\t93.11 %\n",
            "Last validation accuracy:\t\t91.56 %\n",
            "Last test accuracy:\t\t\t\t97.33 %\n",
            "Early Stopping at epoch: 24\n",
            "Done!\n",
            "----------------------------------------------------------------------------------------------------\n",
            "The subjects 10 \t\t Training the 1dconv Model...\n",
            "Load the CNN model weight for backbone...\n",
            "Train set label and proportion:\t (array([0, 1, 2, 3], dtype=int32), array([646, 604, 525, 461]))\n",
            "Val   set label and proportion:\t (array([0, 1, 2, 3], dtype=int32), array([54, 53, 62, 48]))\n",
            "Test  set label and proportion:\t (array([0, 1, 2, 3], dtype=int32), array([57, 58, 53, 49]))\n",
            "The shape of X_trian:\t (7, 2236, 32, 32, 3)\n",
            "The shape of X_val:\t (7, 217, 32, 32, 3)\n",
            "The shape of X_test:\t (7, 217, 32, 32, 3)\n",
            "Building model and compiling functions...\n",
            "Writing to /content/runs/2020-02-05.14.17_1dconv/1dconv_10\n",
            "\n",
            "Starting training...\n",
            "--------------------------------------------------\n",
            "Epoch 1 of 60 took 2.816s\n",
            "Train \tEpoch [1/60]  train_Loss: 4.7748\ttrain_Acc: 30.20\n",
            "Val \tEpoch [1/60]  val_Loss: 1.4632\tval_Acc: 47.47\n",
            "Test \tEpoch [1/60]  test_Loss: 1.6219\ttest_Acc: 41.47\n",
            "--------------------------------------------------\n",
            "Epoch 2 of 60 took 1.937s\n",
            "Train \tEpoch [2/60]  train_Loss: 1.7829\ttrain_Acc: 35.40\n",
            "Val \tEpoch [2/60]  val_Loss: 1.4285\tval_Acc: 49.77\n",
            "Test \tEpoch [2/60]  test_Loss: 1.5550\ttest_Acc: 49.77\n",
            "--------------------------------------------------\n",
            "Epoch 3 of 60 took 1.926s\n",
            "Train \tEpoch [3/60]  train_Loss: 1.5618\ttrain_Acc: 43.75\n",
            "Val \tEpoch [3/60]  val_Loss: 1.3351\tval_Acc: 59.45\n",
            "Test \tEpoch [3/60]  test_Loss: 1.4021\ttest_Acc: 58.99\n",
            "--------------------------------------------------\n",
            "Epoch 4 of 60 took 1.933s\n",
            "Train \tEpoch [4/60]  train_Loss: 1.4862\ttrain_Acc: 47.54\n",
            "Val \tEpoch [4/60]  val_Loss: 1.2426\tval_Acc: 61.75\n",
            "Test \tEpoch [4/60]  test_Loss: 1.3341\ttest_Acc: 59.45\n",
            "--------------------------------------------------\n",
            "Epoch 5 of 60 took 1.948s\n",
            "Train \tEpoch [5/60]  train_Loss: 1.3800\ttrain_Acc: 52.08\n",
            "Val \tEpoch [5/60]  val_Loss: 1.2479\tval_Acc: 61.75\n",
            "Test \tEpoch [5/60]  test_Loss: 1.2897\ttest_Acc: 60.83\n",
            "--------------------------------------------------\n",
            "Epoch 6 of 60 took 1.923s\n",
            "Train \tEpoch [6/60]  train_Loss: 1.2982\ttrain_Acc: 55.60\n",
            "Val \tEpoch [6/60]  val_Loss: 1.0979\tval_Acc: 65.44\n",
            "Test \tEpoch [6/60]  test_Loss: 1.1896\ttest_Acc: 70.05\n",
            "--------------------------------------------------\n",
            "Epoch 7 of 60 took 1.980s\n",
            "Train \tEpoch [7/60]  train_Loss: 1.2124\ttrain_Acc: 60.38\n",
            "Val \tEpoch [7/60]  val_Loss: 1.0203\tval_Acc: 75.58\n",
            "Test \tEpoch [7/60]  test_Loss: 1.1648\ttest_Acc: 71.43\n",
            "--------------------------------------------------\n",
            "Epoch 8 of 60 took 1.941s\n",
            "Train \tEpoch [8/60]  train_Loss: 1.1103\ttrain_Acc: 64.64\n",
            "Val \tEpoch [8/60]  val_Loss: 0.9185\tval_Acc: 81.11\n",
            "Test \tEpoch [8/60]  test_Loss: 1.1353\ttest_Acc: 71.89\n",
            "--------------------------------------------------\n",
            "Epoch 9 of 60 took 1.931s\n",
            "Train \tEpoch [9/60]  train_Loss: 1.0593\ttrain_Acc: 68.57\n",
            "Val \tEpoch [9/60]  val_Loss: 0.8472\tval_Acc: 81.57\n",
            "Test \tEpoch [9/60]  test_Loss: 1.1307\ttest_Acc: 72.81\n",
            "--------------------------------------------------\n",
            "Epoch 10 of 60 took 1.914s\n",
            "Train \tEpoch [10/60]  train_Loss: 0.9840\ttrain_Acc: 70.22\n",
            "Val \tEpoch [10/60]  val_Loss: 0.7636\tval_Acc: 84.79\n",
            "Test \tEpoch [10/60]  test_Loss: 1.0049\ttest_Acc: 71.43\n",
            "--------------------------------------------------\n",
            "Epoch 11 of 60 took 1.986s\n",
            "Train \tEpoch [11/60]  train_Loss: 0.9340\ttrain_Acc: 73.46\n",
            "Val \tEpoch [11/60]  val_Loss: 0.7093\tval_Acc: 87.56\n",
            "Test \tEpoch [11/60]  test_Loss: 0.8996\ttest_Acc: 73.73\n",
            "--------------------------------------------------\n",
            "Epoch 12 of 60 took 1.915s\n",
            "Train \tEpoch [12/60]  train_Loss: 0.8728\ttrain_Acc: 74.70\n",
            "Val \tEpoch [12/60]  val_Loss: 0.7146\tval_Acc: 88.02\n",
            "Test \tEpoch [12/60]  test_Loss: 0.9679\ttest_Acc: 76.04\n",
            "--------------------------------------------------\n",
            "Epoch 13 of 60 took 1.913s\n",
            "Train \tEpoch [13/60]  train_Loss: 0.8006\ttrain_Acc: 77.30\n",
            "Val \tEpoch [13/60]  val_Loss: 0.6128\tval_Acc: 90.78\n",
            "Test \tEpoch [13/60]  test_Loss: 0.9067\ttest_Acc: 77.88\n",
            "--------------------------------------------------\n",
            "Epoch 14 of 60 took 1.912s\n",
            "Train \tEpoch [14/60]  train_Loss: 0.8086\ttrain_Acc: 78.14\n",
            "Val \tEpoch [14/60]  val_Loss: 0.6001\tval_Acc: 89.86\n",
            "Test \tEpoch [14/60]  test_Loss: 0.8857\ttest_Acc: 78.34\n",
            "--------------------------------------------------\n",
            "Epoch 15 of 60 took 1.920s\n",
            "Train \tEpoch [15/60]  train_Loss: 0.7480\ttrain_Acc: 79.64\n",
            "Val \tEpoch [15/60]  val_Loss: 0.5792\tval_Acc: 88.94\n",
            "Test \tEpoch [15/60]  test_Loss: 0.8292\ttest_Acc: 81.57\n",
            "--------------------------------------------------\n",
            "Epoch 16 of 60 took 1.917s\n",
            "Train \tEpoch [16/60]  train_Loss: 0.6838\ttrain_Acc: 81.89\n",
            "Val \tEpoch [16/60]  val_Loss: 0.5389\tval_Acc: 91.24\n",
            "Test \tEpoch [16/60]  test_Loss: 0.8016\ttest_Acc: 82.49\n",
            "--------------------------------------------------\n",
            "Epoch 17 of 60 took 1.935s\n",
            "Train \tEpoch [17/60]  train_Loss: 0.6769\ttrain_Acc: 82.60\n",
            "Val \tEpoch [17/60]  val_Loss: 0.5384\tval_Acc: 90.32\n",
            "Test \tEpoch [17/60]  test_Loss: 0.7389\ttest_Acc: 84.33\n",
            "--------------------------------------------------\n",
            "Epoch 18 of 60 took 1.922s\n",
            "Train \tEpoch [18/60]  train_Loss: 0.6564\ttrain_Acc: 83.93\n",
            "Val \tEpoch [18/60]  val_Loss: 0.5448\tval_Acc: 90.78\n",
            "Test \tEpoch [18/60]  test_Loss: 0.8343\ttest_Acc: 80.18\n",
            "--------------------------------------------------\n",
            "Epoch 19 of 60 took 1.934s\n",
            "Train \tEpoch [19/60]  train_Loss: 0.6232\ttrain_Acc: 83.93\n",
            "Val \tEpoch [19/60]  val_Loss: 0.5149\tval_Acc: 90.32\n",
            "Test \tEpoch [19/60]  test_Loss: 0.6800\ttest_Acc: 87.10\n",
            "--------------------------------------------------\n",
            "Epoch 20 of 60 took 1.939s\n",
            "Train \tEpoch [20/60]  train_Loss: 0.5915\ttrain_Acc: 86.02\n",
            "Val \tEpoch [20/60]  val_Loss: 0.5173\tval_Acc: 88.02\n",
            "Test \tEpoch [20/60]  test_Loss: 0.6557\ttest_Acc: 87.56\n",
            "--------------------------------------------------\n",
            "Epoch 21 of 60 took 1.974s\n",
            "Train \tEpoch [21/60]  train_Loss: 0.5720\ttrain_Acc: 86.72\n",
            "Val \tEpoch [21/60]  val_Loss: 0.4698\tval_Acc: 89.86\n",
            "Test \tEpoch [21/60]  test_Loss: 0.6379\ttest_Acc: 88.94\n",
            "--------------------------------------------------\n",
            "Epoch 22 of 60 took 1.919s\n",
            "Train \tEpoch [22/60]  train_Loss: 0.5641\ttrain_Acc: 87.54\n",
            "Val \tEpoch [22/60]  val_Loss: 0.5100\tval_Acc: 88.94\n",
            "Test \tEpoch [22/60]  test_Loss: 0.6077\ttest_Acc: 89.40\n",
            "--------------------------------------------------\n",
            "Epoch 23 of 60 took 1.940s\n",
            "Train \tEpoch [23/60]  train_Loss: 0.5384\ttrain_Acc: 87.80\n",
            "Val \tEpoch [23/60]  val_Loss: 0.5044\tval_Acc: 90.78\n",
            "Test \tEpoch [23/60]  test_Loss: 0.5519\ttest_Acc: 90.78\n",
            "--------------------------------------------------\n",
            "Epoch 24 of 60 took 1.930s\n",
            "Train \tEpoch [24/60]  train_Loss: 0.5280\ttrain_Acc: 88.11\n",
            "Val \tEpoch [24/60]  val_Loss: 0.4854\tval_Acc: 90.78\n",
            "Test \tEpoch [24/60]  test_Loss: 0.5705\ttest_Acc: 88.94\n",
            "--------------------------------------------------\n",
            "Epoch 25 of 60 took 1.904s\n",
            "Train \tEpoch [25/60]  train_Loss: 0.5112\ttrain_Acc: 88.81\n",
            "Val \tEpoch [25/60]  val_Loss: 0.4928\tval_Acc: 91.24\n",
            "Test \tEpoch [25/60]  test_Loss: 0.5433\ttest_Acc: 90.78\n",
            "--------------------------------------------------\n",
            "Epoch 26 of 60 took 1.960s\n",
            "Train \tEpoch [26/60]  train_Loss: 0.5040\ttrain_Acc: 89.32\n",
            "Val \tEpoch [26/60]  val_Loss: 0.4846\tval_Acc: 89.40\n",
            "Test \tEpoch [26/60]  test_Loss: 0.5724\ttest_Acc: 87.56\n",
            "--------------------------------------------------\n",
            "Time in total: 96.60371136665344\n",
            "Best validation accuracy:\t\t91.24 %\n",
            "Test accuracy when got the best validation accuracy:\t\t82.49 %\n",
            "--------------------------------------------------\n",
            "Last train accuracy:\t\t93.74 %\n",
            "Last validation accuracy:\t\t89.40 %\n",
            "Last test accuracy:\t\t\t\t87.56 %\n",
            "Early Stopping at epoch: 16\n",
            "Done!\n",
            "----------------------------------------------------------------------------------------------------\n",
            "The subjects 11 \t\t Training the 1dconv Model...\n",
            "Load the CNN model weight for backbone...\n",
            "Train set label and proportion:\t (array([0, 1, 2, 3], dtype=int32), array([631, 603, 544, 474]))\n",
            "Val   set label and proportion:\t (array([0, 1, 2, 3], dtype=int32), array([68, 56, 44, 41]))\n",
            "Test  set label and proportion:\t (array([0, 1, 2, 3], dtype=int32), array([58, 56, 52, 43]))\n",
            "The shape of X_trian:\t (7, 2252, 32, 32, 3)\n",
            "The shape of X_val:\t (7, 209, 32, 32, 3)\n",
            "The shape of X_test:\t (7, 209, 32, 32, 3)\n",
            "Building model and compiling functions...\n",
            "Writing to /content/runs/2020-02-05.14.17_1dconv/1dconv_11\n",
            "\n",
            "Starting training...\n",
            "--------------------------------------------------\n",
            "Epoch 1 of 60 took 2.836s\n",
            "Train \tEpoch [1/60]  train_Loss: 7.5571\ttrain_Acc: 31.63\n",
            "Val \tEpoch [1/60]  val_Loss: 1.5612\tval_Acc: 58.37\n",
            "Test \tEpoch [1/60]  test_Loss: 1.5667\ttest_Acc: 59.81\n",
            "--------------------------------------------------\n",
            "Epoch 2 of 60 took 1.965s\n",
            "Train \tEpoch [2/60]  train_Loss: 1.7939\ttrain_Acc: 39.94\n",
            "Val \tEpoch [2/60]  val_Loss: 1.3958\tval_Acc: 59.81\n",
            "Test \tEpoch [2/60]  test_Loss: 1.4452\ttest_Acc: 52.15\n",
            "--------------------------------------------------\n",
            "Epoch 3 of 60 took 1.955s\n",
            "Train \tEpoch [3/60]  train_Loss: 1.5543\ttrain_Acc: 43.72\n",
            "Val \tEpoch [3/60]  val_Loss: 1.2349\tval_Acc: 65.55\n",
            "Test \tEpoch [3/60]  test_Loss: 1.3950\ttest_Acc: 51.20\n",
            "--------------------------------------------------\n",
            "Epoch 4 of 60 took 1.944s\n",
            "Train \tEpoch [4/60]  train_Loss: 1.4519\ttrain_Acc: 45.36\n",
            "Val \tEpoch [4/60]  val_Loss: 1.1669\tval_Acc: 67.94\n",
            "Test \tEpoch [4/60]  test_Loss: 1.4461\ttest_Acc: 28.23\n",
            "--------------------------------------------------\n",
            "Epoch 5 of 60 took 1.931s\n",
            "Train \tEpoch [5/60]  train_Loss: 1.4085\ttrain_Acc: 49.22\n",
            "Val \tEpoch [5/60]  val_Loss: 1.0599\tval_Acc: 69.86\n",
            "Test \tEpoch [5/60]  test_Loss: 1.4201\ttest_Acc: 43.06\n",
            "--------------------------------------------------\n",
            "Epoch 6 of 60 took 1.923s\n",
            "Train \tEpoch [6/60]  train_Loss: 1.3086\ttrain_Acc: 54.23\n",
            "Val \tEpoch [6/60]  val_Loss: 0.9574\tval_Acc: 75.12\n",
            "Test \tEpoch [6/60]  test_Loss: 1.3978\ttest_Acc: 49.76\n",
            "--------------------------------------------------\n",
            "Epoch 7 of 60 took 1.984s\n",
            "Train \tEpoch [7/60]  train_Loss: 1.2252\ttrain_Acc: 55.90\n",
            "Val \tEpoch [7/60]  val_Loss: 0.9300\tval_Acc: 77.99\n",
            "Test \tEpoch [7/60]  test_Loss: 1.4879\ttest_Acc: 26.32\n",
            "--------------------------------------------------\n",
            "Epoch 8 of 60 took 1.927s\n",
            "Train \tEpoch [8/60]  train_Loss: 1.1708\ttrain_Acc: 59.51\n",
            "Val \tEpoch [8/60]  val_Loss: 0.8415\tval_Acc: 81.34\n",
            "Test \tEpoch [8/60]  test_Loss: 1.4129\ttest_Acc: 30.62\n",
            "--------------------------------------------------\n",
            "Epoch 9 of 60 took 1.922s\n",
            "Train \tEpoch [9/60]  train_Loss: 1.0926\ttrain_Acc: 63.91\n",
            "Val \tEpoch [9/60]  val_Loss: 0.8127\tval_Acc: 79.43\n",
            "Test \tEpoch [9/60]  test_Loss: 1.4090\ttest_Acc: 48.80\n",
            "--------------------------------------------------\n",
            "Epoch 10 of 60 took 1.947s\n",
            "Train \tEpoch [10/60]  train_Loss: 1.0407\ttrain_Acc: 67.05\n",
            "Val \tEpoch [10/60]  val_Loss: 0.7448\tval_Acc: 81.82\n",
            "Test \tEpoch [10/60]  test_Loss: 1.4088\ttest_Acc: 39.71\n",
            "--------------------------------------------------\n",
            "Epoch 11 of 60 took 1.940s\n",
            "Train \tEpoch [11/60]  train_Loss: 0.9942\ttrain_Acc: 69.70\n",
            "Val \tEpoch [11/60]  val_Loss: 0.7281\tval_Acc: 82.78\n",
            "Test \tEpoch [11/60]  test_Loss: 1.4392\ttest_Acc: 31.10\n",
            "--------------------------------------------------\n",
            "Epoch 12 of 60 took 1.940s\n",
            "Train \tEpoch [12/60]  train_Loss: 0.9405\ttrain_Acc: 71.63\n",
            "Val \tEpoch [12/60]  val_Loss: 0.6493\tval_Acc: 86.60\n",
            "Test \tEpoch [12/60]  test_Loss: 1.3938\ttest_Acc: 33.49\n",
            "--------------------------------------------------\n",
            "Epoch 13 of 60 took 1.955s\n",
            "Train \tEpoch [13/60]  train_Loss: 0.8852\ttrain_Acc: 75.65\n",
            "Val \tEpoch [13/60]  val_Loss: 0.6101\tval_Acc: 85.17\n",
            "Test \tEpoch [13/60]  test_Loss: 1.2932\ttest_Acc: 60.77\n",
            "--------------------------------------------------\n",
            "Epoch 14 of 60 took 1.937s\n",
            "Train \tEpoch [14/60]  train_Loss: 0.7939\ttrain_Acc: 77.88\n",
            "Val \tEpoch [14/60]  val_Loss: 0.5440\tval_Acc: 88.04\n",
            "Test \tEpoch [14/60]  test_Loss: 1.2153\ttest_Acc: 44.02\n",
            "--------------------------------------------------\n",
            "Epoch 15 of 60 took 1.944s\n",
            "Train \tEpoch [15/60]  train_Loss: 0.7597\ttrain_Acc: 79.49\n",
            "Val \tEpoch [15/60]  val_Loss: 0.5100\tval_Acc: 89.47\n",
            "Test \tEpoch [15/60]  test_Loss: 1.1787\ttest_Acc: 48.80\n",
            "--------------------------------------------------\n",
            "Epoch 16 of 60 took 1.945s\n",
            "Train \tEpoch [16/60]  train_Loss: 0.7020\ttrain_Acc: 81.57\n",
            "Val \tEpoch [16/60]  val_Loss: 0.4886\tval_Acc: 89.47\n",
            "Test \tEpoch [16/60]  test_Loss: 1.1379\ttest_Acc: 53.11\n",
            "--------------------------------------------------\n",
            "Epoch 17 of 60 took 1.968s\n",
            "Train \tEpoch [17/60]  train_Loss: 0.6683\ttrain_Acc: 83.29\n",
            "Val \tEpoch [17/60]  val_Loss: 0.5182\tval_Acc: 87.56\n",
            "Test \tEpoch [17/60]  test_Loss: 1.0364\ttest_Acc: 70.81\n",
            "--------------------------------------------------\n",
            "Epoch 18 of 60 took 1.946s\n",
            "Train \tEpoch [18/60]  train_Loss: 0.6901\ttrain_Acc: 82.28\n",
            "Val \tEpoch [18/60]  val_Loss: 0.4696\tval_Acc: 89.00\n",
            "Test \tEpoch [18/60]  test_Loss: 0.9752\ttest_Acc: 72.25\n",
            "--------------------------------------------------\n",
            "Epoch 19 of 60 took 1.936s\n",
            "Train \tEpoch [19/60]  train_Loss: 0.6315\ttrain_Acc: 84.08\n",
            "Val \tEpoch [19/60]  val_Loss: 0.4619\tval_Acc: 88.52\n",
            "Test \tEpoch [19/60]  test_Loss: 0.9826\ttest_Acc: 77.51\n",
            "--------------------------------------------------\n",
            "Epoch 20 of 60 took 1.941s\n",
            "Train \tEpoch [20/60]  train_Loss: 0.5794\ttrain_Acc: 86.46\n",
            "Val \tEpoch [20/60]  val_Loss: 0.4369\tval_Acc: 91.39\n",
            "Test \tEpoch [20/60]  test_Loss: 0.9152\ttest_Acc: 67.94\n",
            "--------------------------------------------------\n",
            "Epoch 21 of 60 took 1.988s\n",
            "Train \tEpoch [21/60]  train_Loss: 0.5591\ttrain_Acc: 88.13\n",
            "Val \tEpoch [21/60]  val_Loss: 0.4269\tval_Acc: 89.00\n",
            "Test \tEpoch [21/60]  test_Loss: 0.8306\ttest_Acc: 79.43\n",
            "--------------------------------------------------\n",
            "Epoch 22 of 60 took 1.934s\n",
            "Train \tEpoch [22/60]  train_Loss: 0.5562\ttrain_Acc: 87.51\n",
            "Val \tEpoch [22/60]  val_Loss: 0.4359\tval_Acc: 89.47\n",
            "Test \tEpoch [22/60]  test_Loss: 0.8588\ttest_Acc: 82.30\n",
            "--------------------------------------------------\n",
            "Epoch 23 of 60 took 1.956s\n",
            "Train \tEpoch [23/60]  train_Loss: 0.5363\ttrain_Acc: 88.19\n",
            "Val \tEpoch [23/60]  val_Loss: 0.4494\tval_Acc: 90.43\n",
            "Test \tEpoch [23/60]  test_Loss: 0.9033\ttest_Acc: 70.33\n",
            "--------------------------------------------------\n",
            "Epoch 24 of 60 took 1.935s\n",
            "Train \tEpoch [24/60]  train_Loss: 0.5132\ttrain_Acc: 88.66\n",
            "Val \tEpoch [24/60]  val_Loss: 0.4102\tval_Acc: 89.95\n",
            "Test \tEpoch [24/60]  test_Loss: 0.7598\ttest_Acc: 81.82\n",
            "--------------------------------------------------\n",
            "Epoch 25 of 60 took 1.929s\n",
            "Train \tEpoch [25/60]  train_Loss: 0.5158\ttrain_Acc: 89.67\n",
            "Val \tEpoch [25/60]  val_Loss: 0.4612\tval_Acc: 90.43\n",
            "Test \tEpoch [25/60]  test_Loss: 0.7543\ttest_Acc: 87.08\n",
            "--------------------------------------------------\n",
            "Epoch 26 of 60 took 1.942s\n",
            "Train \tEpoch [26/60]  train_Loss: 0.4678\ttrain_Acc: 90.83\n",
            "Val \tEpoch [26/60]  val_Loss: 0.4232\tval_Acc: 91.39\n",
            "Test \tEpoch [26/60]  test_Loss: 0.6862\ttest_Acc: 89.47\n",
            "--------------------------------------------------\n",
            "Epoch 27 of 60 took 1.944s\n",
            "Train \tEpoch [27/60]  train_Loss: 0.4668\ttrain_Acc: 91.18\n",
            "Val \tEpoch [27/60]  val_Loss: 0.4131\tval_Acc: 91.39\n",
            "Test \tEpoch [27/60]  test_Loss: 0.6991\ttest_Acc: 80.38\n",
            "--------------------------------------------------\n",
            "Epoch 28 of 60 took 1.934s\n",
            "Train \tEpoch [28/60]  train_Loss: 0.4737\ttrain_Acc: 90.95\n",
            "Val \tEpoch [28/60]  val_Loss: 0.4012\tval_Acc: 92.34\n",
            "Test \tEpoch [28/60]  test_Loss: 0.6734\ttest_Acc: 90.43\n",
            "--------------------------------------------------\n",
            "Epoch 29 of 60 took 1.970s\n",
            "Train \tEpoch [29/60]  train_Loss: 0.4520\ttrain_Acc: 90.82\n",
            "Val \tEpoch [29/60]  val_Loss: 0.4070\tval_Acc: 91.39\n",
            "Test \tEpoch [29/60]  test_Loss: 0.7065\ttest_Acc: 88.52\n",
            "--------------------------------------------------\n",
            "Epoch 30 of 60 took 1.951s\n",
            "Train \tEpoch [30/60]  train_Loss: 0.4543\ttrain_Acc: 90.82\n",
            "Val \tEpoch [30/60]  val_Loss: 0.4136\tval_Acc: 91.87\n",
            "Test \tEpoch [30/60]  test_Loss: 0.7044\ttest_Acc: 88.04\n",
            "--------------------------------------------------\n",
            "Epoch 31 of 60 took 1.976s\n",
            "Train \tEpoch [31/60]  train_Loss: 0.4517\ttrain_Acc: 91.12\n",
            "Val \tEpoch [31/60]  val_Loss: 0.3952\tval_Acc: 92.34\n",
            "Test \tEpoch [31/60]  test_Loss: 0.6555\ttest_Acc: 89.95\n",
            "--------------------------------------------------\n",
            "Epoch 32 of 60 took 1.949s\n",
            "Train \tEpoch [32/60]  train_Loss: 0.4714\ttrain_Acc: 90.64\n",
            "Val \tEpoch [32/60]  val_Loss: 0.3909\tval_Acc: 93.78\n",
            "Test \tEpoch [32/60]  test_Loss: 0.7755\ttest_Acc: 66.99\n",
            "--------------------------------------------------\n",
            "Epoch 33 of 60 took 1.949s\n",
            "Train \tEpoch [33/60]  train_Loss: 0.4427\ttrain_Acc: 91.21\n",
            "Val \tEpoch [33/60]  val_Loss: 0.3806\tval_Acc: 91.39\n",
            "Test \tEpoch [33/60]  test_Loss: 0.6885\ttest_Acc: 77.03\n",
            "--------------------------------------------------\n",
            "Epoch 34 of 60 took 1.928s\n",
            "Train \tEpoch [34/60]  train_Loss: 0.4084\ttrain_Acc: 92.31\n",
            "Val \tEpoch [34/60]  val_Loss: 0.4012\tval_Acc: 91.87\n",
            "Test \tEpoch [34/60]  test_Loss: 0.7090\ttest_Acc: 89.47\n",
            "--------------------------------------------------\n",
            "Epoch 35 of 60 took 1.933s\n",
            "Train \tEpoch [35/60]  train_Loss: 0.4244\ttrain_Acc: 91.92\n",
            "Val \tEpoch [35/60]  val_Loss: 0.4082\tval_Acc: 91.39\n",
            "Test \tEpoch [35/60]  test_Loss: 0.6178\ttest_Acc: 90.43\n",
            "--------------------------------------------------\n",
            "Epoch 36 of 60 took 1.987s\n",
            "Train \tEpoch [36/60]  train_Loss: 0.4211\ttrain_Acc: 92.05\n",
            "Val \tEpoch [36/60]  val_Loss: 0.4026\tval_Acc: 91.87\n",
            "Test \tEpoch [36/60]  test_Loss: 0.5888\ttest_Acc: 90.91\n",
            "--------------------------------------------------\n",
            "Epoch 37 of 60 took 1.958s\n",
            "Train \tEpoch [37/60]  train_Loss: 0.4151\ttrain_Acc: 92.49\n",
            "Val \tEpoch [37/60]  val_Loss: 0.3834\tval_Acc: 93.30\n",
            "Test \tEpoch [37/60]  test_Loss: 0.8177\ttest_Acc: 65.55\n",
            "--------------------------------------------------\n",
            "Epoch 38 of 60 took 1.960s\n",
            "Train \tEpoch [38/60]  train_Loss: 0.4128\ttrain_Acc: 92.62\n",
            "Val \tEpoch [38/60]  val_Loss: 0.3837\tval_Acc: 90.91\n",
            "Test \tEpoch [38/60]  test_Loss: 0.6401\ttest_Acc: 86.12\n",
            "--------------------------------------------------\n",
            "Epoch 39 of 60 took 1.934s\n",
            "Train \tEpoch [39/60]  train_Loss: 0.4142\ttrain_Acc: 91.52\n",
            "Val \tEpoch [39/60]  val_Loss: 0.3740\tval_Acc: 91.39\n",
            "Test \tEpoch [39/60]  test_Loss: 0.6482\ttest_Acc: 77.03\n",
            "--------------------------------------------------\n",
            "Epoch 40 of 60 took 1.936s\n",
            "Train \tEpoch [40/60]  train_Loss: 0.4027\ttrain_Acc: 92.80\n",
            "Val \tEpoch [40/60]  val_Loss: 0.3907\tval_Acc: 92.82\n",
            "Test \tEpoch [40/60]  test_Loss: 0.7900\ttest_Acc: 75.12\n",
            "--------------------------------------------------\n",
            "Epoch 41 of 60 took 1.970s\n",
            "Train \tEpoch [41/60]  train_Loss: 0.4002\ttrain_Acc: 92.40\n",
            "Val \tEpoch [41/60]  val_Loss: 0.3774\tval_Acc: 92.34\n",
            "Test \tEpoch [41/60]  test_Loss: 0.6506\ttest_Acc: 82.30\n",
            "--------------------------------------------------\n",
            "Epoch 42 of 60 took 1.977s\n",
            "Train \tEpoch [42/60]  train_Loss: 0.3924\ttrain_Acc: 92.90\n",
            "Val \tEpoch [42/60]  val_Loss: 0.3722\tval_Acc: 92.82\n",
            "Test \tEpoch [42/60]  test_Loss: 0.6723\ttest_Acc: 76.08\n",
            "--------------------------------------------------\n",
            "Time in total: 130.66912150382996\n",
            "Best validation accuracy:\t\t93.78 %\n",
            "Test accuracy when got the best validation accuracy:\t\t66.99 %\n",
            "--------------------------------------------------\n",
            "Last train accuracy:\t\t95.56 %\n",
            "Last validation accuracy:\t\t92.82 %\n",
            "Last test accuracy:\t\t\t\t76.08 %\n",
            "Early Stopping at epoch: 32\n",
            "Done!\n",
            "----------------------------------------------------------------------------------------------------\n",
            "The subjects 12 \t\t Training the 1dconv Model...\n",
            "Load the CNN model weight for backbone...\n",
            "Train set label and proportion:\t (array([0, 1, 2, 3], dtype=int32), array([620, 602, 536, 472]))\n",
            "Val   set label and proportion:\t (array([0, 1, 2, 3], dtype=int32), array([77, 54, 50, 39]))\n",
            "Test  set label and proportion:\t (array([0, 1, 2, 3], dtype=int32), array([60, 59, 54, 47]))\n",
            "The shape of X_trian:\t (7, 2230, 32, 32, 3)\n",
            "The shape of X_val:\t (7, 220, 32, 32, 3)\n",
            "The shape of X_test:\t (7, 220, 32, 32, 3)\n",
            "Building model and compiling functions...\n",
            "Writing to /content/runs/2020-02-05.14.17_1dconv/1dconv_12\n",
            "\n",
            "Starting training...\n",
            "--------------------------------------------------\n",
            "Epoch 1 of 60 took 3.118s\n",
            "Train \tEpoch [1/60]  train_Loss: 6.5234\ttrain_Acc: 30.98\n",
            "Val \tEpoch [1/60]  val_Loss: 1.3717\tval_Acc: 51.82\n",
            "Test \tEpoch [1/60]  test_Loss: 1.9722\ttest_Acc: 12.73\n",
            "--------------------------------------------------\n",
            "Epoch 2 of 60 took 1.919s\n",
            "Train \tEpoch [2/60]  train_Loss: 1.6919\ttrain_Acc: 39.07\n",
            "Val \tEpoch [2/60]  val_Loss: 1.3440\tval_Acc: 55.91\n",
            "Test \tEpoch [2/60]  test_Loss: 1.9111\ttest_Acc: 25.00\n",
            "--------------------------------------------------\n",
            "Epoch 3 of 60 took 1.932s\n",
            "Train \tEpoch [3/60]  train_Loss: 1.5741\ttrain_Acc: 42.09\n",
            "Val \tEpoch [3/60]  val_Loss: 1.3202\tval_Acc: 62.27\n",
            "Test \tEpoch [3/60]  test_Loss: 1.9109\ttest_Acc: 12.27\n",
            "--------------------------------------------------\n",
            "Epoch 4 of 60 took 1.931s\n",
            "Train \tEpoch [4/60]  train_Loss: 1.4159\ttrain_Acc: 47.23\n",
            "Val \tEpoch [4/60]  val_Loss: 1.1568\tval_Acc: 63.18\n",
            "Test \tEpoch [4/60]  test_Loss: 2.0281\ttest_Acc: 22.73\n",
            "--------------------------------------------------\n",
            "Epoch 5 of 60 took 1.950s\n",
            "Train \tEpoch [5/60]  train_Loss: 1.3549\ttrain_Acc: 52.61\n",
            "Val \tEpoch [5/60]  val_Loss: 1.1242\tval_Acc: 71.82\n",
            "Test \tEpoch [5/60]  test_Loss: 1.8894\ttest_Acc: 15.00\n",
            "--------------------------------------------------\n",
            "Epoch 6 of 60 took 1.935s\n",
            "Train \tEpoch [6/60]  train_Loss: 1.2580\ttrain_Acc: 57.82\n",
            "Val \tEpoch [6/60]  val_Loss: 1.0084\tval_Acc: 72.27\n",
            "Test \tEpoch [6/60]  test_Loss: 2.0800\ttest_Acc: 15.45\n",
            "--------------------------------------------------\n",
            "Epoch 7 of 60 took 1.926s\n",
            "Train \tEpoch [7/60]  train_Loss: 1.1800\ttrain_Acc: 62.07\n",
            "Val \tEpoch [7/60]  val_Loss: 0.9402\tval_Acc: 76.82\n",
            "Test \tEpoch [7/60]  test_Loss: 2.0120\ttest_Acc: 21.82\n",
            "--------------------------------------------------\n",
            "Epoch 8 of 60 took 1.937s\n",
            "Train \tEpoch [8/60]  train_Loss: 1.0950\ttrain_Acc: 64.07\n",
            "Val \tEpoch [8/60]  val_Loss: 0.8526\tval_Acc: 80.00\n",
            "Test \tEpoch [8/60]  test_Loss: 2.0637\ttest_Acc: 30.00\n",
            "--------------------------------------------------\n",
            "Epoch 9 of 60 took 1.919s\n",
            "Train \tEpoch [9/60]  train_Loss: 1.0106\ttrain_Acc: 68.65\n",
            "Val \tEpoch [9/60]  val_Loss: 0.8172\tval_Acc: 82.73\n",
            "Test \tEpoch [9/60]  test_Loss: 1.8653\ttest_Acc: 39.09\n",
            "--------------------------------------------------\n",
            "Epoch 10 of 60 took 1.971s\n",
            "Train \tEpoch [10/60]  train_Loss: 0.9225\ttrain_Acc: 74.03\n",
            "Val \tEpoch [10/60]  val_Loss: 0.6987\tval_Acc: 85.00\n",
            "Test \tEpoch [10/60]  test_Loss: 2.1518\ttest_Acc: 34.55\n",
            "--------------------------------------------------\n",
            "Epoch 11 of 60 took 1.960s\n",
            "Train \tEpoch [11/60]  train_Loss: 0.8495\ttrain_Acc: 75.75\n",
            "Val \tEpoch [11/60]  val_Loss: 0.6447\tval_Acc: 87.73\n",
            "Test \tEpoch [11/60]  test_Loss: 1.9444\ttest_Acc: 39.55\n",
            "--------------------------------------------------\n",
            "Epoch 12 of 60 took 1.948s\n",
            "Train \tEpoch [12/60]  train_Loss: 0.7875\ttrain_Acc: 79.92\n",
            "Val \tEpoch [12/60]  val_Loss: 0.5879\tval_Acc: 87.73\n",
            "Test \tEpoch [12/60]  test_Loss: 2.0721\ttest_Acc: 41.82\n",
            "--------------------------------------------------\n",
            "Epoch 13 of 60 took 1.962s\n",
            "Train \tEpoch [13/60]  train_Loss: 0.7161\ttrain_Acc: 83.02\n",
            "Val \tEpoch [13/60]  val_Loss: 0.5527\tval_Acc: 90.00\n",
            "Test \tEpoch [13/60]  test_Loss: 1.9254\ttest_Acc: 43.18\n",
            "--------------------------------------------------\n",
            "Epoch 14 of 60 took 2.021s\n",
            "Train \tEpoch [14/60]  train_Loss: 0.6930\ttrain_Acc: 84.18\n",
            "Val \tEpoch [14/60]  val_Loss: 0.5851\tval_Acc: 90.00\n",
            "Test \tEpoch [14/60]  test_Loss: 1.5877\ttest_Acc: 45.00\n",
            "--------------------------------------------------\n",
            "Epoch 15 of 60 took 1.955s\n",
            "Train \tEpoch [15/60]  train_Loss: 0.6499\ttrain_Acc: 85.43\n",
            "Val \tEpoch [15/60]  val_Loss: 0.4569\tval_Acc: 91.36\n",
            "Test \tEpoch [15/60]  test_Loss: 2.1439\ttest_Acc: 44.09\n",
            "--------------------------------------------------\n",
            "Epoch 16 of 60 took 1.927s\n",
            "Train \tEpoch [16/60]  train_Loss: 0.5774\ttrain_Acc: 88.04\n",
            "Val \tEpoch [16/60]  val_Loss: 0.4266\tval_Acc: 92.27\n",
            "Test \tEpoch [16/60]  test_Loss: 2.0036\ttest_Acc: 44.09\n",
            "--------------------------------------------------\n",
            "Epoch 17 of 60 took 1.917s\n",
            "Train \tEpoch [17/60]  train_Loss: 0.5373\ttrain_Acc: 89.09\n",
            "Val \tEpoch [17/60]  val_Loss: 0.4224\tval_Acc: 92.27\n",
            "Test \tEpoch [17/60]  test_Loss: 2.0504\ttest_Acc: 45.00\n",
            "--------------------------------------------------\n",
            "Epoch 18 of 60 took 1.954s\n",
            "Train \tEpoch [18/60]  train_Loss: 0.5633\ttrain_Acc: 87.46\n",
            "Val \tEpoch [18/60]  val_Loss: 0.4101\tval_Acc: 92.27\n",
            "Test \tEpoch [18/60]  test_Loss: 1.9446\ttest_Acc: 44.55\n",
            "--------------------------------------------------\n",
            "Epoch 19 of 60 took 1.931s\n",
            "Train \tEpoch [19/60]  train_Loss: 0.5268\ttrain_Acc: 89.69\n",
            "Val \tEpoch [19/60]  val_Loss: 0.4152\tval_Acc: 93.64\n",
            "Test \tEpoch [19/60]  test_Loss: 2.1843\ttest_Acc: 43.64\n",
            "--------------------------------------------------\n",
            "Epoch 20 of 60 took 1.911s\n",
            "Train \tEpoch [20/60]  train_Loss: 0.5091\ttrain_Acc: 89.40\n",
            "Val \tEpoch [20/60]  val_Loss: 0.3845\tval_Acc: 93.18\n",
            "Test \tEpoch [20/60]  test_Loss: 1.7405\ttest_Acc: 45.45\n",
            "--------------------------------------------------\n",
            "Epoch 21 of 60 took 1.942s\n",
            "Train \tEpoch [21/60]  train_Loss: 0.4825\ttrain_Acc: 91.56\n",
            "Val \tEpoch [21/60]  val_Loss: 0.4094\tval_Acc: 94.09\n",
            "Test \tEpoch [21/60]  test_Loss: 1.5433\ttest_Acc: 46.82\n",
            "--------------------------------------------------\n",
            "Epoch 22 of 60 took 1.934s\n",
            "Train \tEpoch [22/60]  train_Loss: 0.4841\ttrain_Acc: 90.83\n",
            "Val \tEpoch [22/60]  val_Loss: 0.3660\tval_Acc: 94.09\n",
            "Test \tEpoch [22/60]  test_Loss: 1.9434\ttest_Acc: 45.45\n",
            "--------------------------------------------------\n",
            "Epoch 23 of 60 took 1.943s\n",
            "Train \tEpoch [23/60]  train_Loss: 0.4568\ttrain_Acc: 92.23\n",
            "Val \tEpoch [23/60]  val_Loss: 0.3715\tval_Acc: 94.55\n",
            "Test \tEpoch [23/60]  test_Loss: 1.8528\ttest_Acc: 45.45\n",
            "--------------------------------------------------\n",
            "Epoch 24 of 60 took 1.949s\n",
            "Train \tEpoch [24/60]  train_Loss: 0.4467\ttrain_Acc: 93.19\n",
            "Val \tEpoch [24/60]  val_Loss: 0.3532\tval_Acc: 95.45\n",
            "Test \tEpoch [24/60]  test_Loss: 1.9067\ttest_Acc: 46.82\n",
            "--------------------------------------------------\n",
            "Epoch 25 of 60 took 1.937s\n",
            "Train \tEpoch [25/60]  train_Loss: 0.4393\ttrain_Acc: 92.28\n",
            "Val \tEpoch [25/60]  val_Loss: 0.3635\tval_Acc: 94.55\n",
            "Test \tEpoch [25/60]  test_Loss: 2.2393\ttest_Acc: 58.18\n",
            "--------------------------------------------------\n",
            "Epoch 26 of 60 took 1.934s\n",
            "Train \tEpoch [26/60]  train_Loss: 0.4387\ttrain_Acc: 92.72\n",
            "Val \tEpoch [26/60]  val_Loss: 0.3845\tval_Acc: 93.18\n",
            "Test \tEpoch [26/60]  test_Loss: 1.8561\ttest_Acc: 45.91\n",
            "--------------------------------------------------\n",
            "Epoch 27 of 60 took 1.916s\n",
            "Train \tEpoch [27/60]  train_Loss: 0.4165\ttrain_Acc: 93.51\n",
            "Val \tEpoch [27/60]  val_Loss: 0.3339\tval_Acc: 95.00\n",
            "Test \tEpoch [27/60]  test_Loss: 1.7962\ttest_Acc: 45.91\n",
            "--------------------------------------------------\n",
            "Epoch 28 of 60 took 1.917s\n",
            "Train \tEpoch [28/60]  train_Loss: 0.4179\ttrain_Acc: 92.48\n",
            "Val \tEpoch [28/60]  val_Loss: 0.3402\tval_Acc: 95.00\n",
            "Test \tEpoch [28/60]  test_Loss: 1.9069\ttest_Acc: 47.27\n",
            "--------------------------------------------------\n",
            "Epoch 29 of 60 took 1.956s\n",
            "Train \tEpoch [29/60]  train_Loss: 0.4229\ttrain_Acc: 92.93\n",
            "Val \tEpoch [29/60]  val_Loss: 0.3340\tval_Acc: 95.45\n",
            "Test \tEpoch [29/60]  test_Loss: 1.7639\ttest_Acc: 47.27\n",
            "--------------------------------------------------\n",
            "Epoch 30 of 60 took 1.922s\n",
            "Train \tEpoch [30/60]  train_Loss: 0.4257\ttrain_Acc: 92.72\n",
            "Val \tEpoch [30/60]  val_Loss: 0.3369\tval_Acc: 94.55\n",
            "Test \tEpoch [30/60]  test_Loss: 1.8748\ttest_Acc: 47.27\n",
            "--------------------------------------------------\n",
            "Epoch 31 of 60 took 1.925s\n",
            "Train \tEpoch [31/60]  train_Loss: 0.4082\ttrain_Acc: 93.15\n",
            "Val \tEpoch [31/60]  val_Loss: 0.3365\tval_Acc: 95.00\n",
            "Test \tEpoch [31/60]  test_Loss: 1.7409\ttest_Acc: 47.27\n",
            "--------------------------------------------------\n",
            "Epoch 32 of 60 took 1.941s\n",
            "Train \tEpoch [32/60]  train_Loss: 0.4018\ttrain_Acc: 93.57\n",
            "Val \tEpoch [32/60]  val_Loss: 0.3238\tval_Acc: 95.91\n",
            "Test \tEpoch [32/60]  test_Loss: 1.8665\ttest_Acc: 46.82\n",
            "--------------------------------------------------\n",
            "Epoch 33 of 60 took 1.936s\n",
            "Train \tEpoch [33/60]  train_Loss: 0.3787\ttrain_Acc: 94.02\n",
            "Val \tEpoch [33/60]  val_Loss: 0.3451\tval_Acc: 94.55\n",
            "Test \tEpoch [33/60]  test_Loss: 1.4132\ttest_Acc: 48.64\n",
            "--------------------------------------------------\n",
            "Epoch 34 of 60 took 1.946s\n",
            "Train \tEpoch [34/60]  train_Loss: 0.3939\ttrain_Acc: 93.88\n",
            "Val \tEpoch [34/60]  val_Loss: 0.3534\tval_Acc: 95.00\n",
            "Test \tEpoch [34/60]  test_Loss: 1.6949\ttest_Acc: 44.55\n",
            "--------------------------------------------------\n",
            "Epoch 35 of 60 took 1.926s\n",
            "Train \tEpoch [35/60]  train_Loss: 0.3848\ttrain_Acc: 94.33\n",
            "Val \tEpoch [35/60]  val_Loss: 0.3208\tval_Acc: 95.91\n",
            "Test \tEpoch [35/60]  test_Loss: 1.8659\ttest_Acc: 47.27\n",
            "--------------------------------------------------\n",
            "Epoch 36 of 60 took 1.946s\n",
            "Train \tEpoch [36/60]  train_Loss: 0.3842\ttrain_Acc: 93.53\n",
            "Val \tEpoch [36/60]  val_Loss: 0.3391\tval_Acc: 95.00\n",
            "Test \tEpoch [36/60]  test_Loss: 1.9572\ttest_Acc: 47.27\n",
            "--------------------------------------------------\n",
            "Epoch 37 of 60 took 1.949s\n",
            "Train \tEpoch [37/60]  train_Loss: 0.3680\ttrain_Acc: 94.02\n",
            "Val \tEpoch [37/60]  val_Loss: 0.3287\tval_Acc: 95.45\n",
            "Test \tEpoch [37/60]  test_Loss: 2.2613\ttest_Acc: 46.82\n",
            "--------------------------------------------------\n",
            "Epoch 38 of 60 took 1.933s\n",
            "Train \tEpoch [38/60]  train_Loss: 0.3564\ttrain_Acc: 94.73\n",
            "Val \tEpoch [38/60]  val_Loss: 0.3246\tval_Acc: 95.91\n",
            "Test \tEpoch [38/60]  test_Loss: 1.9053\ttest_Acc: 46.82\n",
            "--------------------------------------------------\n",
            "Epoch 39 of 60 took 1.949s\n",
            "Train \tEpoch [39/60]  train_Loss: 0.3626\ttrain_Acc: 94.29\n",
            "Val \tEpoch [39/60]  val_Loss: 0.3265\tval_Acc: 96.36\n",
            "Test \tEpoch [39/60]  test_Loss: 1.7135\ttest_Acc: 47.27\n",
            "--------------------------------------------------\n",
            "Epoch 40 of 60 took 1.959s\n",
            "Train \tEpoch [40/60]  train_Loss: 0.3640\ttrain_Acc: 94.65\n",
            "Val \tEpoch [40/60]  val_Loss: 0.3307\tval_Acc: 95.00\n",
            "Test \tEpoch [40/60]  test_Loss: 1.6441\ttest_Acc: 47.73\n",
            "--------------------------------------------------\n",
            "Epoch 41 of 60 took 1.923s\n",
            "Train \tEpoch [41/60]  train_Loss: 0.3708\ttrain_Acc: 93.51\n",
            "Val \tEpoch [41/60]  val_Loss: 0.3095\tval_Acc: 96.82\n",
            "Test \tEpoch [41/60]  test_Loss: 1.7928\ttest_Acc: 47.73\n",
            "--------------------------------------------------\n",
            "Epoch 42 of 60 took 1.922s\n",
            "Train \tEpoch [42/60]  train_Loss: 0.3522\ttrain_Acc: 94.69\n",
            "Val \tEpoch [42/60]  val_Loss: 0.3170\tval_Acc: 96.36\n",
            "Test \tEpoch [42/60]  test_Loss: 1.9679\ttest_Acc: 46.82\n",
            "--------------------------------------------------\n",
            "Epoch 43 of 60 took 1.947s\n",
            "Train \tEpoch [43/60]  train_Loss: 0.3648\ttrain_Acc: 94.96\n",
            "Val \tEpoch [43/60]  val_Loss: 0.3300\tval_Acc: 95.91\n",
            "Test \tEpoch [43/60]  test_Loss: 1.8494\ttest_Acc: 46.82\n",
            "--------------------------------------------------\n",
            "Epoch 44 of 60 took 1.918s\n",
            "Train \tEpoch [44/60]  train_Loss: 0.3685\ttrain_Acc: 93.93\n",
            "Val \tEpoch [44/60]  val_Loss: 0.3309\tval_Acc: 95.91\n",
            "Test \tEpoch [44/60]  test_Loss: 2.1288\ttest_Acc: 46.36\n",
            "--------------------------------------------------\n",
            "Epoch 45 of 60 took 1.932s\n",
            "Train \tEpoch [45/60]  train_Loss: 0.3463\ttrain_Acc: 94.85\n",
            "Val \tEpoch [45/60]  val_Loss: 0.3089\tval_Acc: 96.36\n",
            "Test \tEpoch [45/60]  test_Loss: 1.7244\ttest_Acc: 48.18\n",
            "--------------------------------------------------\n",
            "Epoch 46 of 60 took 1.964s\n",
            "Train \tEpoch [46/60]  train_Loss: 0.3630\ttrain_Acc: 94.27\n",
            "Val \tEpoch [46/60]  val_Loss: 0.3106\tval_Acc: 95.45\n",
            "Test \tEpoch [46/60]  test_Loss: 1.9092\ttest_Acc: 46.82\n",
            "--------------------------------------------------\n",
            "Epoch 47 of 60 took 1.905s\n",
            "Train \tEpoch [47/60]  train_Loss: 0.3341\ttrain_Acc: 95.31\n",
            "Val \tEpoch [47/60]  val_Loss: 0.3009\tval_Acc: 95.91\n",
            "Test \tEpoch [47/60]  test_Loss: 1.6923\ttest_Acc: 50.00\n",
            "--------------------------------------------------\n",
            "Epoch 48 of 60 took 1.918s\n",
            "Train \tEpoch [48/60]  train_Loss: 0.3455\ttrain_Acc: 94.78\n",
            "Val \tEpoch [48/60]  val_Loss: 0.3080\tval_Acc: 95.91\n",
            "Test \tEpoch [48/60]  test_Loss: 2.0539\ttest_Acc: 47.27\n",
            "--------------------------------------------------\n",
            "Epoch 49 of 60 took 1.927s\n",
            "Train \tEpoch [49/60]  train_Loss: 0.3330\ttrain_Acc: 95.29\n",
            "Val \tEpoch [49/60]  val_Loss: 0.3046\tval_Acc: 95.91\n",
            "Test \tEpoch [49/60]  test_Loss: 1.8357\ttest_Acc: 48.64\n",
            "--------------------------------------------------\n",
            "Epoch 50 of 60 took 1.921s\n",
            "Train \tEpoch [50/60]  train_Loss: 0.3432\ttrain_Acc: 94.82\n",
            "Val \tEpoch [50/60]  val_Loss: 0.3104\tval_Acc: 96.36\n",
            "Test \tEpoch [50/60]  test_Loss: 1.8140\ttest_Acc: 49.09\n",
            "--------------------------------------------------\n",
            "Epoch 51 of 60 took 1.937s\n",
            "Train \tEpoch [51/60]  train_Loss: 0.3444\ttrain_Acc: 95.02\n",
            "Val \tEpoch [51/60]  val_Loss: 0.3318\tval_Acc: 95.91\n",
            "Test \tEpoch [51/60]  test_Loss: 2.5512\ttest_Acc: 46.36\n",
            "--------------------------------------------------\n",
            "Time in total: 148.0282678604126\n",
            "Best validation accuracy:\t\t96.82 %\n",
            "Test accuracy when got the best validation accuracy:\t\t47.73 %\n",
            "--------------------------------------------------\n",
            "Last train accuracy:\t\t97.04 %\n",
            "Last validation accuracy:\t\t95.91 %\n",
            "Last test accuracy:\t\t\t\t46.36 %\n",
            "Early Stopping at epoch: 41\n",
            "Done!\n",
            "All folds for 1dconv are done!\n",
            "Last_train_acc:\t [0.96956521 0.96660727 0.93045777 0.94268078 0.94863915 0.92636687\n",
            " 0.94001752 0.93292147 0.93244445 0.93108106 0.93738818 0.95559502\n",
            " 0.97040361 0.94493603] \tmean : 0.9449360278936533\n",
            "Best_val_acc:\t [0.96756756 0.95754719 0.93969852 0.89552242 0.90816325 0.93532336\n",
            " 0.93264246 0.95049506 0.91428572 0.91555554 0.91244239 0.93779904\n",
            " 0.96818179 0.93347879] \tmean : 0.933478790980119\n",
            "Earlystopping_test_acc:\t [0.50270271 0.71226418 0.89447236 0.99004978 1.         0.9800995\n",
            " 0.98963732 0.99009901 0.95238096 0.97777778 0.82488477 0.66985649\n",
            " 0.47727272 0.84319212] \tmean : 0.8431921211572794\n",
            "Last_val_acc:\t [0.95675677 0.95754719 0.87939698 0.88557214 0.89795917 0.90547264\n",
            " 0.90155441 0.93564355 0.90476191 0.91555554 0.89400923 0.92822969\n",
            " 0.95909089 0.91704232] \tmean : 0.9170423150062561\n",
            "Last_test_acc:\t [0.55135137 0.7028302  0.89447236 0.99004978 1.         0.9800995\n",
            " 0.98445594 0.99009901 0.99047619 0.97333336 0.87557602 0.76076555\n",
            " 0.46363637 0.85824197] \tmean : 0.8582419730149783\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIbdNiEOnplW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "b1fe1cc4-9d34-4b9c-d3f1-aca5bfd135c9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}